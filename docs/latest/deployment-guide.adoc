= Data Lake Accelerator Deployment Guide

WARNING: The instructions in this version in the master branch are different than the one in the 0.2.0 release. In 0.2.0 the thinkbig-ui and thinkbig-services application didn't
include a default JAVA_HOME variable for startup and used the system Java. In the case of a Hortonworks sandbox that would be Java 7. It required you to run
a script to set the JAVA_HOME variable. In the latest 0.3.0-SNAPSHOT the JAVA_HOME is set by default to look at /opt/java/current so that every time you uninstall and re-install the
RPM you wouldn't have to re-run the script to set the JAVA_HOME again.

Think Big Analytics
May 2016

:toc:
:toclevels: 2
:toc-title: Contents

== About

This document explains how to install the Data Lake Accelerator framework as well as Elasticsearch, NiFi, and ActiveMQ. There are a few different ways you can
install it depending on whether or not you are installing all components on one edge node vs. multiple nodes.

== System Requirements

=== Dependencies

The Data Lake Accelerator services should be installed on an edge node.  The following should be available prior to the installing the Data Lake Starter.

.Dependencies
|===
|Redhat/GNU/Linux distributions
|RPM (for install)
|Java 1.8 (or greater)
|Hadoop 2.4+
|Spark 1.5.x+
|Apache NiFi 0.5+ (or Hortonworks DataFlow)
|Hive
|MySQL
|===

.Tested Platforms
|===
|Platform|URL|Version

|Hortonworks Sandbox|http://hortonworks.com/products/hortonworks-sandbox/| HDP 2.3, 2.4
|Cloudera Sandobx|http://www.cloudera.com/downloads/quickstart_vms/5-7.html|5.7
|===

=== Prerequisites
If installing in a new Hortonworks sandbox make sure to do the following first before running through the installation steps below.

. Download and import the HDP sandbox
. SSH into the box and change the password as prompted

    $ ssh root@127.0.0.1 â€“p 2222

. Run "ambari-admin-password-reset" to set the ambari admin password

    [root@sandbox ~]# ambari-admin-password-reset

. After ambari server starts login to the application and validate the dependent services are running (see above)

== Installation
There are 2 procedures you can follow to deploy the solution. In a test and production environment you will likely want to follow the manual installation guide as it has more
detailed instructions on how to install each individual component. For local development and 1 node development boxes you can leverage the setup wizard procedure to quickly bootstrap
your environment.

=== Java Requirements
Data Lake Accelerator requires Java 8 for NiFi, thinkbig-ui, and thinkbig-services. If you already have Java 8 installed as the system level Java you have the option to leverage that.

In some cases, such as with an HDP install, Java 7 is the system version and you likely will not want to change it to Java 8. In this case you can leverage the mentioned
scripts below to download and configure Java 8 in the /opt/java directory. The scripts will also modify the startup scripts for NiFi, thinkbig-ui and
thinkbig-services to reference the /opt/java JAVA_HOME.

If you already have Java 8 installed in a different location you will have the option to use that as well.

NOTE: When installing the RPM the applications are defaulted to use the /opt/java/current location. This default saves a step for developers so that they can uninstall and re-install
the RPM without having to run any other scripts.

=== Install Procedure 1:  Installing all components on one edge node with internet access using the wizard

Follow the steps below to install the data lake accelerator using the installation wizard script. This is convenient for local sandboxes (HDP/Cloudera)
and 1 node development boxes. The WGET command is used to download binaries so internet access is required.

Click on the below link to go to the wizard driven deployment instructions

link:./deployment/wizard-deployment-guide.adoc[Wizard Driven Deployment Guide]

=== Install Procedure 2: Installing each component manually
Click on the below link to go to the manual deployment instructions

link:./deployment/manual-deployment-guide.adoc[Manual Deployment Guide]


== Configuration

=== Configuration Files

Configuration for the data lake accelerator services are located under the following files:

    /opt/thinkbig/thinkbig-ui/conf/application.properties
    /opt/thinkbig/thinkbig-services/conf/application.properties


=== Optimizing Performance

You can adjust the memory setting for each services using the below environment variables

    /opt/thinkbig/thinkbig-ui/bin/run-thinkbig-ui.sh
    export THINKBIG_UI_OPTS= -Xmx4g

    /opt/thinkbig/thinkbig-services/bin/run-thinkbig-services.sh
    export THINKBIG_SERVICES_OPTS= -Xmx4g
    
The setting above would set the Java maximum heap size to 4 GB.

=== Change the Java Home
By default the thinkbig-services and thinkbig-ui application set the JAVA_HOME location to /opt/java/current. This can easily be changed by editing the JAVA_HOME environment variable
in the following two files

    /opt/thinkbig/thinkbig-ui/bin/run-thinkbig-ui.sh
    /opt/thinkbig/thinkbig-services/bin/run-thinkbig-services.sh

In addition, if you run the script to modify the NiFI JAVA_HOME variable you will need to edit

    /opt/nifi/current/bin/nifi.sh

== Starting and Stopping the Services Manually
If you follow the instructions for the installations steps above all of the below applications will be set to startup automatically if you restart the server. In the Hortonworks sandbox
the services for thinkbig and NiFI are set to start after all of the services managed by Ambari start up.

For starting and stopping the 3 data lake accelerator services there you can run the following scripts

   /opt/thinkbig/start-thinkbig-apps.sh
   /opt/thinkbig/stop-thinkbig-apps.sh

1. To Start individual services

    $ service activemq start
    $ service elasticsearch start
    $ service nifi start
    $ service thinkbig-spark-shell start
    $ service thinkbig-services start
    $ service thinkbig-ui start

2. To Stop individual services

    $ service activemq stop
    $ service elasticsearch stop
    $ service nifi stop
    $ service thinkbig-spark-shell stop
    $ service thinkbig-services stop
    $ service thinkbig-ui stop

3.  To get the status of individual services

    $ service activemq status
    $ service elasticsearch status
    $ service nifi status
    $ service thinkbig-spark-shell status
    $ service thinkbig-services status
    $ service thinkbig-ui status

== Log Output

=== Configuring Log Output

Log output for the services mentioned above are configured at:

			/opt/thinkbig/thinkbig-ui/conf/log4j.properties
			/opt/thinkbig/thinkbig-services/conf/log4j.properties

You may place logs where desired according to the 'log4j.appender.file.File' property.  Note the configuration line:

			log4j.appender.file.File=/var/log/<app>/<app>.log

=== Viewing Log Output

The default log locations for the various applications are located at:

/var/log/<service_name>

== Web and REST Access

Below are the default URL's and ports for the services

    Feed Manager and Operations UI
    http://127.0.0.1:8400
    username: dladmin
	password: thinkbig

    NiFi UI
    http://127.0.0.1:8079/nifi

    Elasticsearch REST API
    http://127.0.0.1:9200

    ActiveMQ Admin
    http://127.0.0.1:8161/admin


== Appendix: Cleanup scripts
For development and sandbox environments you can leverage the cleanup script to remove all of the Think Big services as well as Elasticsearch,
ActiveMQ, and NiFi.

    $ /opt/thinkbig/setup/dev/cleanup-env.sh

 IMPORTANT Only run this in a DEV environment. This will delete all application and the MySQL schema

In addition there is a script for cleaning up the hive schema and HDFS folders that are related to a specific "category" that is defined in the UI.

    $ /opt/thinkbig/setup/dev/cleanupCategory.sh [categoryName]

    Example: /opt/thinkbig/setup/dev/cleanupCategory.sh customers

== Appendix: Postgres Integration

TBD
	
