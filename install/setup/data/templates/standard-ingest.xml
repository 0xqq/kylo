<?xml version="1.0" encoding="UTF-8" standalone="yes"?><template><description></description><name>standard-ingest</name><snippet><connections><id>4c4a05ab-ef80-4134-8287-2e74f0a6f920</id><parentGroupId>fa976f65-0073-47fa-b6cd-e75da84f5d7d</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><bends><x>634.5</x><y>748.5</y></bends><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>1b7ce72f-31ab-4629-bf80-a876ba4a145f</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>5c7d4c73-b7b6-42c7-8f24-ec049f62051c</id><type>OUTPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>28888a48-0b60-4af7-9f59-a9de3c487bd6</id><parentGroupId>fa976f65-0073-47fa-b6cd-e75da84f5d7d</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>bcbea9e1-3e59-4d89-8909-158355ed6b81</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>fa976f65-0073-47fa-b6cd-e75da84f5d7d</groupId><id>2b36437a-2cab-4093-ae59-ede6e7ab4ed4</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>822a155d-af3c-40d6-ba47-de866962f99d</id><parentGroupId>fa976f65-0073-47fa-b6cd-e75da84f5d7d</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>84c5842a-34bf-4a2d-a9dc-0234622f90f5</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>72eaa8be-6461-4834-b505-0ecb5c654c2d</id><type>OUTPUT_PORT</type></source><zIndex>0</zIndex></connections><inputPorts><id>2b36437a-2cab-4093-ae59-ede6e7ab4ed4</id><parentGroupId>fa976f65-0073-47fa-b6cd-e75da84f5d7d</parentGroupId><position><x>243.0</x><y>627.0</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-ingest</name><state>STOPPED</state><transmitting>false</transmitting><type>INPUT_PORT</type></inputPorts><processGroups><id>44e29683-0fb2-4b71-a759-d2b22dafc306</id><parentGroupId>fa976f65-0073-47fa-b6cd-e75da84f5d7d</parentGroupId><position><x>652.0</x><y>495.0</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>b87d0b27-caf7-4a51-b243-e8758118ebe0</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a964d51e-ec15-4925-bffb-29011e5ace72</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a7c18651-19be-4351-a767-97418662b7c5</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>f874da02-2ed9-4666-b654-5cd995db0f2c</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>fdbf2c99-18bd-4265-9d33-32227713cebb</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>dcef85dc-5a41-40b0-9789-b33e2505b4a7</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>44e63552-e960-450f-9779-798d1cacd197</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>b6129bf1-4d8e-4695-840f-6ea402c031c5</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>1cb4020e-dd3c-4c8e-bb5c-a7838cad5c0a</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>01f134a4-796a-4646-93c8-4772c1e3046e</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>5c7d4c73-b7b6-42c7-8f24-ec049f62051c</id><type>OUTPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>1cb4020e-dd3c-4c8e-bb5c-a7838cad5c0a</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>11655c7a-0d8c-4bae-9aa7-30933a7542ea</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>2285c641-1098-482e-9237-c4a091d6175c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>1cb4020e-dd3c-4c8e-bb5c-a7838cad5c0a</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>07e69885-92e7-461d-a5db-a72d914e703a</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>1cb4020e-dd3c-4c8e-bb5c-a7838cad5c0a</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>fdbf2c99-18bd-4265-9d33-32227713cebb</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>5e19e385-ad5f-4673-ae71-fa27711afdba</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a5a3cf9b-ef7d-4eaa-9f89-ea99ff3ebf68</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>70873c9b-387a-4412-892f-9edac92b6f7e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>528542b8-bd1e-4f8f-9345-648fe542671a</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a964d51e-ec15-4925-bffb-29011e5ace72</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>0d3f57db-0e07-4ba4-858f-8bc816022293</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>45ce398f-dbfc-41a7-8fee-6e6641451d94</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>2285c641-1098-482e-9237-c4a091d6175c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>ccfd229c-fcec-4348-aa2b-df7382aeba8c</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>3e6c6226-c11c-45c6-b62f-1f4b13e879ac</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>dcef85dc-5a41-40b0-9789-b33e2505b4a7</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>f8fdb867-324a-4481-ba84-33fd20aa8642</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>9a47b37b-e5d2-4700-9ef2-3e973065774a</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>2285c641-1098-482e-9237-c4a091d6175c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a964d51e-ec15-4925-bffb-29011e5ace72</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>33689e6d-cc8e-4d3f-9dd9-241be9af79a0</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>f8fdb867-324a-4481-ba84-33fd20aa8642</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a964d51e-ec15-4925-bffb-29011e5ace72</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>312f5493-56dd-4198-9df1-acb0de42f1c5</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>ccfd229c-fcec-4348-aa2b-df7382aeba8c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>original</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a964d51e-ec15-4925-bffb-29011e5ace72</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>ee798561-c098-4190-bc84-7200f96cc47b</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>24c20969-57b1-4b63-b528-1829fcd2d1f9</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>1cb4020e-dd3c-4c8e-bb5c-a7838cad5c0a</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>9ebdde90-f3c9-4a6d-a9ff-9209efd3d229</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a5a3cf9b-ef7d-4eaa-9f89-ea99ff3ebf68</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>dac3319a-8531-4543-9705-1ba99c3c80df</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>6d7f0329-4452-4301-92e8-418bfff1ec7b</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>2285c641-1098-482e-9237-c4a091d6175c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>dcef85dc-5a41-40b0-9789-b33e2505b4a7</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>2af5131e-439e-47c4-b316-f6134a6af858</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>70873c9b-387a-4412-892f-9edac92b6f7e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>dac3319a-8531-4543-9705-1ba99c3c80df</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a13e92ee-cdc3-4743-b5bc-c73535dbc58f</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a7c18651-19be-4351-a767-97418662b7c5</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>bcbea9e1-3e59-4d89-8909-158355ed6b81</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>41afcf13-1e3d-463e-865a-92628a7c0abe</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>dac3319a-8531-4543-9705-1ba99c3c80df</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>registration_required</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>a7c18651-19be-4351-a767-97418662b7c5</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>0ac3e093-57aa-46b1-9d1a-283c73552c03</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>2285c641-1098-482e-9237-c4a091d6175c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>fdbf2c99-18bd-4265-9d33-32227713cebb</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>c951877a-3d7a-40b0-9e8c-2d8615f49725</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>2285c641-1098-482e-9237-c4a091d6175c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>f8fdb867-324a-4481-ba84-33fd20aa8642</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>d9b4b362-c384-4b47-81b1-34777c839d84</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>0d3f57db-0e07-4ba4-858f-8bc816022293</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>70873c9b-387a-4412-892f-9edac92b6f7e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>fef14b6f-ea1f-4023-ba42-ca1814577860</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>72eaa8be-6461-4834-b505-0ecb5c654c2d</id><type>OUTPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>0d3f57db-0e07-4ba4-858f-8bc816022293</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>e87658be-7e5a-4308-8ede-e7d816bf74ae</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>2285c641-1098-482e-9237-c4a091d6175c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>44e29683-0fb2-4b71-a759-d2b22dafc306</groupId><id>24c20969-57b1-4b63-b528-1829fcd2d1f9</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><inputPorts><id>bcbea9e1-3e59-4d89-8909-158355ed6b81</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>675.9736182975689</x><y>248.87579978952573</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-ingest-input-port</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><labels><id>697e0761-3315-4423-a80d-02c4c7b39df1</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1567.214355417969</x><y>162.70579359555745</y></position><height>515.265380859375</height><label>One-time registration</label><style><entry><key>background-color</key><value>#dbdbdb</value></entry><entry><key>font-size</key><value>18px</value></entry></style><width>1283.34326171875</width></labels><outputPorts><id>5c7d4c73-b7b6-42c7-8f24-ec049f62051c</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>2147.3944353736297</x><y>1626.7321889372543</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>to-elasticsearch-text-index</name><state>STOPPED</state><type>OUTPUT_PORT</type></outputPorts><outputPorts><id>72eaa8be-6461-4834-b505-0ecb5c654c2d</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>2144.3470808309935</x><y>556.6844525159124</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>to-elasticsearch-registration</name><state>STOPPED</state><type>OUTPUT_PORT</type></outputPorts><processors><id>0d3f57db-0e07-4ba4-858f-8bc816022293</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1587.8399789816156</x><y>530.5414659898779</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>782213b1-fd6a-40f8-97b3-bf7fcb1a7ed1</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Result</key><value><allowableValues><displayName>success</displayName><value>success</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>success</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Result</displayName><dynamic>false</dynamic><name>Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>ed37860d-e9ef-41c7-8276-a23f9681c7be</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Result</key><value>success</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Record Registration</name><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.UpdateRegistration</type></processors><processors><id>ccfd229c-fcec-4348-aa2b-df7382aeba8c</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>541.9186720499638</x><y>685.4733547416482</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/archive/${category}/${feed}/${feedts}</value></entry><entry><key>Conflict Resolution Strategy</key><value>fail</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key></entry><entry><key>Remote Group</key></entry><entry><key>Compression codec</key><value>BZIP</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Archive Originals</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#e6f205</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>2285c641-1098-482e-9237-c4a091d6175c</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1045.0428112103114</x><y>1248.0244745783584</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Directory</key><value>/tmp/${category}/${feed}/${feedts}/failed</value></entry><entry><key>Conflict Resolution Strategy</key><value>ignore</value></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Permissions</key></entry><entry><key>Owner</key></entry><entry><key>Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Failed Flow</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#fa0303</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors><processors><id>a5a3cf9b-ef7d-4eaa-9f89-ea99ff3ebf68</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>2117.4519960534362</x><y>295.4737444448199</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Directory</key><value>/tmp/${category}/${feed}/${feedts}/abandoned</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Permissions</key></entry><entry><key>Owner</key></entry><entry><key>Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Aborted Registration</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#fa0a1a</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors><processors><id>24c20969-57b1-4b63-b528-1829fcd2d1f9</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1500.8085098559925</x><y>1668.7915133636916</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>edca5c5d-56d1-49ae-8340-efcd3e58d512</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Strategy</key><value><allowableValues><displayName>MERGE</displayName><value>MERGE</value></allowableValues><allowableValues><displayName>DEDUPE_AND_MERGE</displayName><value>DEDUPE_AND_MERGE</value></allowableValues><allowableValues><displayName>SYNC</displayName><value>SYNC</value></allowableValues><allowableValues><displayName>${metadata.table.targetMergeStrategy}</displayName><value>${metadata.table.targetMergeStrategy}</value></allowableValues><defaultValue>${metadata.table.targetMergeStrategy}</defaultValue><description>Specifies the algorithm used to merge. Valid values are SYNC,MERGE,DEDUPE_AND_MERGE.  Sync will completely overwrite the target table with the source data. Merge will append the data into the target partitions. Dedupe will insert into the target partition but ensure no duplicate rows are remaining. </description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source table</key><value><defaultValue>${metadata.category.systemName}.${metadata.systemFeedName}_valid</defaultValue><description>Fully qualified name of the source table</description><displayName>Source table</displayName><dynamic>false</dynamic><name>Source table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target table</key><value><defaultValue>${category}.${feed}</defaultValue><description>Fully qualified name of the target table</description><displayName>Target table</displayName><dynamic>false</dynamic><name>Target table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed partition value</key><value><defaultValue>${feedts}</defaultValue><description>Feed timestamp that identifies the current feed partition</description><displayName>Feed partition value</displayName><dynamic>false</dynamic><name>Feed partition value</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Specification</key><value><defaultValue>${metadata.table.partitionSpecs}</defaultValue><description>Partition specification in format: field|type|formula
field|type|formula</description><displayName>Partition Specification</displayName><dynamic>false</dynamic><name>Partition Specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>f9c4419d-aec2-44a7-9032-a212409288ad</value></entry><entry><key>Merge Strategy</key><value>${metadata.table.targetMergeStrategy}</value></entry><entry><key>Source table</key><value>${category}.${feed}_valid</value></entry><entry><key>Target table</key><value>${category}.${feed}</value></entry><entry><key>Feed partition value</key><value>${feedts}</value></entry><entry><key>Partition Specification</key><value>${metadata.table.partitionSpecs}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeTable</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.MergeTable</type></processors><processors><id>dcef85dc-5a41-40b0-9789-b33e2505b4a7</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1592.7796962634627</x><y>868.006262452942</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>edca5c5d-56d1-49ae-8340-efcd3e58d512</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Statement</key><value><description>Provide the DDL or DML statement. Return values will be ignored.</description><displayName>Statement</displayName><dynamic>false</dynamic><name>Statement</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>f9c4419d-aec2-44a7-9032-a212409288ad</value></entry><entry><key>Statement</key><value>alter table ${category}.${feed}_feed add
    if not exists partition (processing_dttm=${feedts})
    location '/etl/${category}/${feed}/${feedts}/'</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Create Feed Partition</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQLStatement</type></processors><processors><id>b6129bf1-4d8e-4695-840f-6ea402c031c5</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>2135.0784683312622</x><y>1243.4881391453346</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ApplicationJAR</key><value><description>Path to the JAR file containing the Spark job application</description><displayName>ApplicationJAR</displayName><dynamic>false</dynamic><name>ApplicationJAR</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainClass</key><value><description>Qualified classname of the Spark job application class</description><displayName>MainClass</displayName><dynamic>false</dynamic><name>MainClass</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainArgs</key><value><description>Comma separated arguments to be passed into the main as args</description><displayName>MainArgs</displayName><dynamic>false</dynamic><name>MainArgs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkMaster</key><value><defaultValue>local</defaultValue><description>The Spark master</description><displayName>SparkMaster</displayName><dynamic>false</dynamic><name>SparkMaster</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkHome</key><value><defaultValue>/usr/hdp/current/spark-client/</defaultValue><description>Qualified classname of the Spark job application class</description><displayName>SparkHome</displayName><dynamic>false</dynamic><name>SparkHome</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Driver Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the driver</description><displayName>Driver Memory</displayName><dynamic>false</dynamic><name>Driver Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the executor</description><displayName>Executor Memory</displayName><dynamic>false</dynamic><name>Executor Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Number of Executors</key><value><defaultValue>1</defaultValue><description>The number of exectors to be used</description><displayName>Number of Executors</displayName><dynamic>false</dynamic><name>Number of Executors</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Spark Application Name</key><value><description>The name of the spark application</description><displayName>Spark Application Name</displayName><dynamic>false</dynamic><name>Spark Application Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Cores</key><value><defaultValue>1</defaultValue><description>The number of executor cores to be used</description><displayName>Executor Cores</displayName><dynamic>false</dynamic><name>Executor Cores</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Network Timeout</key><value><defaultValue>120s</defaultValue><description>Default timeout for all network interactions. This config will be used in place of spark.core.connection.ack.wait.timeout, spark.akka.timeout, spark.storage.blockManagerSlaveTimeoutMs, spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.</description><displayName>Network Timeout</displayName><dynamic>false</dynamic><name>Network Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>ApplicationJAR</key><value>
    /opt/nifi/current/lib/app/thinkbig-spark-job-profiler-jar-with-dependencies.jar
</value></entry><entry><key>MainClass</key><value>com.thinkbiganalytics.spark.dataprofiler.core.Profiler</value></entry><entry><key>MainArgs</key><value>table,${category}.${feed}_valid,10,${category}.${feed}_profile,${feedts}</value></entry><entry><key>SparkMaster</key><value>yarn-client</value></entry><entry><key>SparkHome</key><value>/usr/lib/spark</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Driver Memory</key><value>512m</value></entry><entry><key>Executor Memory</key><value>512m</value></entry><entry><key>Number of Executors</key><value>1</value></entry><entry><key>Spark Application Name</key><value>Profiler</value></entry><entry><key>Executor Cores</key><value>2</value></entry><entry><key>Network Timeout</key><value>120s</value></entry><entry><key>Hadoop Configuration Resources</key></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ProfileData</name><relationships><autoTerminate>true</autoTerminate><description>Spark execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Successful result.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#0a70f5</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.spark.ExecuteSparkJob</type></processors><processors><id>dac3319a-8531-4543-9705-1ba99c3c80df</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1584.2054254882844</x><y>209.25173722255272</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The full HDFS directory(s) to create separated by newline</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/model.db/${category}
    /model.db/${category}/${feed}
    /model.db/${category}/${feed}/feed
    /model.db/${category}/${feed}/valid
    /model.db/${category}/${feed}/invalid
    /model.db/${category}/${feed}/profile
    /app/warehouse/${category}/
    /app/warehouse/${category}/${feed}
    /etl/${category}
    /etl/${category}/${feed}</value></entry><entry><key>Permissions umask</key><value>777</value></entry><entry><key>Remote Owner</key><value>nifi</value></entry><entry><key>Remote Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>30 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Register HDFS Folders</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.hdfs.CreateHDFSFolder</type></processors><processors><id>a964d51e-ec15-4925-bffb-29011e5ace72</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1061.1708100219007</x><y>693.3993471534774</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Merge Strategy</key><value><allowableValues><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value></allowableValues><allowableValues><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt; or alternatively (for backward compatibility purposes) &lt;segment.identifier&gt;, &lt;segment.count&gt;, and &lt;segment.index&gt;. All FlowFiles with the same value for &quot;fragment.identifier&quot; will be grouped together. All FlowFiles in this group must have the same value for the &quot;fragment.count&quot; attribute. All FlowFiles in this group must have a unique value for the &quot;fragment.index&quot; attribute between 0 and the value of the &quot;fragment.count&quot; attribute.</description><displayName>Defragment</displayName><value>Defragment</value></allowableValues><defaultValue>Bin-Packing Algorithm</defaultValue><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Format</key><value><allowableValues><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description><displayName>TAR</displayName><value>TAR</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description><displayName>ZIP</displayName><value>ZIP</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value></allowableValues><allowableValues><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value></allowableValues><allowableValues><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Avro</displayName><value>Avro</value></allowableValues><defaultValue>Binary Concatenation</defaultValue><description>Determines the format that will be used to merge the content.</description><displayName>Merge Format</displayName><dynamic>false</dynamic><name>Merge Format</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attribute Strategy</key><value><allowableValues><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value></allowableValues><allowableValues><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value></allowableValues><defaultValue>Keep Only Common Attributes</defaultValue><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><displayName>Attribute Strategy</displayName><dynamic>false</dynamic><name>Attribute Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Correlation Attribute Name</key><value><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><displayName>Correlation Attribute Name</displayName><dynamic>false</dynamic><name>Correlation Attribute Name</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Minimum Number of Entries</key><value><defaultValue>1</defaultValue><description>The minimum number of files to include in a bundle</description><displayName>Minimum Number of Entries</displayName><dynamic>false</dynamic><name>Minimum Number of Entries</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Number of Entries</key><value><description>The maximum number of files to include in a bundle. If not specified, there is no maximum.</description><displayName>Maximum Number of Entries</displayName><dynamic>false</dynamic><name>Maximum Number of Entries</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Group Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size of for the bundle</description><displayName>Minimum Group Size</displayName><dynamic>false</dynamic><name>Minimum Group Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Group Size</key><value><description>The maximum size for the bundle. If not specified, there is no maximum.</description><displayName>Maximum Group Size</displayName><dynamic>false</dynamic><name>Maximum Group Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Bin Age</key><value><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><displayName>Max Bin Age</displayName><dynamic>false</dynamic><name>Max Bin Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum number of Bins</key><value><defaultValue>100</defaultValue><description>Specifies the maximum number of bins that can be held in memory at any one time</description><displayName>Maximum number of Bins</displayName><dynamic>false</dynamic><name>Maximum number of Bins</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Delimiter Strategy</key><value><allowableValues><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description><displayName>Filename</displayName><value>Filename</value></allowableValues><allowableValues><description>The values of Header, Footer, and Demarcator will be specified as property values</description><displayName>Text</displayName><value>Text</value></allowableValues><defaultValue>Filename</defaultValue><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><displayName>Delimiter Strategy</displayName><dynamic>false</dynamic><name>Delimiter Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Header File</key><value><description>Filename specifying the header to use. If not specified, no header is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Header</displayName><dynamic>false</dynamic><name>Header File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Footer File</key><value><description>Filename specifying the footer to use. If not specified, no footer is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Footer</displayName><dynamic>false</dynamic><name>Footer File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Demarcator File</key><value><description>Filename specifying the demarcator to use. If not specified, no demarcator is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Demarcator</displayName><dynamic>false</dynamic><name>Demarcator File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Compression Level</key><value><allowableValues><displayName>0</displayName><value>0</value></allowableValues><allowableValues><displayName>1</displayName><value>1</value></allowableValues><allowableValues><displayName>2</displayName><value>2</value></allowableValues><allowableValues><displayName>3</displayName><value>3</value></allowableValues><allowableValues><displayName>4</displayName><value>4</value></allowableValues><allowableValues><displayName>5</displayName><value>5</value></allowableValues><allowableValues><displayName>6</displayName><value>6</value></allowableValues><allowableValues><displayName>7</displayName><value>7</value></allowableValues><allowableValues><displayName>8</displayName><value>8</value></allowableValues><allowableValues><displayName>9</displayName><value>9</value></allowableValues><defaultValue>1</defaultValue><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Keep Path</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names; if using other merge strategy, this value is ignored</description><displayName>Keep Path</displayName><dynamic>false</dynamic><name>Keep Path</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Merge Strategy</key><value>Bin-Packing Algorithm</value></entry><entry><key>Merge Format</key><value>Binary Concatenation</value></entry><entry><key>Attribute Strategy</key><value>Keep Only Common Attributes</value></entry><entry><key>Correlation Attribute Name</key></entry><entry><key>Minimum Number of Entries</key><value>1</value></entry><entry><key>Maximum Number of Entries</key></entry><entry><key>Minimum Group Size</key><value>0 B</value></entry><entry><key>Maximum Group Size</key></entry><entry><key>Max Bin Age</key></entry><entry><key>Maximum number of Bins</key><value>100</value></entry><entry><key>Delimiter Strategy</key><value>Text</value></entry><entry><key>Header File</key></entry><entry><key>Footer File</key></entry><entry><key>Demarcator File</key></entry><entry><key>Compression Level</key><value>1</value></entry><entry><key>Keep Path</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeContent</name><relationships><autoTerminate>false</autoTerminate><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFile containing the merged content</description><name>merged</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFiles that were used to create the bundle</description><name>original</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.MergeContent</type></processors><processors><id>fdbf2c99-18bd-4265-9d33-32227713cebb</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1592.7054088665614</x><y>1043.3721313476562</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Script Engine</key><value><allowableValues><displayName>ECMAScript</displayName><value>ECMAScript</value></allowableValues><allowableValues><displayName>Groovy</displayName><value>Groovy</value></allowableValues><allowableValues><displayName>lua</displayName><value>lua</value></allowableValues><allowableValues><displayName>python</displayName><value>python</value></allowableValues><allowableValues><displayName>ruby</displayName><value>ruby</value></allowableValues><defaultValue>ECMAScript</defaultValue><description>The engine to execute scripts</description><displayName>Script Engine</displayName><dynamic>false</dynamic><name>Script Engine</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Script File</key><value><description>Path to script file to execute. Only one of Script File or Script Body may be used</description><displayName>Script File</displayName><dynamic>false</dynamic><name>Script File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Script Body</key><value><description>Body of script to execute. Only one of Script File or Script Body may be used</description><displayName>Script Body</displayName><dynamic>false</dynamic><name>Script Body</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Module Directory</key><value><description>Comma-separated list of paths to files and/or directories which contain modules required by the script.</description><displayName>Module Directory</displayName><dynamic>false</dynamic><name>Module Directory</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Script Engine</key><value>Groovy</value></entry><entry><key>Script File</key></entry><entry><key>Script Body</key><value>def flowFile = session.get()
    if(!flowFile) return
    def json = flowFile.getAttribute(&quot;metadata.table.fieldPoliciesJson&quot;);
    def inputFolder = flowFile.getAttribute(&quot;spark.input_folder&quot;)
    def feed = flowFile.getAttribute(&quot;feed&quot;)
    def category = flowFile.getAttribute(&quot;category&quot;)
    def feedts = flowFile.getAttribute(&quot;feedts&quot;)
    def folder = new File(inputFolder + &quot;/&quot;+category+&quot;/&quot;+feed+&quot;/&quot;+feedts)
    // If it doesn't exist
    if( !folder.exists() ) {
    // Create all folders
    folder.mkdirs()
    }
    def jsonFile = new File(folder,feed+&quot;_field_policy.json&quot;)
    jsonFile.write(json)
    flowFile = session.putAttribute(flowFile,&quot;table_field_policy_json_file&quot;,jsonFile.getCanonicalPath())
    session.transfer(flowFile, REL_SUCCESS)
</value></entry><entry><key>Module Directory</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Write field policy JSON to file</name><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that failed to be processed</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that were successfully processed</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>false</supportsParallelProcessing><type>org.apache.nifi.processors.script.ExecuteScript</type></processors><processors><id>70873c9b-387a-4412-892f-9edac92b6f7e</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1586.8748009239077</x><y>367.2587270382396</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>edca5c5d-56d1-49ae-8340-efcd3e58d512</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><defaultValue>ALL</defaultValue><description>Specifies the standard table type to create or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><defaultValue>${metadata.table.partitionStructure}</defaultValue><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Table Storage Format</key><value><defaultValue>${metadata.table.feedFormat}</defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Feed Table Storage Format</displayName><dynamic>false</dynamic><name>Feed Table Storage Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Format</key><value><defaultValue>${metadata.table.targetFormat}</defaultValue><description>Provide storage format specification for the target tables</description><displayName>Target Table Format</displayName><dynamic>false</dynamic><name>Target Table Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Properties</key><value><defaultValue>${metadata.table.targetTblProperties}</defaultValue><description>TblProperties clause generally specificying the compression option</description><displayName>Target Table Properties</displayName><dynamic>false</dynamic><name>Target Table Properties</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>f9c4419d-aec2-44a7-9032-a212409288ad</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry><entry><key>Partition specification</key><value>${metadata.table.partitionStructure}</value></entry><entry><key>Feed Table Storage Format</key><value>${metadata.table.feedFormat}</value></entry><entry><key>Target Table Format</key><value>${metadata.table.targetFormat}</value></entry><entry><key>Target Table Properties</key><value>${metadata.table.targetTblProperties}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Register Tables</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></processors><processors><id>f8fdb867-324a-4481-ba84-33fd20aa8642</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1594.117265107682</x><y>702.3368530273439</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/etl/${category}/${feed}/${feedts}</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key><value>nifi</value></entry><entry><key>Remote Group</key><value>hdfs</value></entry><entry><key>Compression codec</key><value>NONE</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutHDFS</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>1cb4020e-dd3c-4c8e-bb5c-a7838cad5c0a</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1593.8314900590103</x><y>1246.8851634810044</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ApplicationJAR</key><value><description>Path to the JAR file containing the Spark job application</description><displayName>ApplicationJAR</displayName><dynamic>false</dynamic><name>ApplicationJAR</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainClass</key><value><description>Qualified classname of the Spark job application class</description><displayName>MainClass</displayName><dynamic>false</dynamic><name>MainClass</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainArgs</key><value><description>Comma separated arguments to be passed into the main as args</description><displayName>MainArgs</displayName><dynamic>false</dynamic><name>MainArgs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkMaster</key><value><defaultValue>local</defaultValue><description>The Spark master</description><displayName>SparkMaster</displayName><dynamic>false</dynamic><name>SparkMaster</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkHome</key><value><defaultValue>/usr/hdp/current/spark-client/</defaultValue><description>Qualified classname of the Spark job application class</description><displayName>SparkHome</displayName><dynamic>false</dynamic><name>SparkHome</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Driver Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the driver</description><displayName>Driver Memory</displayName><dynamic>false</dynamic><name>Driver Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the executor</description><displayName>Executor Memory</displayName><dynamic>false</dynamic><name>Executor Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Number of Executors</key><value><defaultValue>1</defaultValue><description>The number of exectors to be used</description><displayName>Number of Executors</displayName><dynamic>false</dynamic><name>Number of Executors</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Spark Application Name</key><value><description>The name of the spark application</description><displayName>Spark Application Name</displayName><dynamic>false</dynamic><name>Spark Application Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Cores</key><value><defaultValue>1</defaultValue><description>The number of executor cores to be used</description><displayName>Executor Cores</displayName><dynamic>false</dynamic><name>Executor Cores</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Network Timeout</key><value><defaultValue>120s</defaultValue><description>Default timeout for all network interactions. This config will be used in place of spark.core.connection.ack.wait.timeout, spark.akka.timeout, spark.storage.blockManagerSlaveTimeoutMs, spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.</description><displayName>Network Timeout</displayName><dynamic>false</dynamic><name>Network Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>ApplicationJAR</key><value>
    /opt/nifi/current/lib/app/thinkbig-spark-validate-cleanse-jar-with-dependencies.jar
</value></entry><entry><key>MainClass</key><value>com.thinkbiganalytics.spark.datavalidator.Validator</value></entry><entry><key>MainArgs</key><value>${category},${feed},${feedts},${table_field_policy_json_file}</value></entry><entry><key>SparkMaster</key><value>yarn-client</value></entry><entry><key>SparkHome</key><value>/usr/lib/spark</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Driver Memory</key><value>512m</value></entry><entry><key>Executor Memory</key><value>512m</value></entry><entry><key>Number of Executors</key><value>1</value></entry><entry><key>Spark Application Name</key><value>Validator</value></entry><entry><key>Executor Cores</key><value>2</value></entry><entry><key>Network Timeout</key><value>120s</value></entry><entry><key>Hadoop Configuration Resources</key></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Validate And Split Records</name><relationships><autoTerminate>false</autoTerminate><description>Spark execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successful result.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.spark.ExecuteSparkJob</type></processors><processors><id>a7c18651-19be-4351-a767-97418662b7c5</id><parentGroupId>44e29683-0fb2-4b71-a759-d2b22dafc306</parentGroupId><position><x>1057.6167940389778</x><y>223.05858509360883</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>782213b1-fd6a-40f8-97b3-bf7fcb1a7ed1</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>ed37860d-e9ef-41c7-8276-a23f9681c7be</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Route for Registration?</name><relationships><autoTerminate>false</autoTerminate><description>Registration is required.</description><name>registration_required</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.RouteOnRegistration</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>1</inputPortCount><invalidCount>5</invalidCount><name>standard-ingest</name><outputPortCount>2</outputPortCount><parent><id>fa976f65-0073-47fa-b6cd-e75da84f5d7d</id><name>NiFi Flow</name></parent><runningCount>0</runningCount><stoppedCount>12</stoppedCount></processGroups><processGroups><id>708b5dc5-2daf-4a83-994d-f3dac36286aa</id><parentGroupId>fa976f65-0073-47fa-b6cd-e75da84f5d7d</parentGroupId><position><x>653.0</x><y>953.0</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>642db6df-9379-4f49-abe0-2501353450ed</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>e99500dd-7d67-4908-84d4-f876db9f3628</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>matched</selectedRelationships><source><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>32b0fda6-4261-41ca-b1c1-ac7d5ad3cc3d</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>29301648-f818-4c22-bbe6-95866309dea2</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>ced3e5b3-c896-4ea6-b268-54d897e8970e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>84c5842a-34bf-4a2d-a9dc-0234622f90f5</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>e51a13a5-496d-4a54-bace-db48262f9245</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>32b0fda6-4261-41ca-b1c1-ac7d5ad3cc3d</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>1b7ce72f-31ab-4629-bf80-a876ba4a145f</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>1b7d95ee-754f-41a7-808f-7f3d99d96de2</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>7503a8f2-04ab-4e4b-8dc3-99f4bdec2e8e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>f7e49a4c-0e3b-438e-808d-aead50fda0b6</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>0193ee0c-3b6d-450a-8da2-0a0a36772d7c</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>4bcfaa91-622e-4a3b-91d8-dba63854554f</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>987eb1ba-fc97-4062-a9b4-290416607b8e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>0ca0294b-85e3-4ceb-b603-c1a6ccff4c41</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>26844d9a-1c19-41ad-b660-83818769327c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>7503a8f2-04ab-4e4b-8dc3-99f4bdec2e8e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>7839fbb3-a736-461c-a871-e1d39b2d08e6</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>f7e49a4c-0e3b-438e-808d-aead50fda0b6</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>ced3e5b3-c896-4ea6-b268-54d897e8970e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>51553d66-b381-46be-920a-df23ea1dcff1</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>987eb1ba-fc97-4062-a9b4-290416607b8e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</groupId><id>e99500dd-7d67-4908-84d4-f876db9f3628</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><inputPorts><id>84c5842a-34bf-4a2d-a9dc-0234622f90f5</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>27.578346443926307</x><y>-42.74942462782474</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>elasticsearch-register-input</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><inputPorts><id>1b7ce72f-31ab-4629-bf80-a876ba4a145f</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>41.195438672571754</x><y>404.6720060046366</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>elasticsearch-fulltext-input</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><labels><id>a6e92c55-e3c3-4e7c-b9ba-5952fe5130d1</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>270.7421614455693</x><y>-134.17892753865505</y></position><height>396.84320068359375</height><label>Register schema in ElasticSearch</label><style><entry><key>background-color</key><value>#bc8fff</value></entry><entry><key>font-size</key><value>18px</value></entry></style><width>869.5535888671875</width></labels><labels><id>6f57676c-408e-44ab-97a0-6733a7109ea7</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>270.81927490234375</x><y>313.1640625</y></position><height>673.1553955078125</height><label>Index Elasticsearch</label><style><entry><key>font-size</key><value>18px</value></entry></style><width>575.7344970703125</width></labels><processors><id>7503a8f2-04ab-4e4b-8dc3-99f4bdec2e8e</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>339.83258246017203</x><y>106.6443105885478</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Name Field</key><value><description>The name of the hive database field</description><displayName>Database Name Field</displayName><dynamic>false</dynamic><name>Database Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Database Owner Field</key><value><description>Database owner field name</description><displayName>Database Owner Field</displayName><dynamic>false</dynamic><name>Database Owner Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Create Time Field</key><value><description>Field representing the table create time</description><displayName>Table Create Time Field</displayName><dynamic>false</dynamic><name>Table Create Time Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Name Field</key><value><description>Field holding the table name</description><displayName>Table Name Field</displayName><dynamic>false</dynamic><name>Table Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type Field</key><value><description>Field representing what type of hive table it is</description><displayName>Table Type Field</displayName><dynamic>false</dynamic><name>Table Type Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Column Name Field</key><value><description>Field representing the column name</description><displayName>Column Name Field</displayName><dynamic>false</dynamic><name>Column Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Column Type Field</key><value><description>Field representing what the column type is</description><displayName>Column Type Field</displayName><dynamic>false</dynamic><name>Column Type Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Name Field</key><value>NAME</value></entry><entry><key>Database Owner Field</key><value>OWNER_NAME</value></entry><entry><key>Table Create Time Field</key><value>CREATE_TIME</value></entry><entry><key>Table Name Field</key><value>TBL_NAME</value></entry><entry><key>Table Type Field</key><value>TBL_TYPE</value></entry><entry><key>Column Name Field</key><value>COLUMN_NAME</value></entry><entry><key>Column Type Field</key><value>TYPE_NAME</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Merge Metadata Columns</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully merged are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Json objects that are successfully merged are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.MergeHiveTableMetadata</type></processors><processors><id>987eb1ba-fc97-4062-a9b4-290416607b8e</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>416.58819137188243</x><y>667.5687682773951</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>JSON container options</key><value><allowableValues><displayName>none</displayName><value>none</value></allowableValues><allowableValues><displayName>array</displayName><value>array</value></allowableValues><defaultValue>array</defaultValue><description>Determines how stream of records is exposed: either as a sequence of single Objects (none) (i.e. writing every Object to a new line), or as an array of Objects (array).</description><displayName>JSON container options</displayName><dynamic>false</dynamic><name>JSON container options</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Wrap Single Record</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Determines if the resulting output for empty records or a single record should be wrapped in a container array as specified by 'JSON container options'</description><displayName>Wrap Single Record</displayName><dynamic>false</dynamic><name>Wrap Single Record</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>JSON container options</key><value>array</value></entry><entry><key>Wrap Single Record</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ConvertAvroToJSON</name><relationships><autoTerminate>true</autoTerminate><description>A FlowFile is routed to this relationship if it cannot be parsed as Avro or cannot be converted to JSON for any reason</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>A FlowFile is routed to this relationship after it has been converted to JSON</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.avro.ConvertAvroToJSON</type></processors><processors><id>e99500dd-7d67-4908-84d4-f876db9f3628</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>414.14337735974345</x><y>513.4959145126822</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>edca5c5d-56d1-49ae-8340-efcd3e58d512</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>f9c4419d-aec2-44a7-9032-a212409288ad</value></entry><entry><key>SQL select query</key><value>select ${metadata.table.fieldIndexString} from ${category}.${feed}_valid where processing_dttm =
    ${feedts}</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ExecuteHQL</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from SQL query result set.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type></processors><processors><id>f7e49a4c-0e3b-438e-808d-aead50fda0b6</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>757.0909138267871</x><y>-81.79882633618513</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>JSON container options</key><value><allowableValues><displayName>none</displayName><value>none</value></allowableValues><allowableValues><displayName>array</displayName><value>array</value></allowableValues><defaultValue>array</defaultValue><description>Determines how stream of records is exposed: either as a sequence of single Objects (none) (i.e. writing every Object to a new line), or as an array of Objects (array).</description><displayName>JSON container options</displayName><dynamic>false</dynamic><name>JSON container options</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Wrap Single Record</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Determines if the resulting output for empty records or a single record should be wrapped in a container array as specified by 'JSON container options'</description><displayName>Wrap Single Record</displayName><dynamic>false</dynamic><name>Wrap Single Record</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>JSON container options</key><value>array</value></entry><entry><key>Wrap Single Record</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Convert Metadata SQL to JSON</name><relationships><autoTerminate>true</autoTerminate><description>A FlowFile is routed to this relationship if it cannot be parsed as Avro or cannot be converted to JSON for any reason</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>A FlowFile is routed to this relationship after it has been converted to JSON</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.avro.ConvertAvroToJSON</type></processors><processors><id>4bcfaa91-622e-4a3b-91d8-dba63854554f</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>414.0225043472317</x><y>814.5763728495995</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>IndexName</key><value><description>The name of the index</description><displayName>IndexName</displayName><dynamic>false</dynamic><name>IndexName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Type</key><value><description>Elasticsearch type</description><displayName>Type</displayName><dynamic>false</dynamic><name>Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>HostName</key><value><description>Elasticsearch host</description><displayName>HostName</displayName><dynamic>false</dynamic><name>HostName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>ClusterName</key><value><description>Elasticsearch cluster</description><displayName>ClusterName</displayName><dynamic>false</dynamic><name>ClusterName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>IdField</key><value><description>Id that you want to use for indexing into elasticsearch. If it is empty then a uuid will be generated</description><displayName>IdField</displayName><dynamic>false</dynamic><name>IdField</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>IndexName</key><value>${category}</value></entry><entry><key>Type</key><value>${feed}</value></entry><entry><key>HostName</key><value>localhost</value></entry><entry><key>ClusterName</key><value>demo-cluster</value></entry><entry><key>IdField</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>IndexElasticSearch Full Text</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully indexed in elasticsearch are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Json objects that are successfully indexed in elasticsearch are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.IndexElasticSearch</type></processors><processors><id>32b0fda6-4261-41ca-b1c1-ac7d5ad3cc3d</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>415.22610292695094</x><y>369.71244257771014</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Routing Strategy</key><value><allowableValues><description>A copy of the FlowFile will be routed to each relationship whose corresponding expression evaluates to 'true'</description><displayName>Route to Property name</displayName><value>Route to Property name</value></allowableValues><allowableValues><description>Requires that all user-defined expressions evaluate to 'true' for the FlowFile to be considered a match</description><displayName>Route to 'matched' if all match</displayName><value>Route to 'match' if all match</value></allowableValues><allowableValues><description>Requires that at least one user-defined expression evaluate to 'true' for hte FlowFile to be considered a match</description><displayName>Route to 'matched' if any matches</displayName><value>Route to 'match' if any matches</value></allowableValues><defaultValue>Route to Property name</defaultValue><description>Specifies how to determine which relationship to use when evaluating the Expression Language</description><displayName>Routing Strategy</displayName><dynamic>false</dynamic><name>Routing Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>indexColumns</key><value><description></description><displayName>indexColumns</displayName><dynamic>true</dynamic><name>indexColumns</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Routing Strategy</key><value>Route to 'match' if all match</value></entry><entry><key>indexColumns</key><value>${metadata.table.fieldIndexString:isEmpty():not()}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>RouteOnAttribute</name><relationships><autoTerminate>false</autoTerminate><description>FlowFiles will be routed to 'match' if one or all Expressions match, depending on the configuration of the Routing Strategy property</description><name>matched</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that do not match any user-define expression will be routed here</description><name>unmatched</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.RouteOnAttribute</type></processors><processors><id>ced3e5b3-c896-4ea6-b268-54d897e8970e</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>329.1402587890625</x><y>-74.8199462890625</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>MySQL</displayName><value>5d1d18ec-537c-460a-98ec-1fc524d486d0</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>5ca99d88-7afa-4f18-90fb-fb109350c3de</value></entry><entry><key>SQL select query</key><value>SELECT d.NAME DATABASE_NAME, d.OWNER_NAME OWNER, t.CREATE_TIME, t.TBL_NAME, t.TBL_TYPE,
    c.COLUMN_NAME, c.TYPE_NAME
    FROM ${config.hive.schema}.COLUMNS_V2 c
    JOIN  ${config.hive.schema}.TBLS t ON c.CD_ID=t.TBL_ID
    JOIN  ${config.hive.schema}.DBS d on d.DB_ID = t.DB_ID
    where d.name = '${category}'and t.tbl_name like '${feed}%';</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Query Hive Table Metadata</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from SQL query result set.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.ExecuteSQL</type></processors><processors><id>26844d9a-1c19-41ad-b660-83818769327c</id><parentGroupId>708b5dc5-2daf-4a83-994d-f3dac36286aa</parentGroupId><position><x>754.5156150018033</x><y>107.90421914428634</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>IndexName</key><value><description>The name of the index</description><displayName>IndexName</displayName><dynamic>false</dynamic><name>IndexName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Type</key><value><description>Elasticsearch type</description><displayName>Type</displayName><dynamic>false</dynamic><name>Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>HostName</key><value><description>Elasticsearch host</description><displayName>HostName</displayName><dynamic>false</dynamic><name>HostName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>ClusterName</key><value><description>Elasticsearch cluster</description><displayName>ClusterName</displayName><dynamic>false</dynamic><name>ClusterName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>IdField</key><value><description>Id that you want to use for indexing into elasticsearch. If it is empty then a uuid will be generated</description><displayName>IdField</displayName><dynamic>false</dynamic><name>IdField</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>IndexName</key><value>metadata</value></entry><entry><key>Type</key><value>hive-tables</value></entry><entry><key>HostName</key><value>localhost</value></entry><entry><key>ClusterName</key><value>demo-cluster</value></entry><entry><key>IdField</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Index Metadata Elasticsearch</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully indexed in elasticsearch are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Json objects that are successfully indexed in elasticsearch are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.IndexElasticSearch</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>2</inputPortCount><invalidCount>2</invalidCount><name>index-elasticsearch</name><outputPortCount>0</outputPortCount><parent><id>fa976f65-0073-47fa-b6cd-e75da84f5d7d</id><name>NiFi Flow</name></parent><runningCount>0</runningCount><stoppedCount>8</stoppedCount></processGroups></snippet><timestamp>08/11/2016 00:38:43 UTC</timestamp></template>