<?xml version="1.0" encoding="UTF-8" standalone="yes"?><template><description></description><name>standard-ingest</name><snippet><connections><id>b0617339-a062-4fb6-a362-a1ae097c9bea</id><parentGroupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>2daacf39-62c0-4111-903c-934174b2a9a4</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</groupId><id>3bbe08dc-0583-4cd8-a81e-dac4c136b89c</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>15acf206-7f40-42cd-9b10-2c60e3b1cacc</id><parentGroupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>b3adc567-3e11-4f95-accb-3353f25d85c4</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>35f735ff-534b-4540-a7cb-f7112ab2e41e</id><type>OUTPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>22d840fd-37aa-432f-9b52-830bc4e33b37</id><parentGroupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>7a2bddaf-04ae-497f-84ef-a6f9ac7eaa20</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</groupId><id>e1c21f55-9b61-494e-8bb7-de526920505f</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>0d7798b5-501c-4189-bb9c-8c7ff9e7ea83</id><parentGroupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><bends><x>401.5</x><y>263.5</y></bends><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>af570bae-e0e0-4cb2-85df-5e1df6059d9b</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>34b70d6b-bb20-4440-85ef-190de2fc398f</id><type>OUTPUT_PORT</type></source><zIndex>0</zIndex></connections><controllerServices><id>81b8d7a8-8039-41ac-859e-cc25c9182319</id><comments></comments><descriptors><entry><key>Database Connection URL</key><value><description>A database connection URL used to connect to a database. May contain database system name, host, port, database name and some parameters. The exact syntax of a database connection URL is specified by your DBMS.</description><displayName>Database Connection URL</displayName><dynamic>false</dynamic><name>Database Connection URL</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Class Name</key><value><description>Database driver class name</description><displayName>Database Driver Class Name</displayName><dynamic>false</dynamic><name>Database Driver Class Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Jar Url</key><value><description>Optional database driver jar file path url. For example 'file:///var/tmp/mariadb-java-client-1.1.7.jar'</description><displayName>Database Driver Jar Url</displayName><dynamic>false</dynamic><name>Database Driver Jar Url</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database User</key><value><description>Database user name</description><displayName>Database User</displayName><dynamic>false</dynamic><name>Database User</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Password</key><value><description>The password for the database user</description><displayName>Password</displayName><dynamic>false</dynamic><name>Password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>500 millis</defaultValue><description>The maximum amount of time that the pool will wait (when there are no available connections)  for a connection to be returned before failing, or -1 to wait indefinitely. </description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Total Connections</key><value><defaultValue>8</defaultValue><description>The maximum number of active connections that can be allocated from this pool at the same time,  or negative for no limit.</description><displayName>Max Total Connections</displayName><dynamic>false</dynamic><name>Max Total Connections</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><name>Hive Thrift Service</name><properties><entry><key>Database Connection URL</key><value>jdbc:hive2://localhost:10000/default</value></entry><entry><key>Database Driver Class Name</key><value>org.apache.hive.jdbc.HiveDriver</value></entry><entry><key>Database Driver Jar Url</key></entry><entry><key>Database User</key><value>nifi</value></entry><entry><key>Password</key></entry><entry><key>Max Wait Time</key><value>500 millis</value></entry><entry><key>Max Total Connections</key><value>8</value></entry><entry><key>Hadoop Configuration Resources</key></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry></properties><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>3f576aea-6137-4f5f-9ece-d3b9f101c81c</groupId><id>0e44c068-42a4-401b-bc9a-7fc3933997b3</id><name>ExecuteHQL</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>SQL select query</key><value>select x.invalid_count, y.total_count, x.invalid_count/y.total_count as invalid_pct, CASE WHEN (x.invalid_count/y.total_count)*100 &gt;= ${invalidThresholdPercentage} then 'false' else 'true' end as valid,
                                       CASE WHEN x.invalid_count/y.total_count &gt;= 0.10 then  concat('Invalid. The data has  ', (x.invalid_count/y.total_count)*100,'% of the rows invalid.  This is above the threshold of ','${invalidThresholdPercentage}%' ) else concat('Valid.  This job has passed validation with ',  (x.invalid_count/y.total_count)*100,'% of the rows invalid.  This is below the threshold of ${invalidThresholdPercentage}%') end as validation_message, x.processing_dttm
from (
       select  metricvalue as invalid_count, 'INVALID_COUNT' as type, m.max_date as processing_dttm from ${category}.${feed}_profile
       inner join (SELECT MAX(processing_dttm) as max_date from ${category}.${feed}_profile) m on m.max_date = processing_dttm
       where columnname = '(ALL)'
       and metrictype = 'INVALID_COUNT'
     ) x
  inner join (
               select  metricvalue as total_count, 'TOTAL_COUNT' as type,m.max_date as processing_dttm from ${category}.${feed}_profile
               inner join (SELECT MAX(processing_dttm) as max_date from ${category}.${feed}_profile) m on m.max_date = processing_dttm
               where columnname = '(ALL)'
               and metrictype = 'TOTAL_COUNT') y on y.processing_dttm = x.processing_dttm</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><defaultValue>ALL</defaultValue><description>Specifies the standard table type to create or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><defaultValue>${metadata.table.partitionStructure}</defaultValue><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Table Storage Format</key><value><defaultValue>${metadata.table.feedFormat}</defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Feed Table Storage Format</displayName><dynamic>false</dynamic><name>Feed Table Storage Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Format</key><value><defaultValue>${metadata.table.targetFormat}</defaultValue><description>Provide storage format specification for the target tables</description><displayName>Target Table Format</displayName><dynamic>false</dynamic><name>Target Table Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Properties</key><value><defaultValue>${metadata.table.targetTblProperties}</defaultValue><description>TblProperties clause generally specificying the compression option</description><displayName>Target Table Properties</displayName><dynamic>false</dynamic><name>Target Table Properties</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>2cb29f9b-38a7-4a87-aa20-898ef552e4f9</groupId><id>6227d916-e6a0-43f7-a0fc-d485b0ee0d58</id><name>Register Tables</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry><entry><key>Partition specification</key><value>${metadata.table.partitionStructure}</value></entry><entry><key>Feed Table Storage Format</key><value>${metadata.table.feedFormat}</value></entry><entry><key>Target Table Format</key><value>${metadata.table.targetFormat}</value></entry><entry><key>Target Table Properties</key><value>${metadata.table.targetTblProperties}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>946919b1-ba17-41a2-b7d0-c4ab10c72cb4</id><name>ExecuteHQL</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>SQL select query</key><value>select ${metadata.table.fieldIndexString} from ${category}.${feed}_valid where processing_dttm =
    ${feedts}</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>5876ba01-d972-4e0e-a8dd-b5f6a3cb272d</groupId><id>b865fd24-af8d-46c5-834f-4cff4470e312</id><name>ExecuteHQL</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>SQL select query</key><value>select ${metadata.table.fieldIndexString} from ${category}.${feed}_valid where processing_dttm =
    ${feedts}</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><defaultValue>ALL</defaultValue><description>Specifies the standard table type to create or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><defaultValue>${metadata.table.partitionStructure}</defaultValue><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Table Storage Format</key><value><defaultValue>${metadata.table.feedFormat}</defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Feed Table Storage Format</displayName><dynamic>false</dynamic><name>Feed Table Storage Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Format</key><value><defaultValue>${metadata.table.targetFormat}</defaultValue><description>Provide storage format specification for the target tables</description><displayName>Target Table Format</displayName><dynamic>false</dynamic><name>Target Table Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Properties</key><value><defaultValue>${metadata.table.targetTblProperties}</defaultValue><description>TblProperties clause generally specificying the compression option</description><displayName>Target Table Properties</displayName><dynamic>false</dynamic><name>Target Table Properties</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>0345b49f-13d8-4a2b-87ab-1b91fa8eabf2</groupId><id>64c5c525-821d-4300-a254-01d4ed471d62</id><name>Register Tables</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry><entry><key>Partition specification</key><value>${metadata.table.partitionStructure}</value></entry><entry><key>Feed Table Storage Format</key><value>${metadata.table.feedFormat}</value></entry><entry><key>Target Table Format</key><value>${metadata.table.targetFormat}</value></entry><entry><key>Target Table Properties</key><value>${metadata.table.targetTblProperties}</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><defaultValue>ALL</defaultValue><description>Specifies the standard table type to create or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><defaultValue>${metadata.table.partitionStructure}</defaultValue><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Table Storage Format</key><value><defaultValue>${metadata.table.feedFormat}</defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Feed Table Storage Format</displayName><dynamic>false</dynamic><name>Feed Table Storage Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Format</key><value><defaultValue>${metadata.table.targetFormat}</defaultValue><description>Provide storage format specification for the target tables</description><displayName>Target Table Format</displayName><dynamic>false</dynamic><name>Target Table Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Properties</key><value><defaultValue>${metadata.table.targetTblProperties}</defaultValue><description>TblProperties clause generally specificying the compression option</description><displayName>Target Table Properties</displayName><dynamic>false</dynamic><name>Target Table Properties</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>cea79fe6-a126-46b0-80ca-0da44dec95fa</groupId><id>c94d4ca6-3bea-44bf-8504-62072692f2fb</id><name>Register Tables</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry><entry><key>Partition specification</key><value>${metadata.table.partitionStructure}</value></entry><entry><key>Feed Table Storage Format</key><value>${metadata.table.feedFormat}</value></entry><entry><key>Target Table Format</key><value>${metadata.table.targetFormat}</value></entry><entry><key>Target Table Properties</key><value>${metadata.table.targetTblProperties}</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Statement</key><value><description>Provide the DDL or DML statement. Return values will be ignored.</description><displayName>Statement</displayName><dynamic>false</dynamic><name>Statement</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c2c1ec03-72d3-4a00-9c0e-f9c53dc932be</id><name>Create Feed Partition</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>Statement</key><value>alter table ${category}.${feed}_feed add
    if not exists partition (processing_dttm=${feedts})
    location '/etl/${category}/${feed}/${feedts}/'</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQLStatement</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><description>Specifies the standard table type to drop or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Additional Tables</key><value><description>Additional tables to drop separated by comma.</description><displayName>Additional Tables</displayName><dynamic>false</dynamic><name>Additional Tables</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>2cb29f9b-38a7-4a87-aa20-898ef552e4f9</groupId><id>94c17f40-8e52-4ab1-9dab-fbb7f62ef806</id><name>DropFeedTables</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Additional Tables</key></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.DropFeedTables</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>2da38962-142a-49b6-91a1-82989256e464</groupId><id>9b856abb-a13d-4012-b41c-b3abf132ced3</id><name>ExecuteHQL</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>SQL select query</key><value>select x.invalid_count, y.total_count, x.invalid_count/y.total_count as invalid_pct, CASE WHEN (x.invalid_count/y.total_count)*100 &gt;= ${invalidThresholdPercentage} then 'false' else 'true' end as valid,
                                       CASE WHEN x.invalid_count/y.total_count &gt;= 0.10 then  concat('Invalid. The data has  ', (x.invalid_count/y.total_count)*100,'% of the rows invalid.  This is above the threshold of ','${invalidThresholdPercentage}%' ) else concat('Valid.  This job has passed validation with ',  (x.invalid_count/y.total_count)*100,'% of the rows invalid.  This is below the threshold of ${invalidThresholdPercentage}%') end as validation_message, x.processing_dttm
from (
       select  metricvalue as invalid_count, 'INVALID_COUNT' as type, m.max_date as processing_dttm from ${category}.${feed}_profile
       inner join (SELECT MAX(processing_dttm) as max_date from ${category}.${feed}_profile) m on m.max_date = processing_dttm
       where columnname = '(ALL)'
       and metrictype = 'INVALID_COUNT'
     ) x
  inner join (
               select  metricvalue as total_count, 'TOTAL_COUNT' as type,m.max_date as processing_dttm from ${category}.${feed}_profile
               inner join (SELECT MAX(processing_dttm) as max_date from ${category}.${feed}_profile) m on m.max_date = processing_dttm
               where columnname = '(ALL)'
               and metrictype = 'TOTAL_COUNT') y on y.processing_dttm = x.processing_dttm</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><defaultValue>ALL</defaultValue><description>Specifies the standard table type to create or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><defaultValue>${metadata.table.partitionStructure}</defaultValue><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Table Storage Format</key><value><defaultValue>${metadata.table.feedFormat}</defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Feed Table Storage Format</displayName><dynamic>false</dynamic><name>Feed Table Storage Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Format</key><value><defaultValue>${metadata.table.targetFormat}</defaultValue><description>Provide storage format specification for the target tables</description><displayName>Target Table Format</displayName><dynamic>false</dynamic><name>Target Table Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Properties</key><value><defaultValue>${metadata.table.targetTblProperties}</defaultValue><description>TblProperties clause generally specificying the compression option</description><displayName>Target Table Properties</displayName><dynamic>false</dynamic><name>Target Table Properties</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>63ea4dae-f086-4172-a695-04726ad93a83</groupId><id>114d5301-9c60-42b2-b5a4-8cf6ca0be8dc</id><name>Register Tables</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry><entry><key>Partition specification</key><value>${metadata.table.partitionStructure}</value></entry><entry><key>Feed Table Storage Format</key><value>${metadata.table.feedFormat}</value></entry><entry><key>Target Table Format</key><value>${metadata.table.targetFormat}</value></entry><entry><key>Target Table Properties</key><value>${metadata.table.targetTblProperties}</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Statement</key><value><description>Provide the DDL or DML statement. Return values will be ignored.</description><displayName>Statement</displayName><dynamic>false</dynamic><name>Statement</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>2cb29f9b-38a7-4a87-aa20-898ef552e4f9</groupId><id>33c368c9-1509-4289-a4e8-4796bdc3c5f0</id><name>Create Feed Partition</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>Statement</key><value>alter table ${category}.${feed}_feed add
    if not exists partition (processing_dttm=${feedts})
    location '/etl/${category}/${feed}/${feedts}/'</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQLStatement</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Strategy</key><value><allowableValues><displayName>MERGE</displayName><value>MERGE</value></allowableValues><allowableValues><displayName>DEDUPE_AND_MERGE</displayName><value>DEDUPE_AND_MERGE</value></allowableValues><allowableValues><displayName>SYNC</displayName><value>SYNC</value></allowableValues><allowableValues><displayName>${metadata.table.targetMergeStrategy}</displayName><value>${metadata.table.targetMergeStrategy}</value></allowableValues><defaultValue>${metadata.table.targetMergeStrategy}</defaultValue><description>Specifies the algorithm used to merge. Valid values are SYNC,MERGE,DEDUPE_AND_MERGE.  Sync will completely overwrite the target table with the source data. Merge will append the data into the target partitions. Dedupe will insert into the target partition but ensure no duplicate rows are remaining. </description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source table</key><value><defaultValue>${metadata.category.systemName}.${metadata.systemFeedName}_valid</defaultValue><description>Fully qualified name of the source table</description><displayName>Source table</displayName><dynamic>false</dynamic><name>Source table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target table</key><value><defaultValue>${category}.${feed}</defaultValue><description>Fully qualified name of the target table</description><displayName>Target table</displayName><dynamic>false</dynamic><name>Target table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed partition value</key><value><defaultValue>${feedts}</defaultValue><description>Feed timestamp that identifies the current feed partition</description><displayName>Feed partition value</displayName><dynamic>false</dynamic><name>Feed partition value</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Specification</key><value><defaultValue>${metadata.table.partitionSpecs}</defaultValue><description>Partition specification in format: field|type|formula
field|type|formula</description><displayName>Partition Specification</displayName><dynamic>false</dynamic><name>Partition Specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>2cb29f9b-38a7-4a87-aa20-898ef552e4f9</groupId><id>cb0584e3-3921-404c-9985-46c6d293c994</id><name>MergeTable</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>Merge Strategy</key><value>${metadata.table.targetMergeStrategy}</value></entry><entry><key>Source table</key><value>${category}.${feed}_valid</value></entry><entry><key>Target table</key><value>${category}.${feed}</value></entry><entry><key>Feed partition value</key><value>${feedts}</value></entry><entry><key>Partition Specification</key><value>${metadata.table.partitionSpecs}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.MergeTable</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Strategy</key><value><allowableValues><displayName>MERGE</displayName><value>MERGE</value></allowableValues><allowableValues><displayName>DEDUPE_AND_MERGE</displayName><value>DEDUPE_AND_MERGE</value></allowableValues><allowableValues><displayName>SYNC</displayName><value>SYNC</value></allowableValues><allowableValues><displayName>${metadata.table.targetMergeStrategy}</displayName><value>${metadata.table.targetMergeStrategy}</value></allowableValues><defaultValue>${metadata.table.targetMergeStrategy}</defaultValue><description>Specifies the algorithm used to merge. Valid values are SYNC,MERGE,DEDUPE_AND_MERGE.  Sync will completely overwrite the target table with the source data. Merge will append the data into the target partitions. Dedupe will insert into the target partition but ensure no duplicate rows are remaining. </description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source table</key><value><defaultValue>${metadata.category.systemName}.${metadata.systemFeedName}_valid</defaultValue><description>Fully qualified name of the source table</description><displayName>Source table</displayName><dynamic>false</dynamic><name>Source table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target table</key><value><defaultValue>${category}.${feed}</defaultValue><description>Fully qualified name of the target table</description><displayName>Target table</displayName><dynamic>false</dynamic><name>Target table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed partition value</key><value><defaultValue>${feedts}</defaultValue><description>Feed timestamp that identifies the current feed partition</description><displayName>Feed partition value</displayName><dynamic>false</dynamic><name>Feed partition value</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Specification</key><value><defaultValue>${metadata.table.partitionSpecs}</defaultValue><description>Partition specification in format: field|type|formula
field|type|formula</description><displayName>Partition Specification</displayName><dynamic>false</dynamic><name>Partition Specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>3ebf8b9e-af39-4612-9391-0adf9ebacba4</id><name>MergeTable</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>Merge Strategy</key><value>${metadata.table.targetMergeStrategy}</value></entry><entry><key>Source table</key><value>${category}.${feed}_valid</value></entry><entry><key>Target table</key><value>${category}.${feed}</value></entry><entry><key>Feed partition value</key><value>${feedts}</value></entry><entry><key>Partition Specification</key><value>${metadata.table.partitionSpecs}</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.ingest.MergeTable</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><description>Specifies the standard table type to drop or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Additional Tables</key><value><description>Additional tables to drop separated by comma.</description><displayName>Additional Tables</displayName><dynamic>false</dynamic><name>Additional Tables</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>2d9f18e6-e10f-4e93-96fc-4f8d9601ccc7</id><name>DropFeedTables</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>System feed category</key></entry><entry><key>System feed name</key></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Additional Tables</key></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.ingest.DropFeedTables</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><defaultValue>ALL</defaultValue><description>Specifies the standard table type to create or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><defaultValue>${metadata.table.partitionStructure}</defaultValue><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Table Storage Format</key><value><defaultValue>${metadata.table.feedFormat}</defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Feed Table Storage Format</displayName><dynamic>false</dynamic><name>Feed Table Storage Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Format</key><value><defaultValue>${metadata.table.targetFormat}</defaultValue><description>Provide storage format specification for the target tables</description><displayName>Target Table Format</displayName><dynamic>false</dynamic><name>Target Table Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Properties</key><value><defaultValue>${metadata.table.targetTblProperties}</defaultValue><description>TblProperties clause generally specificying the compression option</description><displayName>Target Table Properties</displayName><dynamic>false</dynamic><name>Target Table Properties</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>32173701-c04b-40d9-ae16-6c4497b75714</id><name>Register Tables</name><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry><entry><key>Partition specification</key><value>${metadata.table.partitionStructure}</value></entry><entry><key>Feed Table Storage Format</key><value>${metadata.table.feedFormat}</value></entry><entry><key>Target Table Format</key><value>${metadata.table.targetFormat}</value></entry><entry><key>Target Table Properties</key><value>${metadata.table.targetTblProperties}</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></referencingComponents><state>ENABLED</state><type>com.thinkbiganalytics.nifi.v2.thrift.ThriftConnectionPool</type></controllerServices><controllerServices><id>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</id><comments></comments><descriptors><entry><key>Implementation</key><value><allowableValues><description>An implemenation that stores metadata locally in memory (for development-only)</description><displayName>Local, In-memory storage</displayName><value>LOCAL</value></allowableValues><allowableValues><description>An implemenation that accesses metadata via the metadata service REST API</description><displayName>REST API</displayName><value>REMOTE</value></allowableValues><defaultValue>REMOTE</defaultValue><description>Specifies which implementation of the metadata providers should be used</description><displayName>Implementation</displayName><dynamic>false</dynamic><name>Implementation</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>rest-client-url</key><value><defaultValue>http://localhost:8400/proxy/metadata</defaultValue><description>The base URL to the metadata server when the REST API client implementation is chosen.</description><displayName>REST Client URL</displayName><dynamic>false</dynamic><name>rest-client-url</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>client-username</key><value><defaultValue>dladmin</defaultValue><description>Optional user name if the client requires a credential</description><displayName>REST Client User Name</displayName><dynamic>false</dynamic><name>client-username</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>client-password</key><value><defaultValue></defaultValue><description>Optional password if the client requires a credential</description><displayName>REST Client Password</displayName><dynamic>false</dynamic><name>client-password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><name>Think Big Metadata Service</name><properties><entry><key>Implementation</key><value>REMOTE</value></entry><entry><key>rest-client-url</key><value>http://localhost:8420/api/metadata</value></entry><entry><key>client-username</key><value>dladmin</value></entry><entry><key>client-password</key></entry></properties><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Result</key><value><allowableValues><displayName>success</displayName><value>success</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>success</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Result</displayName><dynamic>false</dynamic><name>Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>63ea4dae-f086-4172-a695-04726ad93a83</groupId><id>a6557356-3e1e-43a7-ac9a-95cc7e643ad6</id><name>Record Registration</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Result</key><value>success</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.UpdateRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Result</key><value><allowableValues><displayName>success</displayName><value>success</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>success</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Result</displayName><dynamic>false</dynamic><name>Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>d2cd95b7-3404-4df2-819a-1d328475cb38</id><name>Record Registration</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Result</key><value>success</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.UpdateRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Result</key><value><allowableValues><displayName>success</displayName><value>success</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>success</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Result</displayName><dynamic>false</dynamic><name>Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>cea79fe6-a126-46b0-80ca-0da44dec95fa</groupId><id>5044e3f5-b80e-40f7-962f-d9b57f9db7d5</id><name>Record Registration</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Result</key><value>success</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.UpdateRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>2cb29f9b-38a7-4a87-aa20-898ef552e4f9</groupId><id>0f24e548-78ed-4443-b8f0-11bb7f7ecda8</id><name>Route for Registration?</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.RouteOnRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>0345b49f-13d8-4a2b-87ab-1b91fa8eabf2</groupId><id>e8761e15-44f8-4683-9756-c5a08e6eaf0e</id><name>Route for Registration?</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.RouteOnRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Result</key><value><allowableValues><displayName>success</displayName><value>success</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>success</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Result</displayName><dynamic>false</dynamic><name>Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>0345b49f-13d8-4a2b-87ab-1b91fa8eabf2</groupId><id>067a628b-6872-445f-8c91-0d3f4afe25c5</id><name>Record Registration</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Result</key><value>success</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.UpdateRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>cea79fe6-a126-46b0-80ca-0da44dec95fa</groupId><id>b95802b4-a104-478d-9f47-e3f2978944fb</id><name>Route for Registration?</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.RouteOnRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>4ab15de6-a2cd-44b9-9a54-dd0f821b2667</id><name>Route for Registration?</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.RouteOnRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Result</key><value><allowableValues><displayName>success</displayName><value>success</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>success</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Result</displayName><dynamic>false</dynamic><name>Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>2cb29f9b-38a7-4a87-aa20-898ef552e4f9</groupId><id>da1677ef-65c6-404a-bf00-a80cc8969a5e</id><name>Record Registration</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Result</key><value>success</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.UpdateRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>63ea4dae-f086-4172-a695-04726ad93a83</groupId><id>2eadfa36-ca45-40a5-8e68-fa577f3ce9da</id><name>Route for Registration?</name><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.RouteOnRegistration</type><validationErrors>'Metadata Service' validated against '30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6' is invalid because Controller Service is not valid: 'client-password' validated against '' is invalid because client-password cannot be empty</validationErrors></referencingComponents><state>ENABLED</state><type>com.thinkbiganalytics.nifi.v2.core.metadata.MetadataProviderSelectorService</type></controllerServices><controllerServices><id>4688ee71-262c-46bc-af35-9e9825507160</id><comments></comments><descriptors><entry><key>Database Connection URL</key><value><description>A database connection URL used to connect to a database. May contain database system name, host, port, database name and some parameters. The exact syntax of a database connection URL is specified by your DBMS.</description><displayName>Database Connection URL</displayName><dynamic>false</dynamic><name>Database Connection URL</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Class Name</key><value><description>Database driver class name</description><displayName>Database Driver Class Name</displayName><dynamic>false</dynamic><name>Database Driver Class Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Jar Url</key><value><description>Optional database driver jar file path url. For example 'file:///var/tmp/mariadb-java-client-1.1.7.jar'</description><displayName>Database Driver Jar Url</displayName><dynamic>false</dynamic><name>Database Driver Jar Url</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database User</key><value><description>Database user name</description><displayName>Database User</displayName><dynamic>false</dynamic><name>Database User</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Password</key><value><description>The password for the database user</description><displayName>Password</displayName><dynamic>false</dynamic><name>Password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>500 millis</defaultValue><description>The maximum amount of time that the pool will wait (when there are no available connections)  for a connection to be returned before failing, or -1 to wait indefinitely. </description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Total Connections</key><value><defaultValue>8</defaultValue><description>The maximum number of active connections that can be allocated from this pool at the same time,  or negative for no limit.</description><displayName>Max Total Connections</displayName><dynamic>false</dynamic><name>Max Total Connections</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><name>Example MySQL Connection Pool</name><properties><entry><key>Database Connection URL</key><value>jdbc:mysql://localhost</value></entry><entry><key>Database Driver Class Name</key><value>com.mysql.jdbc.Driver</value></entry><entry><key>Database Driver Jar Url</key><value>file:///opt/nifi/mysql/mysql-connector-java-5.1.32.jar</value></entry><entry><key>Database User</key><value>nifi</value></entry><entry><key>Password</key></entry><entry><key>Max Wait Time</key><value>500 millis</value></entry><entry><key>Max Total Connections</key><value>8</value></entry></properties><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Example MySQL Connection Pool</displayName><value>4688ee71-262c-46bc-af35-9e9825507160</value></allowableValues><allowableValues><displayName>MySQL</displayName><value>28ebe4b5-aeaf-4fe4-aacc-7a8aed0c7c1b</value></allowableValues><allowableValues><displayName>MySQL</displayName><value>191e02d3-ec7d-4052-aff7-00fffb2c641b</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>a253d178-c91d-4dbc-a401-e7bb6ecf5be7</id><name>Query Hive Table Metadata</name><properties><entry><key>Database Connection Pooling Service</key><value>4688ee71-262c-46bc-af35-9e9825507160</value></entry><entry><key>SQL select query</key><value>SELECT d.NAME DATABASE_NAME, d.OWNER_NAME OWNER, t.CREATE_TIME, t.TBL_NAME, t.TBL_TYPE,
    c.COLUMN_NAME, c.TYPE_NAME
    FROM hive.COLUMNS_V2 c
    JOIN  hive.TBLS t ON c.CD_ID=t.TBL_ID
    JOIN  hive.DBS d on d.DB_ID = t.DB_ID
    where d.name = '${category}'and t.tbl_name like '${feed}%';</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>RUNNING</state><type>org.apache.nifi.processors.standard.ExecuteSQL</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Example MySQL Connection Pool</displayName><value>4688ee71-262c-46bc-af35-9e9825507160</value></allowableValues><allowableValues><displayName>MySQL</displayName><value>28ebe4b5-aeaf-4fe4-aacc-7a8aed0c7c1b</value></allowableValues><allowableValues><displayName>MySQL</displayName><value>191e02d3-ec7d-4052-aff7-00fffb2c641b</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>5876ba01-d972-4e0e-a8dd-b5f6a3cb272d</groupId><id>9438b555-525a-4606-906b-b1d3697ce370</id><name>Query Hive Table Metadata</name><properties><entry><key>Database Connection Pooling Service</key><value>4688ee71-262c-46bc-af35-9e9825507160</value></entry><entry><key>SQL select query</key><value>SELECT d.NAME DATABASE_NAME, d.OWNER_NAME OWNER, t.CREATE_TIME, t.TBL_NAME, t.TBL_TYPE,
    c.COLUMN_NAME, c.TYPE_NAME
    FROM hive.COLUMNS_V2 c
    JOIN  hive.TBLS t ON c.CD_ID=t.TBL_ID
    JOIN  hive.DBS d on d.DB_ID = t.DB_ID
    where d.name = '${category}'and t.tbl_name like '${feed}%';</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>org.apache.nifi.processors.standard.ExecuteSQL</type></referencingComponents><state>ENABLED</state><type>org.apache.nifi.dbcp.DBCPConnectionPool</type></controllerServices><inputPorts><id>e1c21f55-9b61-494e-8bb7-de526920505f</id><parentGroupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</parentGroupId><position><x>9.000001822147638</x><y>97.99999945624495</y></position><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-cleanup</name><state>RUNNING</state><type>INPUT_PORT</type></inputPorts><inputPorts><id>3bbe08dc-0583-4cd8-a81e-dac4c136b89c</id><parentGroupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</parentGroupId><position><x>11.0</x><y>8.000000000000028</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-ingest</name><state>RUNNING</state><type>INPUT_PORT</type></inputPorts><processGroups><id>694df974-263b-4b80-b087-67c13a0b863a</id><parentGroupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</parentGroupId><position><x>419.0</x><y>10.0</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>e9f503bb-aa77-4a59-bf04-f7fb43419cff</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c87c2a1b-50e8-42d2-a09e-aa62094901df</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>3ebf8b9e-af39-4612-9391-0adf9ebacba4</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>4cc69cc5-4574-4202-ac25-2a29f178dd17</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c87c2a1b-50e8-42d2-a09e-aa62094901df</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>48b1d337-fda2-4170-92c8-cb9f829f8eef</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>18ce7706-e5ea-4043-beb6-f9777fc928d1</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>48b1d337-fda2-4170-92c8-cb9f829f8eef</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>4ab15de6-a2cd-44b9-9a54-dd0f821b2667</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>56c3011e-a31d-436b-b1d1-f02f53e4670a</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>ca654dff-32f6-4daf-8783-5c92099270d2</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>32173701-c04b-40d9-ae16-6c4497b75714</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>d6816a50-d45a-4d64-9bad-a5e3eb73e1ad</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>4b727d07-5b2f-4932-bc47-56d476c81deb</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>b8942599-2504-4830-8bcc-144d8ebb91e1</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>9bf2d131-ff28-42f4-b8b5-7e75a58c625d</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>48b1d337-fda2-4170-92c8-cb9f829f8eef</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>d2cd95b7-3404-4df2-819a-1d328475cb38</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>0811afc9-ed22-4028-848b-8e85521b9023</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>036c1a06-84d0-4bc7-90b0-e5585ca1ae46</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>5c000117-6237-4a85-ac0d-4ccbc3bee625</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>259d230d-780a-4142-aa05-79b020af1840</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>ca654dff-32f6-4daf-8783-5c92099270d2</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>b8942599-2504-4830-8bcc-144d8ebb91e1</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a7d9c416-bb3d-4bc5-9551-480072222cf1</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>34b70d6b-bb20-4440-85ef-190de2fc398f</id><type>OUTPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>036c1a06-84d0-4bc7-90b0-e5585ca1ae46</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>08f696be-6871-4031-874c-ebf14ea739c7</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>d2cd95b7-3404-4df2-819a-1d328475cb38</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>32173701-c04b-40d9-ae16-6c4497b75714</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a577d7a4-e1fa-4770-8250-e8d32fafdf17</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c2c1ec03-72d3-4a00-9c0e-f9c53dc932be</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>e7c79d65-18ba-467e-90ad-f89d1e0cd712</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>83afe111-992e-4466-b465-11f6a658b5a3</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c87c2a1b-50e8-42d2-a09e-aa62094901df</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>e7c79d65-18ba-467e-90ad-f89d1e0cd712</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>6cb45b9a-50dc-473e-a165-93b9856f185e</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>629310b8-a821-4b1c-81ae-b2bc6d1d0d2f</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>036c1a06-84d0-4bc7-90b0-e5585ca1ae46</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>f7f03df2-8959-4a71-afed-a4c6406583fa</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c87c2a1b-50e8-42d2-a09e-aa62094901df</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c2c1ec03-72d3-4a00-9c0e-f9c53dc932be</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>4b06c75b-337d-4896-959e-280baa4448d8</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c87c2a1b-50e8-42d2-a09e-aa62094901df</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>036c1a06-84d0-4bc7-90b0-e5585ca1ae46</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>4851c02e-f207-487c-860a-49175944f8ce</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>b8942599-2504-4830-8bcc-144d8ebb91e1</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>60c6e792-98ed-4f68-854e-69ee244ad309</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>2e9abd0b-1024-42eb-88d5-4a27d6370122</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>ca654dff-32f6-4daf-8783-5c92099270d2</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>60c6e792-98ed-4f68-854e-69ee244ad309</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>18136023-2fad-427e-9b48-a757a8498055</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>60c6e792-98ed-4f68-854e-69ee244ad309</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>registration_required</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>4ab15de6-a2cd-44b9-9a54-dd0f821b2667</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>eedc1771-71a4-471d-9067-11c29670a4a3</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>164c5f15-451e-47ca-814e-01db5eb87451</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>original</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>48b1d337-fda2-4170-92c8-cb9f829f8eef</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>58874193-eeae-4d54-a9f0-6ed29806c14b</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c87c2a1b-50e8-42d2-a09e-aa62094901df</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>5c000117-6237-4a85-ac0d-4ccbc3bee625</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>193bde46-6a91-4599-bfaa-76444f497dc1</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c87c2a1b-50e8-42d2-a09e-aa62094901df</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>164c5f15-451e-47ca-814e-01db5eb87451</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>cda2cc38-2afe-40c6-840a-a1a4fc4b8c20</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>e7c79d65-18ba-467e-90ad-f89d1e0cd712</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>48b1d337-fda2-4170-92c8-cb9f829f8eef</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>1453a290-bf3c-4cd2-8678-d211ae123747</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>2d9f18e6-e10f-4e93-96fc-4f8d9601ccc7</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>7a2bddaf-04ae-497f-84ef-a6f9ac7eaa20</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>49780e25-a01a-47e8-92fb-416bc106e191</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>aa6a1560-7ca9-4d04-9e14-25bee7ed71e2</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>2d9f18e6-e10f-4e93-96fc-4f8d9601ccc7</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>34cd74e1-237d-4a57-80d1-2fea12986acf</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>32173701-c04b-40d9-ae16-6c4497b75714</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>60c6e792-98ed-4f68-854e-69ee244ad309</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a07ed91a-5dac-4859-b58a-efa277b3ca63</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>3ebf8b9e-af39-4612-9391-0adf9ebacba4</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>036c1a06-84d0-4bc7-90b0-e5585ca1ae46</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>7226b42a-8e22-4e9e-84d9-7686cb709046</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>5c000117-6237-4a85-ac0d-4ccbc3bee625</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>c2c1ec03-72d3-4a00-9c0e-f9c53dc932be</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a9729332-f473-47fb-8557-6f5eb06a07d0</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>4ab15de6-a2cd-44b9-9a54-dd0f821b2667</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>2daacf39-62c0-4111-903c-934174b2a9a4</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>b63a7555-ab8a-4e15-ba7c-fd11fc3a8987</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>ca654dff-32f6-4daf-8783-5c92099270d2</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>4b727d07-5b2f-4932-bc47-56d476c81deb</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>2f5dac31-e675-40ed-908b-f88cd3df0720</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>35f735ff-534b-4540-a7cb-f7112ab2e41e</id><type>OUTPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>694df974-263b-4b80-b087-67c13a0b863a</groupId><id>d2cd95b7-3404-4df2-819a-1d328475cb38</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><inputPorts><id>7a2bddaf-04ae-497f-84ef-a6f9ac7eaa20</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>674.8434950761638</x><y>-4.022438423253959</y></position><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-cleanup-input-port</name><state>RUNNING</state><type>INPUT_PORT</type></inputPorts><inputPorts><id>2daacf39-62c0-4111-903c-934174b2a9a4</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>675.9736182975689</x><y>248.87579978952573</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-ingest-input-port</name><state>RUNNING</state><type>INPUT_PORT</type></inputPorts><labels><id>a4d57798-afd7-4b02-b273-9e0c164bee4c</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1567.214355417969</x><y>162.70579359555745</y></position><height>502.94512939453125</height><label>One-time registration</label><style><entry><key>background-color</key><value>#dbdbdb</value></entry><entry><key>font-size</key><value>18px</value></entry></style><width>1418.3701171875</width></labels><labels><id>a3369df5-b5cc-4bbd-9639-24c58ec4b938</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1050.155088391275</x><y>-69.3339830070997</y></position><height>154.5399932861328</height><label>Cleanup</label><style><entry><key>background-color</key><value>#dbdbdb</value></entry><entry><key>font-size</key><value>18px</value></entry></style><width>941.9580688476562</width></labels><outputPorts><id>34b70d6b-bb20-4440-85ef-190de2fc398f</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>2147.3944353736297</x><y>1626.7321889372543</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>to-elasticsearch-text-index</name><state>RUNNING</state><type>OUTPUT_PORT</type></outputPorts><outputPorts><id>35f735ff-534b-4540-a7cb-f7112ab2e41e</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>2144.3470808309935</x><y>556.6844525159124</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>to-elasticsearch-registration</name><state>RUNNING</state><type>OUTPUT_PORT</type></outputPorts><processors><id>036c1a06-84d0-4bc7-90b0-e5585ca1ae46</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1593.8314900590103</x><y>1246.8851634810044</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ApplicationJAR</key><value><description>Path to the JAR file containing the Spark job application</description><displayName>ApplicationJAR</displayName><dynamic>false</dynamic><name>ApplicationJAR</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainClass</key><value><description>Qualified classname of the Spark job application class</description><displayName>MainClass</displayName><dynamic>false</dynamic><name>MainClass</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainArgs</key><value><description>Comma separated arguments to be passed into the main as args</description><displayName>MainArgs</displayName><dynamic>false</dynamic><name>MainArgs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkMaster</key><value><defaultValue>local</defaultValue><description>The Spark master</description><displayName>SparkMaster</displayName><dynamic>false</dynamic><name>SparkMaster</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkHome</key><value><defaultValue>/usr/hdp/current/spark-client/</defaultValue><description>Qualified classname of the Spark job application class</description><displayName>SparkHome</displayName><dynamic>false</dynamic><name>SparkHome</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Driver Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the driver</description><displayName>Driver Memory</displayName><dynamic>false</dynamic><name>Driver Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the executor</description><displayName>Executor Memory</displayName><dynamic>false</dynamic><name>Executor Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Number of Executors</key><value><defaultValue>1</defaultValue><description>The number of exectors to be used</description><displayName>Number of Executors</displayName><dynamic>false</dynamic><name>Number of Executors</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Spark Application Name</key><value><description>The name of the spark application</description><displayName>Spark Application Name</displayName><dynamic>false</dynamic><name>Spark Application Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Cores</key><value><defaultValue>1</defaultValue><description>The number of executor cores to be used</description><displayName>Executor Cores</displayName><dynamic>false</dynamic><name>Executor Cores</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Network Timeout</key><value><defaultValue>120s</defaultValue><description>Default timeout for all network interactions. This config will be used in place of spark.core.connection.ack.wait.timeout, spark.akka.timeout, spark.storage.blockManagerSlaveTimeoutMs, spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.</description><displayName>Network Timeout</displayName><dynamic>false</dynamic><name>Network Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>ApplicationJAR</key><value>
    /opt/nifi/current/lib/app/thinkbig-spark-validate-cleanse-jar-with-dependencies.jar
</value></entry><entry><key>MainClass</key><value>com.thinkbiganalytics.spark.datavalidator.Validator</value></entry><entry><key>MainArgs</key><value>${category},${feed},${feedts},${table_field_policy_json_file}</value></entry><entry><key>SparkMaster</key><value>yarn-client</value></entry><entry><key>SparkHome</key><value>/usr/hdp/current/spark-client</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Driver Memory</key><value>512m</value></entry><entry><key>Executor Memory</key><value>512m</value></entry><entry><key>Number of Executors</key><value>1</value></entry><entry><key>Spark Application Name</key><value>Validator</value></entry><entry><key>Executor Cores</key><value>2</value></entry><entry><key>Network Timeout</key><value>120s</value></entry><entry><key>Hadoop Configuration Resources</key></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Validate And Split Records</name><relationships><autoTerminate>false</autoTerminate><description>Spark execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successful result.</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.spark.ExecuteSparkJob</type></processors><processors><id>c87c2a1b-50e8-42d2-a09e-aa62094901df</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1045.0428112103114</x><y>1248.0244745783584</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Directory</key><value>/tmp/${category}/${feed}/${feedts}/failed</value></entry><entry><key>Conflict Resolution Strategy</key><value>ignore</value></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Permissions</key></entry><entry><key>Owner</key></entry><entry><key>Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Failed Flow</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#fa0303</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors><processors><id>2d9f18e6-e10f-4e93-96fc-4f8d9601ccc7</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1074.0719479083898</x><y>-34.37850991355097</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><description>Specifies the standard table type to drop or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Additional Tables</key><value><description>Additional tables to drop separated by comma.</description><displayName>Additional Tables</displayName><dynamic>false</dynamic><name>Additional Tables</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>System feed category</key></entry><entry><key>System feed name</key></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Additional Tables</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>DropFeedTables</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#ff9900</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.DropFeedTables</type></processors><processors><id>aa6a1560-7ca9-4d04-9e14-25bee7ed71e2</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1661.8756452411317</x><y>-34.37850958399767</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The absolute path to the HDFS directory to be permanently deleted. One directory per line.</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key></entry><entry><key>Directory</key><value>${hdfsFolder}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>RemoveHDFSFolder</name><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that failed to be processed</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that removed a directory</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#ff9900</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.hdfs.RemoveHDFSFolder</type></processors><processors><id>b8942599-2504-4830-8bcc-144d8ebb91e1</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>2115.3770459738944</x><y>208.47006736731106</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Script Engine</key><value><allowableValues><displayName>ECMAScript</displayName><value>ECMAScript</value></allowableValues><allowableValues><displayName>Groovy</displayName><value>Groovy</value></allowableValues><allowableValues><displayName>lua</displayName><value>lua</value></allowableValues><allowableValues><displayName>python</displayName><value>python</value></allowableValues><allowableValues><displayName>ruby</displayName><value>ruby</value></allowableValues><defaultValue>ECMAScript</defaultValue><description>The engine to execute scripts</description><displayName>Script Engine</displayName><dynamic>false</dynamic><name>Script Engine</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Script File</key><value><description>Path to script file to execute. Only one of Script File or Script Body may be used</description><displayName>Script File</displayName><dynamic>false</dynamic><name>Script File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Script Body</key><value><description>Body of script to execute. Only one of Script File or Script Body may be used</description><displayName>Script Body</displayName><dynamic>false</dynamic><name>Script Body</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Module Directory</key><value><description>Comma-separated list of paths to files and/or directories which contain modules required by the script.</description><displayName>Module Directory</displayName><dynamic>false</dynamic><name>Module Directory</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Script Engine</key><value>Groovy</value></entry><entry><key>Script File</key></entry><entry><key>Script Body</key><value>def src = session.get()
if (src == null) return

def category = src.getAttribute(&quot;category&quot;)
def feed = src.getAttribute(&quot;feed&quot;)
def contents = &quot;{\&quot;hdfsFolder\&quot;: \&quot;/model.db/${category}/${feed}/\\n/etl/${category}/${feed}/\&quot;}&quot;

def dst = session.create(src)
dst = session.importFrom(new ByteArrayInputStream(contents.getBytes(&quot;UTF-8&quot;)), dst)
session.remove(src)
session.transfer(dst, REL_SUCCESS)
</value></entry><entry><key>Module Directory</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ExecuteScript</name><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that failed to be processed</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that were successfully processed</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>false</supportsParallelProcessing><type>org.apache.nifi.processors.script.ExecuteScript</type></processors><processors><id>4b727d07-5b2f-4932-bc47-56d476c81deb</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>2649.82790860549</x><y>202.03089418276414</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>URL</key><value><description>The URL to POST to. The first part of the URL must be static. However, the path of the URL may be defined using the Attribute Expression Language. For example, https://${hostname} is not valid, but https://1.1.1.1:8080/files/${nf.file.name} is valid.</description><displayName>URL</displayName><dynamic>false</dynamic><name>URL</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Batch Size</key><value><defaultValue>100 MB</defaultValue><description>If the Send as FlowFile property is true, specifies the max data size for a batch of FlowFiles to send in a single HTTP POST. If not specified, each FlowFile will be sent separately. If the Send as FlowFile property is false, this property is ignored</description><displayName>Max Batch Size</displayName><dynamic>false</dynamic><name>Max Batch Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Data to Post per Second</key><value><description>The maximum amount of data to send per second; this allows the bandwidth to be throttled to a specified data rate; if not specified, the data rate is not throttled</description><displayName>Max Data to Post per Second</displayName><dynamic>false</dynamic><name>Max Data to Post per Second</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SSL Context Service</key><value><description>The Controller Service to use in order to obtain an SSL Context</description><displayName>SSL Context Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.ssl.SSLContextService</identifiesControllerService><name>SSL Context Service</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Username</key><value><description>Username required to access the URL</description><displayName>Username</displayName><dynamic>false</dynamic><name>Username</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Password</key><value><description>Password required to access the URL</description><displayName>Password</displayName><dynamic>false</dynamic><name>Password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Send as FlowFile</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If true, will package the FlowFile's contents and attributes together and send the FlowFile Package; otherwise, will send only the FlowFile's content</description><displayName>Send as FlowFile</displayName><dynamic>false</dynamic><name>Send as FlowFile</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Use Chunked Encoding</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><description>Specifies whether or not to use Chunked Encoding to send the data. This property is ignored in the event the contents are compressed or sent as FlowFiles.</description><displayName>Use Chunked Encoding</displayName><dynamic>false</dynamic><name>Use Chunked Encoding</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression Level</key><value><defaultValue>0</defaultValue><description>Determines the GZIP Compression Level to use when sending the file; the value must be in the range of 0-9. A value of 0 indicates that the file will not be GZIP'ed</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Connection Timeout</key><value><defaultValue>30 sec</defaultValue><description>How long to wait when attempting to connect to the remote server before giving up</description><displayName>Connection Timeout</displayName><dynamic>false</dynamic><name>Connection Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Data Timeout</key><value><defaultValue>30 sec</defaultValue><description>How long to wait between receiving segments of data from the remote server before giving up and discarding the partial file</description><displayName>Data Timeout</displayName><dynamic>false</dynamic><name>Data Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attributes to Send as HTTP Headers (Regex)</key><value><description>Specifies the Regular Expression that determines the names of FlowFile attributes that should be sent as HTTP Headers</description><displayName>Attributes to Send as HTTP Headers (Regex)</displayName><dynamic>false</dynamic><name>Attributes to Send as HTTP Headers (Regex)</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>User Agent</key><value><description>What to report as the User Agent when we connect to the remote server</description><displayName>User Agent</displayName><dynamic>false</dynamic><name>User Agent</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Proxy Host</key><value><description>The fully qualified hostname or IP address of the proxy server</description><displayName>Proxy Host</displayName><dynamic>false</dynamic><name>Proxy Host</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Proxy Port</key><value><description>The port of the proxy server</description><displayName>Proxy Port</displayName><dynamic>false</dynamic><name>Proxy Port</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Content-Type</key><value><defaultValue>${mime.type}</defaultValue><description>The Content-Type to specify for the content of the FlowFile being POSTed if Send as FlowFile is false. In the case of an empty value after evaluating an expression language expression, Content-Type defaults to application/octet-stream</description><displayName>Content-Type</displayName><dynamic>false</dynamic><name>Content-Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>URL</key><value>http://localhost:8420/api/metadata/feed/${category}.${feed}/props</value></entry><entry><key>Max Batch Size</key></entry><entry><key>Max Data to Post per Second</key></entry><entry><key>SSL Context Service</key></entry><entry><key>Username</key><value>dladmin</value></entry><entry><key>Password</key></entry><entry><key>Send as FlowFile</key></entry><entry><key>Use Chunked Encoding</key><value>false</value></entry><entry><key>Compression Level</key></entry><entry><key>Connection Timeout</key></entry><entry><key>Data Timeout</key></entry><entry><key>Attributes to Send as HTTP Headers (Regex)</key></entry><entry><key>User Agent</key></entry><entry><key>Proxy Host</key></entry><entry><key>Proxy Port</key></entry><entry><key>Content-Type</key><value>application/json</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PostHTTP</name><relationships><autoTerminate>false</autoTerminate><description>Files that fail to send will transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that are successfully send will be transferred to success</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PostHTTP</type></processors><processors><id>164c5f15-451e-47ca-814e-01db5eb87451</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>541.9186720499638</x><y>685.4733547416482</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/archive/${category}/${feed}/${feedts}</value></entry><entry><key>Conflict Resolution Strategy</key><value>fail</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key></entry><entry><key>Remote Group</key></entry><entry><key>Compression codec</key><value>BZIP</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Archive Originals</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#e6f205</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>3ebf8b9e-af39-4612-9391-0adf9ebacba4</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1500.8085098559925</x><y>1668.7915133636916</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Strategy</key><value><allowableValues><displayName>MERGE</displayName><value>MERGE</value></allowableValues><allowableValues><displayName>DEDUPE_AND_MERGE</displayName><value>DEDUPE_AND_MERGE</value></allowableValues><allowableValues><displayName>SYNC</displayName><value>SYNC</value></allowableValues><allowableValues><displayName>${metadata.table.targetMergeStrategy}</displayName><value>${metadata.table.targetMergeStrategy}</value></allowableValues><defaultValue>${metadata.table.targetMergeStrategy}</defaultValue><description>Specifies the algorithm used to merge. Valid values are SYNC,MERGE,DEDUPE_AND_MERGE.  Sync will completely overwrite the target table with the source data. Merge will append the data into the target partitions. Dedupe will insert into the target partition but ensure no duplicate rows are remaining. </description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source table</key><value><defaultValue>${metadata.category.systemName}.${metadata.systemFeedName}_valid</defaultValue><description>Fully qualified name of the source table</description><displayName>Source table</displayName><dynamic>false</dynamic><name>Source table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target table</key><value><defaultValue>${category}.${feed}</defaultValue><description>Fully qualified name of the target table</description><displayName>Target table</displayName><dynamic>false</dynamic><name>Target table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed partition value</key><value><defaultValue>${feedts}</defaultValue><description>Feed timestamp that identifies the current feed partition</description><displayName>Feed partition value</displayName><dynamic>false</dynamic><name>Feed partition value</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Specification</key><value><defaultValue>${metadata.table.partitionSpecs}</defaultValue><description>Partition specification in format: field|type|formula
field|type|formula</description><displayName>Partition Specification</displayName><dynamic>false</dynamic><name>Partition Specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>Merge Strategy</key><value>${metadata.table.targetMergeStrategy}</value></entry><entry><key>Source table</key><value>${category}.${feed}_valid</value></entry><entry><key>Target table</key><value>${category}.${feed}</value></entry><entry><key>Feed partition value</key><value>${feedts}</value></entry><entry><key>Partition Specification</key><value>${metadata.table.partitionSpecs}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeTable</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.MergeTable</type></processors><processors><id>d2cd95b7-3404-4df2-819a-1d328475cb38</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1587.8399789816156</x><y>530.5414659898779</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Result</key><value><allowableValues><displayName>success</displayName><value>success</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>success</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Result</displayName><dynamic>false</dynamic><name>Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Result</key><value>success</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Record Registration</name><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.UpdateRegistration</type></processors><processors><id>e7c79d65-18ba-467e-90ad-f89d1e0cd712</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1594.117265107682</x><y>702.3368530273439</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/etl/${category}/${feed}/${feedts}</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key><value>nifi</value></entry><entry><key>Remote Group</key><value>hdfs</value></entry><entry><key>Compression codec</key><value>NONE</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutHDFS</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>4ab15de6-a2cd-44b9-9a54-dd0f821b2667</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1057.6167940389778</x><y>223.05858509360883</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>e3277508-5437-46af-bcd0-c691f4e1fcb6</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>30c2c746-ad7d-457f-a0f9-a9ecf18fd2a6</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Route for Registration?</name><relationships><autoTerminate>false</autoTerminate><description>Registration is required.</description><name>registration_required</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.RouteOnRegistration</type></processors><processors><id>629310b8-a821-4b1c-81ae-b2bc6d1d0d2f</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>2135.0784683312622</x><y>1243.4881391453346</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ApplicationJAR</key><value><description>Path to the JAR file containing the Spark job application</description><displayName>ApplicationJAR</displayName><dynamic>false</dynamic><name>ApplicationJAR</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainClass</key><value><description>Qualified classname of the Spark job application class</description><displayName>MainClass</displayName><dynamic>false</dynamic><name>MainClass</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainArgs</key><value><description>Comma separated arguments to be passed into the main as args</description><displayName>MainArgs</displayName><dynamic>false</dynamic><name>MainArgs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkMaster</key><value><defaultValue>local</defaultValue><description>The Spark master</description><displayName>SparkMaster</displayName><dynamic>false</dynamic><name>SparkMaster</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkHome</key><value><defaultValue>/usr/hdp/current/spark-client/</defaultValue><description>Qualified classname of the Spark job application class</description><displayName>SparkHome</displayName><dynamic>false</dynamic><name>SparkHome</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Driver Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the driver</description><displayName>Driver Memory</displayName><dynamic>false</dynamic><name>Driver Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the executor</description><displayName>Executor Memory</displayName><dynamic>false</dynamic><name>Executor Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Number of Executors</key><value><defaultValue>1</defaultValue><description>The number of exectors to be used</description><displayName>Number of Executors</displayName><dynamic>false</dynamic><name>Number of Executors</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Spark Application Name</key><value><description>The name of the spark application</description><displayName>Spark Application Name</displayName><dynamic>false</dynamic><name>Spark Application Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Cores</key><value><defaultValue>1</defaultValue><description>The number of executor cores to be used</description><displayName>Executor Cores</displayName><dynamic>false</dynamic><name>Executor Cores</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Network Timeout</key><value><defaultValue>120s</defaultValue><description>Default timeout for all network interactions. This config will be used in place of spark.core.connection.ack.wait.timeout, spark.akka.timeout, spark.storage.blockManagerSlaveTimeoutMs, spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.</description><displayName>Network Timeout</displayName><dynamic>false</dynamic><name>Network Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>ApplicationJAR</key><value>
    /opt/nifi/current/lib/app/thinkbig-spark-job-profiler-jar-with-dependencies.jar
</value></entry><entry><key>MainClass</key><value>com.thinkbiganalytics.spark.dataprofiler.core.Profiler</value></entry><entry><key>MainArgs</key><value>table,${category}.${feed}_valid,10,${category}.${feed}_profile,${feedts}</value></entry><entry><key>SparkMaster</key><value>yarn-client</value></entry><entry><key>SparkHome</key><value>/usr/hdp/current/spark-client</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Driver Memory</key><value>512m</value></entry><entry><key>Executor Memory</key><value>512m</value></entry><entry><key>Number of Executors</key><value>1</value></entry><entry><key>Spark Application Name</key><value>Profiler</value></entry><entry><key>Executor Cores</key><value>2</value></entry><entry><key>Network Timeout</key><value>120s</value></entry><entry><key>Hadoop Configuration Resources</key></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ProfileData</name><relationships><autoTerminate>true</autoTerminate><description>Spark execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Successful result.</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#0a70f5</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.spark.ExecuteSparkJob</type></processors><processors><id>32173701-c04b-40d9-ae16-6c4497b75714</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1586.8748009239077</x><y>367.2587270382396</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${category}</defaultValue><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${feed}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><defaultValue>ALL</defaultValue><description>Specifies the standard table type to create or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><defaultValue>${metadata.table.partitionStructure}</defaultValue><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Table Storage Format</key><value><defaultValue>${metadata.table.feedFormat}</defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Feed Table Storage Format</displayName><dynamic>false</dynamic><name>Feed Table Storage Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Format</key><value><defaultValue>${metadata.table.targetFormat}</defaultValue><description>Provide storage format specification for the target tables</description><displayName>Target Table Format</displayName><dynamic>false</dynamic><name>Target Table Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Properties</key><value><defaultValue>${metadata.table.targetTblProperties}</defaultValue><description>TblProperties clause generally specificying the compression option</description><displayName>Target Table Properties</displayName><dynamic>false</dynamic><name>Target Table Properties</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry><entry><key>Partition specification</key><value>${metadata.table.partitionStructure}</value></entry><entry><key>Feed Table Storage Format</key><value>${metadata.table.feedFormat}</value></entry><entry><key>Target Table Format</key><value>${metadata.table.targetFormat}</value></entry><entry><key>Target Table Properties</key><value>${metadata.table.targetTblProperties}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Register Tables</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></processors><processors><id>c2c1ec03-72d3-4a00-9c0e-f9c53dc932be</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1592.7796962634627</x><y>868.006262452942</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Statement</key><value><description>Provide the DDL or DML statement. Return values will be ignored.</description><displayName>Statement</displayName><dynamic>false</dynamic><name>Statement</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>Statement</key><value>alter table ${category}.${feed}_feed add
    if not exists partition (processing_dttm=${feedts})
    location '/etl/${category}/${feed}/${feedts}/'</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Create Feed Partition</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQLStatement</type></processors><processors><id>48b1d337-fda2-4170-92c8-cb9f829f8eef</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1061.1708100219007</x><y>693.3993471534774</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Merge Strategy</key><value><allowableValues><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value></allowableValues><allowableValues><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt; or alternatively (for backward compatibility purposes) &lt;segment.identifier&gt;, &lt;segment.count&gt;, and &lt;segment.index&gt;. All FlowFiles with the same value for &quot;fragment.identifier&quot; will be grouped together. All FlowFiles in this group must have the same value for the &quot;fragment.count&quot; attribute. All FlowFiles in this group must have a unique value for the &quot;fragment.index&quot; attribute between 0 and the value of the &quot;fragment.count&quot; attribute.</description><displayName>Defragment</displayName><value>Defragment</value></allowableValues><defaultValue>Bin-Packing Algorithm</defaultValue><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Format</key><value><allowableValues><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description><displayName>TAR</displayName><value>TAR</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description><displayName>ZIP</displayName><value>ZIP</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value></allowableValues><allowableValues><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value></allowableValues><allowableValues><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Avro</displayName><value>Avro</value></allowableValues><defaultValue>Binary Concatenation</defaultValue><description>Determines the format that will be used to merge the content.</description><displayName>Merge Format</displayName><dynamic>false</dynamic><name>Merge Format</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attribute Strategy</key><value><allowableValues><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value></allowableValues><allowableValues><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value></allowableValues><defaultValue>Keep Only Common Attributes</defaultValue><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><displayName>Attribute Strategy</displayName><dynamic>false</dynamic><name>Attribute Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Correlation Attribute Name</key><value><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><displayName>Correlation Attribute Name</displayName><dynamic>false</dynamic><name>Correlation Attribute Name</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Minimum Number of Entries</key><value><defaultValue>1</defaultValue><description>The minimum number of files to include in a bundle</description><displayName>Minimum Number of Entries</displayName><dynamic>false</dynamic><name>Minimum Number of Entries</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Number of Entries</key><value><description>The maximum number of files to include in a bundle. If not specified, there is no maximum.</description><displayName>Maximum Number of Entries</displayName><dynamic>false</dynamic><name>Maximum Number of Entries</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Group Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size of for the bundle</description><displayName>Minimum Group Size</displayName><dynamic>false</dynamic><name>Minimum Group Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Group Size</key><value><description>The maximum size for the bundle. If not specified, there is no maximum.</description><displayName>Maximum Group Size</displayName><dynamic>false</dynamic><name>Maximum Group Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Bin Age</key><value><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><displayName>Max Bin Age</displayName><dynamic>false</dynamic><name>Max Bin Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum number of Bins</key><value><defaultValue>100</defaultValue><description>Specifies the maximum number of bins that can be held in memory at any one time</description><displayName>Maximum number of Bins</displayName><dynamic>false</dynamic><name>Maximum number of Bins</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Delimiter Strategy</key><value><allowableValues><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description><displayName>Filename</displayName><value>Filename</value></allowableValues><allowableValues><description>The values of Header, Footer, and Demarcator will be specified as property values</description><displayName>Text</displayName><value>Text</value></allowableValues><defaultValue>Filename</defaultValue><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><displayName>Delimiter Strategy</displayName><dynamic>false</dynamic><name>Delimiter Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Header File</key><value><description>Filename specifying the header to use. If not specified, no header is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Header</displayName><dynamic>false</dynamic><name>Header File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Footer File</key><value><description>Filename specifying the footer to use. If not specified, no footer is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Footer</displayName><dynamic>false</dynamic><name>Footer File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Demarcator File</key><value><description>Filename specifying the demarcator to use. If not specified, no demarcator is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Demarcator</displayName><dynamic>false</dynamic><name>Demarcator File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Compression Level</key><value><allowableValues><displayName>0</displayName><value>0</value></allowableValues><allowableValues><displayName>1</displayName><value>1</value></allowableValues><allowableValues><displayName>2</displayName><value>2</value></allowableValues><allowableValues><displayName>3</displayName><value>3</value></allowableValues><allowableValues><displayName>4</displayName><value>4</value></allowableValues><allowableValues><displayName>5</displayName><value>5</value></allowableValues><allowableValues><displayName>6</displayName><value>6</value></allowableValues><allowableValues><displayName>7</displayName><value>7</value></allowableValues><allowableValues><displayName>8</displayName><value>8</value></allowableValues><allowableValues><displayName>9</displayName><value>9</value></allowableValues><defaultValue>1</defaultValue><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Keep Path</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names; if using other merge strategy, this value is ignored</description><displayName>Keep Path</displayName><dynamic>false</dynamic><name>Keep Path</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Merge Strategy</key><value>Bin-Packing Algorithm</value></entry><entry><key>Merge Format</key><value>Binary Concatenation</value></entry><entry><key>Attribute Strategy</key><value>Keep Only Common Attributes</value></entry><entry><key>Correlation Attribute Name</key></entry><entry><key>Minimum Number of Entries</key><value>1</value></entry><entry><key>Maximum Number of Entries</key></entry><entry><key>Minimum Group Size</key><value>0 B</value></entry><entry><key>Maximum Group Size</key></entry><entry><key>Max Bin Age</key></entry><entry><key>Maximum number of Bins</key><value>100</value></entry><entry><key>Delimiter Strategy</key><value>Text</value></entry><entry><key>Header File</key></entry><entry><key>Footer File</key></entry><entry><key>Demarcator File</key></entry><entry><key>Compression Level</key><value>1</value></entry><entry><key>Keep Path</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeContent</name><relationships><autoTerminate>false</autoTerminate><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFile containing the merged content</description><name>merged</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFiles that were used to create the bundle</description><name>original</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.MergeContent</type></processors><processors><id>5c000117-6237-4a85-ac0d-4ccbc3bee625</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1592.7054088665614</x><y>1043.3721313476562</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Script Engine</key><value><allowableValues><displayName>ECMAScript</displayName><value>ECMAScript</value></allowableValues><allowableValues><displayName>Groovy</displayName><value>Groovy</value></allowableValues><allowableValues><displayName>lua</displayName><value>lua</value></allowableValues><allowableValues><displayName>python</displayName><value>python</value></allowableValues><allowableValues><displayName>ruby</displayName><value>ruby</value></allowableValues><defaultValue>ECMAScript</defaultValue><description>The engine to execute scripts</description><displayName>Script Engine</displayName><dynamic>false</dynamic><name>Script Engine</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Script File</key><value><description>Path to script file to execute. Only one of Script File or Script Body may be used</description><displayName>Script File</displayName><dynamic>false</dynamic><name>Script File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Script Body</key><value><description>Body of script to execute. Only one of Script File or Script Body may be used</description><displayName>Script Body</displayName><dynamic>false</dynamic><name>Script Body</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Module Directory</key><value><description>Comma-separated list of paths to files and/or directories which contain modules required by the script.</description><displayName>Module Directory</displayName><dynamic>false</dynamic><name>Module Directory</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Script Engine</key><value>Groovy</value></entry><entry><key>Script File</key></entry><entry><key>Script Body</key><value>def flowFile = session.get()
    if(!flowFile) return
    def json = flowFile.getAttribute(&quot;metadata.table.fieldPoliciesJson&quot;);
    def inputFolder = flowFile.getAttribute(&quot;spark.input_folder&quot;)
    def feed = flowFile.getAttribute(&quot;feed&quot;)
    def category = flowFile.getAttribute(&quot;category&quot;)
    def feedts = flowFile.getAttribute(&quot;feedts&quot;)
    def folder = new File(inputFolder + &quot;/&quot;+category+&quot;/&quot;+feed+&quot;/&quot;+feedts)
    // If it doesn't exist
    if( !folder.exists() ) {
    // Create all folders
    folder.mkdirs()
    }
    def jsonFile = new File(folder,feed+&quot;_field_policy.json&quot;)
    jsonFile.write(json)
    flowFile = session.putAttribute(flowFile,&quot;table_field_policy_json_file&quot;,jsonFile.getCanonicalPath())
    session.transfer(flowFile, REL_SUCCESS)
</value></entry><entry><key>Module Directory</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Write field policy JSON to file</name><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that failed to be processed</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that were successfully processed</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>false</supportsParallelProcessing><type>org.apache.nifi.processors.script.ExecuteScript</type></processors><processors><id>60c6e792-98ed-4f68-854e-69ee244ad309</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>1584.2054254882844</x><y>209.25173722255272</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The full HDFS directory(s) to create separated by newline</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/model.db/${category}
    /model.db/${category}/${feed}
    /model.db/${category}/${feed}/feed
    /model.db/${category}/${feed}/valid
    /model.db/${category}/${feed}/invalid
    /model.db/${category}/${feed}/profile
    /app/warehouse/${category}/
    /app/warehouse/${category}/${feed}
    /etl/${category}
    /etl/${category}/${feed}</value></entry><entry><key>Permissions umask</key><value>777</value></entry><entry><key>Remote Owner</key><value>nifi</value></entry><entry><key>Remote Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>30 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Register HDFS Folders</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.hdfs.CreateHDFSFolder</type></processors><processors><id>ca654dff-32f6-4daf-8783-5c92099270d2</id><parentGroupId>694df974-263b-4b80-b087-67c13a0b863a</parentGroupId><position><x>2114.6922304284362</x><y>361.70515923974176</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Directory</key><value>/tmp/${category}/${feed}/${feedts}/abandoned</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Permissions</key></entry><entry><key>Owner</key></entry><entry><key>Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Aborted Registration</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style><entry><key>background-color</key><value>#fa0a1a</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>2</inputPortCount><invalidCount>2</invalidCount><name>standard-ingest</name><outputPortCount>2</outputPortCount><parent><id>1ba55d50-10e0-4009-8dc8-4820a80638e4</id><name>standard-ingest</name><parent><id>68bc830d-00ae-4b7c-9783-40cf19ba2980</id><name>reusable_templates</name><parent><id>7c664aaf-3d33-447e-89d1-457b0feb68e9</id><name>NiFi Flow</name></parent></parent></parent><runningCount>20</runningCount><stoppedCount>0</stoppedCount></processGroups><processGroups><id>1861cb4b-6891-48df-88fa-0c40dae8f55b</id><parentGroupId>1ba55d50-10e0-4009-8dc8-4820a80638e4</parentGroupId><position><x>420.0</x><y>468.0</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>a29a5d15-08db-413a-98ea-fa4c3603fbaf</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>fe767844-7407-412d-a3db-19a9ed103786</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>af570bae-e0e0-4cb2-85df-5e1df6059d9b</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>20f410fd-cd92-416c-a61b-05281bec1819</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>86488821-3bb9-4b86-94f0-9b35d057cf76</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>946919b1-ba17-41a2-b7d0-c4ab10c72cb4</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>3ffa8e46-d401-4c04-83e0-e7160d0b0c50</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>946919b1-ba17-41a2-b7d0-c4ab10c72cb4</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>matched</selectedRelationships><source><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>fe767844-7407-412d-a3db-19a9ed103786</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>5167d29f-5dc3-4411-b90c-a0e5c1202d23</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>89c7e65a-97ff-44e9-b7b5-2c1d9112f292</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>a253d178-c91d-4dbc-a401-e7bb6ecf5be7</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>5dda5a2e-694b-4fe2-935d-b90cafeeed26</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>ef24d360-8122-4bae-a372-dafaf3a86108</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>89c7e65a-97ff-44e9-b7b5-2c1d9112f292</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>bff7a48f-6b7a-4909-a354-b796c16267b4</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>a253d178-c91d-4dbc-a401-e7bb6ecf5be7</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>b3adc567-3e11-4f95-accb-3353f25d85c4</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>5a4e2505-9e85-4637-9068-c700838d0ba0</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>60940d7a-4e8c-4ee2-9846-42423556f6fc</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>86488821-3bb9-4b86-94f0-9b35d057cf76</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a1f438ff-3832-4831-b14a-6688fde5fad6</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>fc97212b-fcd9-434f-aa24-8fe1f3a5970e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</groupId><id>ef24d360-8122-4bae-a372-dafaf3a86108</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><inputPorts><id>b3adc567-3e11-4f95-accb-3353f25d85c4</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>27.578346443926307</x><y>-42.74942462782474</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>elasticsearch-register-input</name><state>RUNNING</state><type>INPUT_PORT</type></inputPorts><inputPorts><id>af570bae-e0e0-4cb2-85df-5e1df6059d9b</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>41.195438672571754</x><y>404.6720060046366</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>elasticsearch-fulltext-input</name><state>RUNNING</state><type>INPUT_PORT</type></inputPorts><labels><id>6f8acfbc-a708-4b82-9735-04a55ef728a5</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>270.7421614455693</x><y>-134.17892753865505</y></position><height>396.84320068359375</height><label>Register schema in ElasticSearch</label><style><entry><key>background-color</key><value>#bc8fff</value></entry><entry><key>font-size</key><value>18px</value></entry></style><width>869.5535888671875</width></labels><labels><id>1de1a4bc-dc90-42fe-8a9c-1c26e365b087</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>270.81927490234375</x><y>313.1640625</y></position><height>673.1553955078125</height><label>Index Elasticsearch</label><style><entry><key>font-size</key><value>18px</value></entry></style><width>575.7344970703125</width></labels><processors><id>ef24d360-8122-4bae-a372-dafaf3a86108</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>339.83258246017203</x><y>106.6443105885478</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Name Field</key><value><description>The name of the hive database field</description><displayName>Database Name Field</displayName><dynamic>false</dynamic><name>Database Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Database Owner Field</key><value><description>Database owner field name</description><displayName>Database Owner Field</displayName><dynamic>false</dynamic><name>Database Owner Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Create Time Field</key><value><description>Field representing the table create time</description><displayName>Table Create Time Field</displayName><dynamic>false</dynamic><name>Table Create Time Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Name Field</key><value><description>Field holding the table name</description><displayName>Table Name Field</displayName><dynamic>false</dynamic><name>Table Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type Field</key><value><description>Field representing what type of hive table it is</description><displayName>Table Type Field</displayName><dynamic>false</dynamic><name>Table Type Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Column Name Field</key><value><description>Field representing the column name</description><displayName>Column Name Field</displayName><dynamic>false</dynamic><name>Column Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Column Type Field</key><value><description>Field representing what the column type is</description><displayName>Column Type Field</displayName><dynamic>false</dynamic><name>Column Type Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Name Field</key><value>NAME</value></entry><entry><key>Database Owner Field</key><value>OWNER_NAME</value></entry><entry><key>Table Create Time Field</key><value>CREATE_TIME</value></entry><entry><key>Table Name Field</key><value>TBL_NAME</value></entry><entry><key>Table Type Field</key><value>TBL_TYPE</value></entry><entry><key>Column Name Field</key><value>COLUMN_NAME</value></entry><entry><key>Column Type Field</key><value>TYPE_NAME</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Merge Metadata Columns</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully merged are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Json objects that are successfully merged are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.MergeHiveTableMetadata</type></processors><processors><id>89c7e65a-97ff-44e9-b7b5-2c1d9112f292</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>757.0909138267871</x><y>-81.79882633618513</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>JSON container options</key><value><allowableValues><displayName>none</displayName><value>none</value></allowableValues><allowableValues><displayName>array</displayName><value>array</value></allowableValues><defaultValue>array</defaultValue><description>Determines how stream of records is exposed: either as a sequence of single Objects (none) (i.e. writing every Object to a new line), or as an array of Objects (array).</description><displayName>JSON container options</displayName><dynamic>false</dynamic><name>JSON container options</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Wrap Single Record</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Determines if the resulting output for empty records or a single record should be wrapped in a container array as specified by 'JSON container options'</description><displayName>Wrap Single Record</displayName><dynamic>false</dynamic><name>Wrap Single Record</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>JSON container options</key><value>array</value></entry><entry><key>Wrap Single Record</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Convert Metadata SQL to JSON</name><relationships><autoTerminate>true</autoTerminate><description>A FlowFile is routed to this relationship if it cannot be parsed as Avro or cannot be converted to JSON for any reason</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>A FlowFile is routed to this relationship after it has been converted to JSON</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.avro.ConvertAvroToJSON</type></processors><processors><id>86488821-3bb9-4b86-94f0-9b35d057cf76</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>416.58819137188243</x><y>667.5687682773951</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>JSON container options</key><value><allowableValues><displayName>none</displayName><value>none</value></allowableValues><allowableValues><displayName>array</displayName><value>array</value></allowableValues><defaultValue>array</defaultValue><description>Determines how stream of records is exposed: either as a sequence of single Objects (none) (i.e. writing every Object to a new line), or as an array of Objects (array).</description><displayName>JSON container options</displayName><dynamic>false</dynamic><name>JSON container options</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Wrap Single Record</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Determines if the resulting output for empty records or a single record should be wrapped in a container array as specified by 'JSON container options'</description><displayName>Wrap Single Record</displayName><dynamic>false</dynamic><name>Wrap Single Record</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>JSON container options</key><value>array</value></entry><entry><key>Wrap Single Record</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ConvertAvroToJSON</name><relationships><autoTerminate>true</autoTerminate><description>A FlowFile is routed to this relationship if it cannot be parsed as Avro or cannot be converted to JSON for any reason</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>A FlowFile is routed to this relationship after it has been converted to JSON</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.avro.ConvertAvroToJSON</type></processors><processors><id>60940d7a-4e8c-4ee2-9846-42423556f6fc</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>414.0225043472317</x><y>814.5763728495995</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>IndexName</key><value><description>The name of the index</description><displayName>IndexName</displayName><dynamic>false</dynamic><name>IndexName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Type</key><value><description>Elasticsearch type</description><displayName>Type</displayName><dynamic>false</dynamic><name>Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>HostName</key><value><description>Elasticsearch host</description><displayName>HostName</displayName><dynamic>false</dynamic><name>HostName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>ClusterName</key><value><description>Elasticsearch cluster</description><displayName>ClusterName</displayName><dynamic>false</dynamic><name>ClusterName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>IdField</key><value><description>Id that you want to use for indexing into elasticsearch. If it is empty then a uuid will be generated</description><displayName>IdField</displayName><dynamic>false</dynamic><name>IdField</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>IndexName</key><value>${category}</value></entry><entry><key>Type</key><value>${feed}</value></entry><entry><key>HostName</key><value>localhost</value></entry><entry><key>ClusterName</key><value>demo-cluster</value></entry><entry><key>IdField</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>IndexElasticSearch Full Text</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully indexed in elasticsearch are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Json objects that are successfully indexed in elasticsearch are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.IndexElasticSearch</type></processors><processors><id>fc97212b-fcd9-434f-aa24-8fe1f3a5970e</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>754.5156150018033</x><y>107.90421914428634</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>IndexName</key><value><description>The name of the index</description><displayName>IndexName</displayName><dynamic>false</dynamic><name>IndexName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Type</key><value><description>Elasticsearch type</description><displayName>Type</displayName><dynamic>false</dynamic><name>Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>HostName</key><value><description>Elasticsearch host</description><displayName>HostName</displayName><dynamic>false</dynamic><name>HostName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>ClusterName</key><value><description>Elasticsearch cluster</description><displayName>ClusterName</displayName><dynamic>false</dynamic><name>ClusterName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>IdField</key><value><description>Id that you want to use for indexing into elasticsearch. If it is empty then a uuid will be generated</description><displayName>IdField</displayName><dynamic>false</dynamic><name>IdField</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>IndexName</key><value>metadata</value></entry><entry><key>Type</key><value>hive-tables</value></entry><entry><key>HostName</key><value>localhost</value></entry><entry><key>ClusterName</key><value>demo-cluster</value></entry><entry><key>IdField</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Index Metadata Elasticsearch</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully indexed in elasticsearch are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Json objects that are successfully indexed in elasticsearch are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.IndexElasticSearch</type></processors><processors><id>a253d178-c91d-4dbc-a401-e7bb6ecf5be7</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>329.1402587890625</x><y>-74.8199462890625</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Example MySQL Connection Pool</displayName><value>4688ee71-262c-46bc-af35-9e9825507160</value></allowableValues><allowableValues><displayName>MySQL</displayName><value>28ebe4b5-aeaf-4fe4-aacc-7a8aed0c7c1b</value></allowableValues><allowableValues><displayName>MySQL</displayName><value>191e02d3-ec7d-4052-aff7-00fffb2c641b</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>4688ee71-262c-46bc-af35-9e9825507160</value></entry><entry><key>SQL select query</key><value>SELECT d.NAME DATABASE_NAME, d.OWNER_NAME OWNER, t.CREATE_TIME, t.TBL_NAME, t.TBL_TYPE,
    c.COLUMN_NAME, c.TYPE_NAME
    FROM hive.COLUMNS_V2 c
    JOIN  hive.TBLS t ON c.CD_ID=t.TBL_ID
    JOIN  hive.DBS d on d.DB_ID = t.DB_ID
    where d.name = '${category}'and t.tbl_name like '${feed}%';</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Query Hive Table Metadata</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from SQL query result set.</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.ExecuteSQL</type></processors><processors><id>946919b1-ba17-41a2-b7d0-c4ab10c72cb4</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>414.14337735974345</x><y>513.4959145126822</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>e4de3976-a462-4fa7-993b-82b6eaf93d39</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>81b8d7a8-8039-41ac-859e-cc25c9182319</value></entry><entry><key>SQL select query</key><value>select ${metadata.table.fieldIndexString} from ${category}.${feed}_valid where processing_dttm =
    ${feedts}</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ExecuteHQL</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from SQL query result set.</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type></processors><processors><id>fe767844-7407-412d-a3db-19a9ed103786</id><parentGroupId>1861cb4b-6891-48df-88fa-0c40dae8f55b</parentGroupId><position><x>415.22610292695094</x><y>369.71244257771014</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Routing Strategy</key><value><allowableValues><description>A copy of the FlowFile will be routed to each relationship whose corresponding expression evaluates to 'true'</description><displayName>Route to Property name</displayName><value>Route to Property name</value></allowableValues><allowableValues><description>Requires that all user-defined expressions evaluate to 'true' for the FlowFile to be considered a match</description><displayName>Route to 'matched' if all match</displayName><value>Route to 'match' if all match</value></allowableValues><allowableValues><description>Requires that at least one user-defined expression evaluate to 'true' for hte FlowFile to be considered a match</description><displayName>Route to 'matched' if any matches</displayName><value>Route to 'match' if any matches</value></allowableValues><defaultValue>Route to Property name</defaultValue><description>Specifies how to determine which relationship to use when evaluating the Expression Language</description><displayName>Routing Strategy</displayName><dynamic>false</dynamic><name>Routing Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>indexColumns</key><value><description></description><displayName>indexColumns</displayName><dynamic>true</dynamic><name>indexColumns</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Routing Strategy</key><value>Route to 'match' if all match</value></entry><entry><key>indexColumns</key><value>${metadata.table.fieldIndexString:isEmpty():not()}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>RouteOnAttribute</name><relationships><autoTerminate>false</autoTerminate><description>FlowFiles will be routed to 'match' if one or all Expressions match, depending on the configuration of the Routing Strategy property</description><name>matched</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that do not match any user-define expression will be routed here</description><name>unmatched</name></relationships><state>RUNNING</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.RouteOnAttribute</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>2</inputPortCount><invalidCount>0</invalidCount><name>index-elasticsearch</name><outputPortCount>0</outputPortCount><parent><id>1ba55d50-10e0-4009-8dc8-4820a80638e4</id><name>standard-ingest</name><parent><id>68bc830d-00ae-4b7c-9783-40cf19ba2980</id><name>reusable_templates</name><parent><id>7c664aaf-3d33-447e-89d1-457b0feb68e9</id><name>NiFi Flow</name></parent></parent></parent><runningCount>10</runningCount><stoppedCount>0</stoppedCount></processGroups></snippet><timestamp>08/23/2016 17:05:52 UTC</timestamp></template>