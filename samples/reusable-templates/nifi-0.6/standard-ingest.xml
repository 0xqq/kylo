<?xml version="1.0" encoding="UTF-8" standalone="yes"?><template><description></description><name>standard-ingest</name><snippet><connections><id>a02658c9-511c-4c02-8c71-86abaf74f915</id><parentGroupId>4effe0f1-d388-4b70-a041-5a11bb080232</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>f3490b54-b98a-4871-a9af-dc6291972949</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>4effe0f1-d388-4b70-a041-5a11bb080232</groupId><id>5d5e5a86-f539-4d2a-8de3-a0949251592c</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>3276ad67-e349-4987-912e-a07ce22ef87f</id><parentGroupId>4effe0f1-d388-4b70-a041-5a11bb080232</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><bends><x>471.4999981778524</x><y>285.5</y></bends><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>3404db61-10b5-4808-9984-e2cc5bcc7ad6</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>da1b4c0f-a545-41de-b507-baf7f9725328</id><type>OUTPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>7aed25d4-1b0f-42bf-8790-cb157c9cc73b</id><parentGroupId>4effe0f1-d388-4b70-a041-5a11bb080232</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>b0f7812c-9027-4168-96e7-f70b3696b711</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>4effe0f1-d388-4b70-a041-5a11bb080232</groupId><id>924d1846-9727-437e-8cc9-f984bd553819</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>f667fc6d-3302-4507-8807-68912c0860af</id><parentGroupId>4effe0f1-d388-4b70-a041-5a11bb080232</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>fe149e9d-71bf-48a5-808e-8a2acec106fe</id><type>INPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e1e16c88-6897-4ace-a4cb-b49948b9299a</id><type>OUTPUT_PORT</type></source><zIndex>0</zIndex></connections><controllerServices><id>0aa0b6c1-15c8-4518-9717-193854c72337</id><comments></comments><descriptors><entry><key>Implementation</key><value><allowableValues><description>An implemenation that stores metadata locally in memory (for development-only)</description><displayName>Local, In-memory storage</displayName><value>LOCAL</value></allowableValues><allowableValues><description>An implementation that accesses metadata via the metadata service REST API</description><displayName>REST API</displayName><value>REMOTE</value></allowableValues><defaultValue>REMOTE</defaultValue><description>Specifies which implementation of the metadata providers should be used</description><displayName>Implementation</displayName><dynamic>false</dynamic><name>Implementation</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>rest-client-url</key><value><defaultValue>http://localhost:8400/proxy/metadata</defaultValue><description>The base URL to the metadata server when the REST API client implementation is chosen.</description><displayName>REST Client URL</displayName><dynamic>false</dynamic><name>rest-client-url</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>client-username</key><value><defaultValue>dladmin</defaultValue><description>Optional user name if the client requires a credential</description><displayName>REST Client User Name</displayName><dynamic>false</dynamic><name>client-username</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>client-password</key><value><defaultValue></defaultValue><description>Optional password if the client requires a credential</description><displayName>REST Client Password</displayName><dynamic>false</dynamic><name>client-password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SSL Context Service</key><value><description>The Controller Service to obtain the SSL Context</description><displayName>SSL Context Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.ssl.SSLContextService</identifiesControllerService><name>SSL Context Service</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><name>Think Big Metadata Service</name><properties><entry><key>Implementation</key><value>REMOTE</value></entry><entry><key>rest-client-url</key><value>http://localhost:8400/proxy/metadata</value></entry><entry><key>client-username</key><value>dladmin</value></entry><entry><key>client-password</key></entry><entry><key>SSL Context Service</key></entry></properties><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>High-Water Mark</key><value><defaultValue>highWaterMark</defaultValue><description>The name to be given to this high-water mark, stored in the feed's metadata, which records the latest committed water mark value</description><displayName>High-Water Mark</displayName><dynamic>false</dynamic><name>High-Water Mark</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>High-Water Mark Value Property Name</key><value><defaultValue>water.mark</defaultValue><description>Name of the flow file property which is set to the current high-water mark value for use in subsequent processing and commit</description><displayName>High-Water Mark Value Property Name</displayName><dynamic>false</dynamic><name>High-Water Mark Value Property Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Mode</key><value><allowableValues><description>Commits the updates to the high-water mark(s)</description><displayName>Commit</displayName><value>COMMIT</value></allowableValues><allowableValues><description>Rejects any updates to the high-water mark(s)</description><displayName>Reject</displayName><value>REJECT</value></allowableValues><defaultValue>COMMIT</defaultValue><description>Indicates whether this processor should commit or reject high-water mark updates</description><displayName>Mode</displayName><dynamic>false</dynamic><name>Mode</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Release All</key><value><allowableValues><displayName>True</displayName><value>true</value></allowableValues><allowableValues><displayName>False</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, commits or rolls back all pending high-water marks.  Otherwise, commits/rolls back only the named water mark property.</description><displayName>Release All</displayName><dynamic>false</dynamic><name>Release All</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><name>Failed Flow - Release High Water Mark</name><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>High-Water Mark</key><value>highWaterMark</value></entry><entry><key>High-Water Mark Value Property Name</key><value>water.mark</value></entry><entry><key>Mode</key><value>REJECT</value></entry><entry><key>Release All</key><value>true</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.core.watermark.ReleaseHighWaterMark</type><validationErrors>'Metadata Service' validated against 'Think Big Metadata Service' is invalid because Controller Service MetadataProviderSelectorService[id=0aa0b6c1-15c8-4518-9717-193854c72337] is disabled</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Initialization Result</key><value><allowableValues><description>The mode indicating feed initialization was successful.</description><displayName>Successful</displayName><value>SUCCESSFUL</value></allowableValues><allowableValues><description>The mode indicating feed initialization failed.</description><displayName>Failure</displayName><value>FAILURE</value></allowableValues><description>Indicates how this processor should behave when a flow file arrives after feed initialization has failed.</description><displayName>Initialization Result</displayName><dynamic>false</dynamic><name>Initialization Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e363633a-18ca-43a2-9044-d7a74a6c141d</id><name>Initialization Failure</name><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Initialization Result</key><value>FAILURE</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.init.CompleteInitializeFeed</type><validationErrors>'Metadata Service' validated against 'Think Big Metadata Service' is invalid because Controller Service MetadataProviderSelectorService[id=0aa0b6c1-15c8-4518-9717-193854c72337] is disabled</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>High-Water Mark</key><value><defaultValue>highWaterMark</defaultValue><description>The name to be given to this high-water mark, stored in the feed's metadata, which records the latest committed water mark value</description><displayName>High-Water Mark</displayName><dynamic>false</dynamic><name>High-Water Mark</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>High-Water Mark Value Property Name</key><value><defaultValue>water.mark</defaultValue><description>Name of the flow file property which is set to the current high-water mark value for use in subsequent processing and commit</description><displayName>High-Water Mark Value Property Name</displayName><dynamic>false</dynamic><name>High-Water Mark Value Property Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Mode</key><value><allowableValues><description>Commits the updates to the high-water mark(s)</description><displayName>Commit</displayName><value>COMMIT</value></allowableValues><allowableValues><description>Rejects any updates to the high-water mark(s)</description><displayName>Reject</displayName><value>REJECT</value></allowableValues><defaultValue>COMMIT</defaultValue><description>Indicates whether this processor should commit or reject high-water mark updates</description><displayName>Mode</displayName><dynamic>false</dynamic><name>Mode</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Release All</key><value><allowableValues><displayName>True</displayName><value>true</value></allowableValues><allowableValues><displayName>False</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, commits or rolls back all pending high-water marks.  Otherwise, commits/rolls back only the named water mark property.</description><displayName>Release All</displayName><dynamic>false</dynamic><name>Release All</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>2929da33-b670-401b-835e-4d1c0e20f7b1</id><name>Commit High Water Mark</name><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>High-Water Mark</key><value>highWaterMark</value></entry><entry><key>High-Water Mark Value Property Name</key><value>water.mark</value></entry><entry><key>Mode</key><value>COMMIT</value></entry><entry><key>Release All</key><value>true</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.core.watermark.ReleaseHighWaterMark</type><validationErrors>'Metadata Service' validated against 'Think Big Metadata Service' is invalid because Controller Service MetadataProviderSelectorService[id=0aa0b6c1-15c8-4518-9717-193854c72337] is disabled</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Initialization Result</key><value><allowableValues><description>The mode indicating feed initialization was successful.</description><displayName>Successful</displayName><value>SUCCESSFUL</value></allowableValues><allowableValues><description>The mode indicating feed initialization failed.</description><displayName>Failure</displayName><value>FAILURE</value></allowableValues><description>Indicates how this processor should behave when a flow file arrives after feed initialization has failed.</description><displayName>Initialization Result</displayName><dynamic>false</dynamic><name>Initialization Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>a7716cbe-f429-41f9-817e-100235553b3f</id><name>Record Initialization</name><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Initialization Result</key><value>SUCCESSFUL</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.init.CompleteInitializeFeed</type><validationErrors>'Metadata Service' validated against 'Think Big Metadata Service' is invalid because Controller Service MetadataProviderSelectorService[id=0aa0b6c1-15c8-4518-9717-193854c72337] is disabled</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Initialization Failure Strategy</key><value><allowableValues><description>Immediately fail the flow file</description><displayName>Fail</displayName><value>FAIL</value></allowableValues><allowableValues><description>Retry initialization (if the appropriate time delay has expired) and penalize the flow file.</description><displayName>Retry</displayName><value>RETRY</value></allowableValues><defaultValue>RETRY</defaultValue><description>Indicates how this processor should behave when a flow file arrives after feed initialization has failed.</description><displayName>Initialization Failure Strategy</displayName><dynamic>false</dynamic><name>Initialization Failure Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Initialization Retry Delay (seconds)</key><value><defaultValue>60</defaultValue><description>The minimum amount of seconds to delay before an arriving flow file should trigger another attempt to initialize a feed that has previously failed initialization.  Any flow file arriving before this delay has expired will be immediately failed.</description><displayName>Initialization Retry Delay (seconds)</displayName><dynamic>false</dynamic><name>Initialization Retry Delay (seconds)</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Initialization Attempts</key><value><description>The maximum number of times initialization will be retried where there are failures.  There is no limit if unset.</description><displayName>Max Initialization Attempts</displayName><dynamic>false</dynamic><name>Max Initialization Attempts</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92640506-dbb5-446e-8dbd-d403d41030f4</id><name>Initialize Feed?</name><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Initialization Failure Strategy</key><value>RETRY</value></entry><entry><key>Initialization Retry Delay (seconds)</key><value>15</value></entry><entry><key>Max Initialization Attempts</key><value>40</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.init.InitializeFeed</type><validationErrors>'Metadata Service' validated against 'Think Big Metadata Service' is invalid because Controller Service MetadataProviderSelectorService[id=0aa0b6c1-15c8-4518-9717-193854c72337] is disabled</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Provider Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Service supplying the implementations of the various metadata providers.</description><displayName>Metadata Provider Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Provider Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Feed Category</key><value><description>They category your feed is created under</description><displayName>Feed Category</displayName><dynamic>false</dynamic><name>Feed Category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Name</key><value><description>They name of the feed</description><displayName>Feed Name</displayName><dynamic>false</dynamic><name>Feed Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Namespace</key><value><description>Namespace for the attributes you create. This value will be prepended to the attribute name for storage in the metadata store  </description><displayName>Namespace</displayName><dynamic>false</dynamic><name>Namespace</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hdfsFolders</key><value><description></description><displayName>hdfsFolders</displayName><dynamic>true</dynamic><name>hdfsFolders</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hiveSchema</key><value><description></description><displayName>hiveSchema</displayName><dynamic>true</dynamic><name>hiveSchema</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hiveTableNames</key><value><description></description><displayName>hiveTableNames</displayName><dynamic>true</dynamic><name>hiveTableNames</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>20401f7c-ef5d-4fda-acec-ec6960135416</id><name>Record Metadata</name><properties><entry><key>Metadata Provider Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>Feed Category</key><value>${category}</value></entry><entry><key>Feed Name</key><value>${feed}</value></entry><entry><key>Namespace</key><value>registration</value></entry><entry><key>hdfsFolders</key><value>${hive.ingest.root}/${category}
${hive.ingest.root}/${category}/${feed}
${hive.ingest.root}/${category}/${feed}/feed
${hive.ingest.root}/${category}/${feed}/valid
${hive.ingest.root}/${category}/${feed}/invalid
${hive.profile.root}/${category}
${hive.profile.root}/${category}/${feed}
${hive.profile.root}/${category}/${feed}/profile
${hive.master.root}/${category}/
${hive.master.root}/${category}/${feed}</value></entry><entry><key>hiveSchema</key><value>${category}</value></entry><entry><key>hiveTableNames</key><value>${feed}_feed
${feed}_valid
${feed}_invalid
${feed}_profile
${feed}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.metadata.PutFeedMetadata</type><validationErrors>'Metadata Provider Service' validated against 'Think Big Metadata Service' is invalid because Controller Service MetadataProviderSelectorService[id=0aa0b6c1-15c8-4518-9717-193854c72337] is disabled</validationErrors></referencingComponents><state>DISABLED</state><type>com.thinkbiganalytics.nifi.v2.core.metadata.MetadataProviderSelectorService</type></controllerServices><controllerServices><id>289bb069-e856-4d0e-94e9-5fbdd90424e5</id><comments></comments><descriptors><entry><key>Database Connection URL</key><value><description>A database connection URL used to connect to a database. May contain database system name, host, port, database name and some parameters. The exact syntax of a database connection URL is specified by your DBMS.</description><displayName>Database Connection URL</displayName><dynamic>false</dynamic><name>Database Connection URL</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Class Name</key><value><description>Database driver class name</description><displayName>Database Driver Class Name</displayName><dynamic>false</dynamic><name>Database Driver Class Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Jar Url</key><value><description>Optional database driver jar file path url. For example 'file:///var/tmp/mariadb-java-client-1.1.7.jar'</description><displayName>Database Driver Jar Url</displayName><dynamic>false</dynamic><name>Database Driver Jar Url</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database User</key><value><description>Database user name</description><displayName>Database User</displayName><dynamic>false</dynamic><name>Database User</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Password</key><value><description>The password for the database user</description><displayName>Password</displayName><dynamic>false</dynamic><name>Password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Validation Query</key><value><defaultValue>show tables 'test'</defaultValue><description>Query to be used when testing the Datasource. </description><displayName>Validation Query</displayName><dynamic>false</dynamic><name>Validation Query</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>500 millis</defaultValue><description>The maximum amount of time that the pool will wait (when there are no available connections)  for a connection to be returned before failing, or -1 to wait indefinitely. </description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Total Connections</key><value><defaultValue>8</defaultValue><description>The maximum number of active connections that can be allocated from this pool at the same time,  or negative for no limit.</description><displayName>Max Total Connections</displayName><dynamic>false</dynamic><name>Max Total Connections</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><name>Hive Thrift Service</name><properties><entry><key>Database Connection URL</key><value>jdbc:hive2://localhost:10000/default</value></entry><entry><key>Database Driver Class Name</key><value>org.apache.hive.jdbc.HiveDriver</value></entry><entry><key>Database Driver Jar Url</key></entry><entry><key>Database User</key><value>nifi</value></entry><entry><key>Password</key></entry><entry><key>Validation Query</key><value>show tables 'test'</value></entry><entry><key>Max Wait Time</key><value>500 millis</value></entry><entry><key>Max Total Connections</key><value>8</value></entry><entry><key>Hadoop Configuration Resources</key></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry></properties><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><defaultValue>ALL</defaultValue><description>Specifies the standard table type to create or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><defaultValue>${metadata.table.partitionStructure}</defaultValue><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Table Storage Format</key><value><defaultValue>${metadata.table.feedFormat}</defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Feed Table Storage Format</displayName><dynamic>false</dynamic><name>Feed Table Storage Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Format</key><value><defaultValue>${metadata.table.targetFormat}</defaultValue><description>Provide storage format specification for the target tables</description><displayName>Target Table Format</displayName><dynamic>false</dynamic><name>Target Table Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Properties</key><value><defaultValue>${metadata.table.targetTblProperties}</defaultValue><description>TblProperties clause generally specificying the compression option</description><displayName>Target Table Properties</displayName><dynamic>false</dynamic><name>Target Table Properties</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Root Path</key><value><defaultValue>${hive.ingest.root}</defaultValue><description>Specify the full HDFS root path for the feed,valid,invalid tables.</description><displayName>Feed Root Path</displayName><dynamic>false</dynamic><name>Feed Root Path</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Profile Root Path</key><value><defaultValue>${hive.profile.root}</defaultValue><description>Specify the HDFS folder root path for creating the profile table</description><displayName>Profile Root Path</displayName><dynamic>false</dynamic><name>Profile Root Path</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Master Root Path</key><value><defaultValue>${hive.master.root}</defaultValue><description>Specify the HDFS folder root path for creating the master table</description><displayName>Master Root Path</displayName><dynamic>false</dynamic><name>Master Root Path</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>325a8513-19e2-4c41-8234-98e1ec0a9387</id><name>Register Tables</name><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry><entry><key>Partition specification</key><value>${metadata.table.partitionStructure}</value></entry><entry><key>Feed Table Storage Format</key><value>${metadata.table.feedFormat}</value></entry><entry><key>Target Table Format</key><value>${metadata.table.targetFormat}</value></entry><entry><key>Target Table Properties</key><value>${metadata.table.targetTblProperties}</value></entry><entry><key>Feed Root Path</key><value>${hive.ingest.root}</value></entry><entry><key>Profile Root Path</key><value>${hive.profile.root}</value></entry><entry><key>Master Root Path</key><value>${hive.master.root}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type><validationErrors>'Database Connection Pooling Service' validated against 'Hive Thrift Service' is invalid because Controller Service ThriftConnectionPool[id=289bb069-e856-4d0e-94e9-5fbdd90424e5] is disabled</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>bfbea11b-7dff-4561-9f5a-c1c5f3e3df5d</id><name>Extract Feed Data</name><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>SQL select query</key><value>select ${metadata.table.fieldIndexString} from ${category}.${feed}_valid where processing_dttm =
    ${feedts}</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type><validationErrors>'Database Connection Pooling Service' validated against 'Hive Thrift Service' is invalid because Controller Service ThriftConnectionPool[id=289bb069-e856-4d0e-94e9-5fbdd90424e5] is disabled</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Statement</key><value><description>Provide the DDL or DML statement. Return values will be ignored.</description><displayName>Statement</displayName><dynamic>false</dynamic><name>Statement</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e119e2d3-39ad-43cc-83c7-2629dea25e16</id><name>Create Feed Partition</name><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>Statement</key><value>alter table `${category}`.`${feed}_feed` add
    if not exists partition (processing_dttm=${feedts})
    location '${hdfs.etl.root}/${category}/${feed}/${feedts}/'</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQLStatement</type><validationErrors>'Database Connection Pooling Service' validated against 'Hive Thrift Service' is invalid because Controller Service ThriftConnectionPool[id=289bb069-e856-4d0e-94e9-5fbdd90424e5] is disabled</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Strategy</key><value><allowableValues><displayName>MERGE</displayName><value>MERGE</value></allowableValues><allowableValues><displayName>DEDUPE_AND_MERGE</displayName><value>DEDUPE_AND_MERGE</value></allowableValues><allowableValues><displayName>PK_MERGE</displayName><value>PK_MERGE</value></allowableValues><allowableValues><displayName>SYNC</displayName><value>SYNC</value></allowableValues><allowableValues><displayName>${metadata.table.targetMergeStrategy}</displayName><value>${metadata.table.targetMergeStrategy}</value></allowableValues><defaultValue>${metadata.table.targetMergeStrategy}</defaultValue><description>Specifies the algorithm used to merge. Valid values are SYNC,MERGE,PK_MERGE,DEDUPE_AND_MERGE.  Sync will completely overwrite the target table with the source data. Merge will append the data into the target partitions. Dedupe will insert into the target partition but ensure no duplicate rows are remaining. PK Merge will insert or update existing rows matching the same primary key.</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source schema</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>Name of the schema or database for the source table</description><displayName>Source schema</displayName><dynamic>false</dynamic><name>Source schema</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source table</key><value><defaultValue>${metadata.systemFeedName}_valid</defaultValue><description>Name of the source table</description><displayName>Source table</displayName><dynamic>false</dynamic><name>Source table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target schema</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>Name of the schema or database for the target table</description><displayName>Target schema</displayName><dynamic>false</dynamic><name>Target schema</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target table</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of the target table</description><displayName>Target table</displayName><dynamic>false</dynamic><name>Target table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed partition value</key><value><defaultValue>${feedts}</defaultValue><description>Feed timestamp that identifies the current feed partition</description><displayName>Feed partition value</displayName><dynamic>false</dynamic><name>Feed partition value</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Specification</key><value><defaultValue>${metadata.table.partitionSpecs}</defaultValue><description>Partition specification in format: field|type|formula
field|type|formula</description><displayName>Partition Specification</displayName><dynamic>false</dynamic><name>Partition Specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>130f5bf5-64f5-46a2-8141-508aba4ca04e</id><name>Merge Table</name><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>Merge Strategy</key><value>${metadata.table.targetMergeStrategy}</value></entry><entry><key>Source schema</key><value>${category}</value></entry><entry><key>Source table</key><value>${feed}_valid</value></entry><entry><key>Target schema</key><value>${category}</value></entry><entry><key>Target table</key><value>${feed}</value></entry><entry><key>Feed partition value</key><value>${feedts}</value></entry><entry><key>Partition Specification</key><value>${metadata.table.partitionSpecs}</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.MergeTable</type><validationErrors>'Database Connection Pooling Service' validated against 'Hive Thrift Service' is invalid because Controller Service ThriftConnectionPool[id=289bb069-e856-4d0e-94e9-5fbdd90424e5] is disabled</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><description>Specifies the standard table type to drop or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Additional Tables</key><value><description>Additional tables to drop separated by comma.</description><displayName>Additional Tables</displayName><dynamic>false</dynamic><name>Additional Tables</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>87c072b4-1491-4686-b087-1aa41ef38696</id><name>Drop Feed Tables</name><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Additional Tables</key></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.DropFeedTables</type><validationErrors>'Database Connection Pooling Service' validated against 'Hive Thrift Service' is invalid because Controller Service ThriftConnectionPool[id=289bb069-e856-4d0e-94e9-5fbdd90424e5] is disabled</validationErrors></referencingComponents><state>DISABLED</state><type>com.thinkbiganalytics.nifi.v2.thrift.ThriftConnectionPool</type></controllerServices><controllerServices><id>8e0bd85a-9966-4b49-90f8-fed6f3649c09</id><comments></comments><descriptors><entry><key>Database Connection URL</key><value><description>A database connection URL used to connect to a database. May contain database system name, host, port, database name and some parameters. The exact syntax of a database connection URL is specified by your DBMS.</description><displayName>Database Connection URL</displayName><dynamic>false</dynamic><name>Database Connection URL</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Class Name</key><value><description>Database driver class name</description><displayName>Database Driver Class Name</displayName><dynamic>false</dynamic><name>Database Driver Class Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Jar Url</key><value><description>Optional database driver jar file path url. For example 'file:///var/tmp/mariadb-java-client-1.1.7.jar'</description><displayName>Database Driver Jar Url</displayName><dynamic>false</dynamic><name>Database Driver Jar Url</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database User</key><value><description>Database user name</description><displayName>Database User</displayName><dynamic>false</dynamic><name>Database User</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Password</key><value><description>The password for the database user</description><displayName>Password</displayName><dynamic>false</dynamic><name>Password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>500 millis</defaultValue><description>The maximum amount of time that the pool will wait (when there are no available connections)  for a connection to be returned before failing, or -1 to wait indefinitely. </description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Total Connections</key><value><defaultValue>8</defaultValue><description>The maximum number of active connections that can be allocated from this pool at the same time,  or negative for no limit.</description><displayName>Max Total Connections</displayName><dynamic>false</dynamic><name>Max Total Connections</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><name>MySQL</name><properties><entry><key>Database Connection URL</key><value>jdbc:mysql://localhost</value></entry><entry><key>Database Driver Class Name</key><value>com.mysql.jdbc.Driver</value></entry><entry><key>Database Driver Jar Url</key><value>file:///opt/nifi/mysql/mysql-connector-java-5.1.32.jar</value></entry><entry><key>Database User</key><value>root</value></entry><entry><key>Password</key></entry><entry><key>Max Wait Time</key><value>500 millis</value></entry><entry><key>Max Total Connections</key><value>8</value></entry></properties><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>MySQL</displayName><value>8e0bd85a-9966-4b49-90f8-fed6f3649c09</value></allowableValues><allowableValues><displayName>MySQL</displayName><value>f577dedb-abb3-4edf-9fe1-b9e0256279cd</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>b3e2acfa-9544-42c7-bf7d-ac28f0886c2a</id><name>Query Hive Table Metadata</name><properties><entry><key>Database Connection Pooling Service</key><value>8e0bd85a-9966-4b49-90f8-fed6f3649c09</value></entry><entry><key>SQL select query</key><value>SELECT d.NAME DATABASE_NAME, d.OWNER_NAME OWNER, t.CREATE_TIME, t.TBL_NAME, t.TBL_TYPE,
    c.COLUMN_NAME, c.TYPE_NAME
    FROM ${config.hive.schema}.COLUMNS_V2 c
    JOIN ${config.hive.schema}.SDS s on s.CD_ID = c.CD_ID
    JOIN  ${config.hive.schema}.TBLS t ON s.SD_ID=t.SD_ID
    JOIN  ${config.hive.schema}.DBS d on d.DB_ID = t.DB_ID
    where d.name = '${category}'and t.tbl_name like '${feed}%';</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>org.apache.nifi.processors.standard.ExecuteSQL</type><validationErrors>'Database Connection Pooling Service' validated against 'MySQL' is invalid because Controller Service DBCPConnectionPool[id=8e0bd85a-9966-4b49-90f8-fed6f3649c09] is disabled</validationErrors></referencingComponents><state>DISABLED</state><type>org.apache.nifi.dbcp.DBCPConnectionPool</type></controllerServices><inputPorts><id>924d1846-9727-437e-8cc9-f984bd553819</id><parentGroupId>4effe0f1-d388-4b70-a041-5a11bb080232</parentGroupId><position><x>79.0</x><y>119.99999945624495</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-cleanup</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><inputPorts><id>5d5e5a86-f539-4d2a-8de3-a0949251592c</id><parentGroupId>4effe0f1-d388-4b70-a041-5a11bb080232</parentGroupId><position><x>81.99999817785238</x><y>30.0</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-ingest</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><processGroups><id>c529c8d4-1307-4eb8-9f59-8406992e88fb</id><parentGroupId>4effe0f1-d388-4b70-a041-5a11bb080232</parentGroupId><position><x>488.9999981778524</x><y>32.0</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>98fcb0b5-cc4a-409e-bb3a-90ba87e8ed48</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>a7716cbe-f429-41f9-817e-100235553b3f</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>20401f7c-ef5d-4fda-acec-ec6960135416</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>33621f50-ad5f-4f18-b300-b8ce6474ae8c</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>6b1f04ca-5ba7-4a48-b74e-388faa990c7f</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>fa6b2cf9-6877-4d62-8946-d70dcd526559</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>8c902415-d549-45fc-a19a-097946af584e</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e363633a-18ca-43a2-9044-d7a74a6c141d</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>57ea7a90-f331-498c-9b94-cd0dcc7d74f6</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>c3871b08-9115-46f1-8a00-315bd324d0ba</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e363633a-18ca-43a2-9044-d7a74a6c141d</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>20401f7c-ef5d-4fda-acec-ec6960135416</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>be89ce62-4154-4546-ae71-fae6aea10f32</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>3e002e7f-825a-4ce2-86b7-29faab1c7038</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>1c1981cb-3ede-48ca-a085-4da9a965d072</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>b37e35bb-9293-4413-9d4d-a7b81ef2815d</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>7644b986-07a5-415c-bc93-a574ded7117d</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>ca7e9d3c-17db-4994-b1dd-b14fe2aa2076</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>f2bedbd1-5a06-4004-b292-f134e817cfa7</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>fa6b2cf9-6877-4d62-8946-d70dcd526559</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a95e9fb8-cfba-4d54-a650-02d766d05fda</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>33545455-530f-442b-b72c-b1d74be9776e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>202e7bcd-97d4-4688-a5b8-f56064e720c8</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>130f5bf5-64f5-46a2-8141-508aba4ca04e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>30b7b407-4259-4e1b-925e-76b940da1c45</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e119e2d3-39ad-43cc-83c7-2629dea25e16</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>db9dae6d-aa49-4cf4-8296-507a121e007e</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>c2a4e3b3-bf68-4599-bd1f-2953837b9ea0</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>b0f7812c-9027-4168-96e7-f70b3696b711</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>3a78ea98-4570-48fa-9ec1-051d2d98b71a</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>fa6b2cf9-6877-4d62-8946-d70dcd526559</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>33545455-530f-442b-b72c-b1d74be9776e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>8aff59fb-0207-4854-90f1-df387363578d</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>4a1817b0-ebe4-4e1c-b2b8-16f0f56cab14</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>f3490b54-b98a-4871-a9af-dc6291972949</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>9994260f-1b26-4334-9f12-cbd72be3d412</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>57ea7a90-f331-498c-9b94-cd0dcc7d74f6</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>Initialize</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92640506-dbb5-446e-8dbd-d403d41030f4</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>acb3a209-d1b9-44ce-9409-4f76a36ace5c</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>2ca9afe4-f209-458d-b225-920181760dcd</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92640506-dbb5-446e-8dbd-d403d41030f4</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>97d27907-db2d-464d-a794-3210b139be6a</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92640506-dbb5-446e-8dbd-d403d41030f4</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>bdf366e5-ce11-457a-88e8-c8498634cd27</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>205e4b40-6e80-49e5-8f3c-0e8c19b82a43</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>20401f7c-ef5d-4fda-acec-ec6960135416</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>325a8513-19e2-4c41-8234-98e1ec0a9387</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>27a8e69e-31c9-459c-892e-0732f5a00399</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>130f5bf5-64f5-46a2-8141-508aba4ca04e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>fa6b2cf9-6877-4d62-8946-d70dcd526559</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>2aeb9de3-e29d-48ed-8194-4dbb1553687d</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>ca7e9d3c-17db-4994-b1dd-b14fe2aa2076</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>2929da33-b670-401b-835e-4d1c0e20f7b1</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>5fe4c9d1-49d6-4a5e-b065-028bbf20e4bd</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>d46dc721-d8cc-4a81-ac0e-021df5767427</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>87c072b4-1491-4686-b087-1aa41ef38696</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>dd2fa770-3c15-4bb6-b8e4-afb24090faa6</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>3e002e7f-825a-4ce2-86b7-29faab1c7038</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>content</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>ac94fa4d-da5c-4882-bdf2-a33c0ee04ec0</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>1bf5f330-71ce-4a40-8aa1-9312411b7251</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>33545455-530f-442b-b72c-b1d74be9776e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e119e2d3-39ad-43cc-83c7-2629dea25e16</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a32f2c9b-cc96-4299-95d6-3af840f838cb</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>87c072b4-1491-4686-b087-1aa41ef38696</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>c2a4e3b3-bf68-4599-bd1f-2953837b9ea0</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>4a431a14-2d80-48cc-bfde-8d3270829110</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>2ca9afe4-f209-458d-b225-920181760dcd</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>14d6a735-e7d2-464e-b5f9-8f9ea39f2085</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>325a8513-19e2-4c41-8234-98e1ec0a9387</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>57ea7a90-f331-498c-9b94-cd0dcc7d74f6</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>b1a3477e-16cf-488f-a950-4c6de2730128</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>2929da33-b670-401b-835e-4d1c0e20f7b1</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>130f5bf5-64f5-46a2-8141-508aba4ca04e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>dccab7a6-017b-4b00-8f47-2e408b270d2b</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>bdf366e5-ce11-457a-88e8-c8498634cd27</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>3e002e7f-825a-4ce2-86b7-29faab1c7038</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>b4ae3573-8030-45de-8806-3d281e280f7b</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>ac94fa4d-da5c-4882-bdf2-a33c0ee04ec0</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>ff295958-678b-4db1-ad1e-bb4563c8f326</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e363633a-18ca-43a2-9044-d7a74a6c141d</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>325a8513-19e2-4c41-8234-98e1ec0a9387</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>abc8770c-3ee5-4ac7-acfd-cbaf5ff2e2e7</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>da1b4c0f-a545-41de-b507-baf7f9725328</id><type>OUTPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>fa6b2cf9-6877-4d62-8946-d70dcd526559</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>f444eed0-fd84-44a6-8e67-f80ee457539b</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e1e16c88-6897-4ace-a4cb-b49948b9299a</id><type>OUTPUT_PORT</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>20401f7c-ef5d-4fda-acec-ec6960135416</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>63eb7a80-8ea1-4698-8d55-fdeaeef73206</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92889367-1600-454c-96b6-a1399d91dd57</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>92640506-dbb5-446e-8dbd-d403d41030f4</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>c0aa2bf0-2f6a-4876-9fc5-886b12d9ddf8</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>e119e2d3-39ad-43cc-83c7-2629dea25e16</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>2ca9afe4-f209-458d-b225-920181760dcd</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>2b902aee-5b72-498a-8218-d77505ec9675</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>b37e35bb-9293-4413-9d4d-a7b81ef2815d</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>original</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>ac94fa4d-da5c-4882-bdf2-a33c0ee04ec0</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>9e2411b3-7a11-4ae8-a0a8-48e82a6dfee9</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>ac94fa4d-da5c-4882-bdf2-a33c0ee04ec0</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</groupId><id>4a1817b0-ebe4-4e1c-b2b8-16f0f56cab14</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><inputPorts><id>b0f7812c-9027-4168-96e7-f70b3696b711</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>-38.87176066114091</x><y>1372.3935943678837</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-cleanup-input-port</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><inputPorts><id>f3490b54-b98a-4871-a9af-dc6291972949</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>77.4918172645489</x><y>-345.03169189443423</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>standard-ingest-input-port</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><labels><id>011e52a6-531e-4ad0-95cf-13eeefdbefca</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1549.3709716289065</x><y>166.20070097470784</y></position><height>644.9923095703125</height><label>One-time registration</label><style><entry><key>background-color</key><value>#dbdbdb</value></entry><entry><key>font-size</key><value>18px</value></entry></style><width>925.1513671875</width></labels><labels><id>b73c5154-2b4f-4bdc-8e90-1dfd30aafadb</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>326.8277263307282</x><y>1311.1896776526903</y></position><height>153.34129333496094</height><label>Cleanup</label><style><entry><key>background-color</key><value>#dbdbdb</value></entry><entry><key>font-size</key><value>18px</value></entry></style><width>1588.0556640625</width></labels><outputPorts><id>da1b4c0f-a545-41de-b507-baf7f9725328</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1612.6629900611297</x><y>1130.5473439665511</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>to-elasticsearch-text-index</name><state>STOPPED</state><type>OUTPUT_PORT</type></outputPorts><outputPorts><id>e1e16c88-6897-4ace-a4cb-b49948b9299a</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>2168.2687116903685</x><y>566.4561810315374</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>to-elasticsearch-registration</name><state>STOPPED</state><type>OUTPUT_PORT</type></outputPorts><processors><id>b37e35bb-9293-4413-9d4d-a7b81ef2815d</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>613.3924727091435</x><y>-2.47123797266147</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/archive/${category}/${feed}/${archiveId}</value></entry><entry><key>Conflict Resolution Strategy</key><value>fail</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key></entry><entry><key>Remote Group</key></entry><entry><key>Compression codec</key><value>BZIP</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Archive Originals</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#e6f205</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>20401f7c-ef5d-4fda-acec-ec6960135416</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1587.4901370842117</x><y>530.5101658996747</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Provider Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Service supplying the implementations of the various metadata providers.</description><displayName>Metadata Provider Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Provider Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Feed Category</key><value><description>They category your feed is created under</description><displayName>Feed Category</displayName><dynamic>false</dynamic><name>Feed Category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Name</key><value><description>They name of the feed</description><displayName>Feed Name</displayName><dynamic>false</dynamic><name>Feed Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Namespace</key><value><description>Namespace for the attributes you create. This value will be prepended to the attribute name for storage in the metadata store  </description><displayName>Namespace</displayName><dynamic>false</dynamic><name>Namespace</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hdfsFolders</key><value><description></description><displayName>hdfsFolders</displayName><dynamic>true</dynamic><name>hdfsFolders</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hiveSchema</key><value><description></description><displayName>hiveSchema</displayName><dynamic>true</dynamic><name>hiveSchema</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hiveTableNames</key><value><description></description><displayName>hiveTableNames</displayName><dynamic>true</dynamic><name>hiveTableNames</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Provider Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>Feed Category</key><value>${category}</value></entry><entry><key>Feed Name</key><value>${feed}</value></entry><entry><key>Namespace</key><value>registration</value></entry><entry><key>hdfsFolders</key><value>${hive.ingest.root}/${category}
${hive.ingest.root}/${category}/${feed}
${hive.ingest.root}/${category}/${feed}/feed
${hive.ingest.root}/${category}/${feed}/valid
${hive.ingest.root}/${category}/${feed}/invalid
${hive.profile.root}/${category}
${hive.profile.root}/${category}/${feed}
${hive.profile.root}/${category}/${feed}/profile
${hive.master.root}/${category}/
${hive.master.root}/${category}/${feed}</value></entry><entry><key>hiveSchema</key><value>${category}</value></entry><entry><key>hiveTableNames</key><value>${feed}_feed
${feed}_valid
${feed}_invalid
${feed}_profile
${feed}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Record Metadata</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this relationship on failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this relationship on success</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.metadata.PutFeedMetadata</type></processors><processors><id>3e002e7f-825a-4ce2-86b7-29faab1c7038</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1058.105148669983</x><y>-192.07482719614558</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Merge Strategy</key><value><allowableValues><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value></allowableValues><allowableValues><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt; or alternatively (for backward compatibility purposes) &lt;segment.identifier&gt;, &lt;segment.count&gt;, and &lt;segment.index&gt;. All FlowFiles with the same value for &quot;fragment.identifier&quot; will be grouped together. All FlowFiles in this group must have the same value for the &quot;fragment.count&quot; attribute. All FlowFiles in this group must have a unique value for the &quot;fragment.index&quot; attribute between 0 and the value of the &quot;fragment.count&quot; attribute.</description><displayName>Defragment</displayName><value>Defragment</value></allowableValues><defaultValue>Bin-Packing Algorithm</defaultValue><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Format</key><value><allowableValues><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description><displayName>TAR</displayName><value>TAR</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description><displayName>ZIP</displayName><value>ZIP</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value></allowableValues><allowableValues><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value></allowableValues><allowableValues><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Avro</displayName><value>Avro</value></allowableValues><defaultValue>Binary Concatenation</defaultValue><description>Determines the format that will be used to merge the content.</description><displayName>Merge Format</displayName><dynamic>false</dynamic><name>Merge Format</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attribute Strategy</key><value><allowableValues><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value></allowableValues><allowableValues><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value></allowableValues><defaultValue>Keep Only Common Attributes</defaultValue><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><displayName>Attribute Strategy</displayName><dynamic>false</dynamic><name>Attribute Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Correlation Attribute Name</key><value><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><displayName>Correlation Attribute Name</displayName><dynamic>false</dynamic><name>Correlation Attribute Name</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Minimum Number of Entries</key><value><defaultValue>1</defaultValue><description>The minimum number of files to include in a bundle</description><displayName>Minimum Number of Entries</displayName><dynamic>false</dynamic><name>Minimum Number of Entries</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Number of Entries</key><value><description>The maximum number of files to include in a bundle. If not specified, there is no maximum.</description><displayName>Maximum Number of Entries</displayName><dynamic>false</dynamic><name>Maximum Number of Entries</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Group Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size of for the bundle</description><displayName>Minimum Group Size</displayName><dynamic>false</dynamic><name>Minimum Group Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Group Size</key><value><description>The maximum size for the bundle. If not specified, there is no maximum.</description><displayName>Maximum Group Size</displayName><dynamic>false</dynamic><name>Maximum Group Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Bin Age</key><value><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><displayName>Max Bin Age</displayName><dynamic>false</dynamic><name>Max Bin Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum number of Bins</key><value><defaultValue>100</defaultValue><description>Specifies the maximum number of bins that can be held in memory at any one time</description><displayName>Maximum number of Bins</displayName><dynamic>false</dynamic><name>Maximum number of Bins</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Delimiter Strategy</key><value><allowableValues><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description><displayName>Filename</displayName><value>Filename</value></allowableValues><allowableValues><description>The values of Header, Footer, and Demarcator will be specified as property values</description><displayName>Text</displayName><value>Text</value></allowableValues><defaultValue>Filename</defaultValue><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><displayName>Delimiter Strategy</displayName><dynamic>false</dynamic><name>Delimiter Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Header File</key><value><description>Filename specifying the header to use. If not specified, no header is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Header</displayName><dynamic>false</dynamic><name>Header File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Footer File</key><value><description>Filename specifying the footer to use. If not specified, no footer is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Footer</displayName><dynamic>false</dynamic><name>Footer File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Demarcator File</key><value><description>Filename specifying the demarcator to use. If not specified, no demarcator is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Demarcator</displayName><dynamic>false</dynamic><name>Demarcator File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Compression Level</key><value><allowableValues><displayName>0</displayName><value>0</value></allowableValues><allowableValues><displayName>1</displayName><value>1</value></allowableValues><allowableValues><displayName>2</displayName><value>2</value></allowableValues><allowableValues><displayName>3</displayName><value>3</value></allowableValues><allowableValues><displayName>4</displayName><value>4</value></allowableValues><allowableValues><displayName>5</displayName><value>5</value></allowableValues><allowableValues><displayName>6</displayName><value>6</value></allowableValues><allowableValues><displayName>7</displayName><value>7</value></allowableValues><allowableValues><displayName>8</displayName><value>8</value></allowableValues><allowableValues><displayName>9</displayName><value>9</value></allowableValues><defaultValue>1</defaultValue><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Keep Path</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names; if using other merge strategy, this value is ignored</description><displayName>Keep Path</displayName><dynamic>false</dynamic><name>Keep Path</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Merge Strategy</key><value>Bin-Packing Algorithm</value></entry><entry><key>Merge Format</key><value>Binary Concatenation</value></entry><entry><key>Attribute Strategy</key><value>Keep Only Common Attributes</value></entry><entry><key>Correlation Attribute Name</key><value>merge.correlation</value></entry><entry><key>Minimum Number of Entries</key><value>1</value></entry><entry><key>Maximum Number of Entries</key></entry><entry><key>Minimum Group Size</key><value>0 B</value></entry><entry><key>Maximum Group Size</key></entry><entry><key>Max Bin Age</key><value>10s</value></entry><entry><key>Maximum number of Bins</key><value>100</value></entry><entry><key>Delimiter Strategy</key><value>Text</value></entry><entry><key>Header File</key></entry><entry><key>Footer File</key></entry><entry><key>Demarcator File</key></entry><entry><key>Compression Level</key><value>1</value></entry><entry><key>Keep Path</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Merge Content</name><relationships><autoTerminate>false</autoTerminate><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFile containing the merged content</description><name>merged</name></relationships><relationships><autoTerminate>true</autoTerminate><description>The FlowFiles that were used to create the bundle</description><name>original</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.MergeContent</type></processors><processors><id>ac94fa4d-da5c-4882-bdf2-a33c0ee04ec0</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>457.9693439213929</x><y>-196.5361397520092</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Enable processing</key><value><defaultValue>false</defaultValue><description>Whether to strip the header</description><displayName>Enable processing</displayName><dynamic>false</dynamic><name>Enable processing</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Header Line Count</key><value><defaultValue>1</defaultValue><description>The number of lines that should be considered part of the header</description><displayName>Header Line Count</displayName><dynamic>false</dynamic><name>Header Line Count</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Enable processing</key><value>${skipHeader}</value></entry><entry><key>Header Line Count</key><value>1</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Strip Header</name><relationships><autoTerminate>false</autoTerminate><description>The content (stripped of header if enabled) will be routed to this destination</description><name>content</name></relationships><relationships><autoTerminate>false</autoTerminate><description>If a file cannot be split for some reason, the original file will be routed to this destination and nothing will be routed elsewhere</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>The header will be routed to this destination when header is stripped</description><name>header</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The original input file will be routed to this destination</description><name>original</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.StripHeader</type></processors><processors><id>87c072b4-1491-4686-b087-1aa41ef38696</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>947.7815426349523</x><y>1351.0929656876453</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><description>Specifies the standard table type to drop or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Additional Tables</key><value><description>Additional tables to drop separated by comma.</description><displayName>Additional Tables</displayName><dynamic>false</dynamic><name>Additional Tables</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Additional Tables</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Drop Feed Tables</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully relationship.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#ff9900</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.DropFeedTables</type></processors><processors><id>e119e2d3-39ad-43cc-83c7-2629dea25e16</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1060.7152431384627</x><y>579.5490175798951</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Statement</key><value><description>Provide the DDL or DML statement. Return values will be ignored.</description><displayName>Statement</displayName><dynamic>false</dynamic><name>Statement</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>Statement</key><value>alter table `${category}`.`${feed}_feed` add
    if not exists partition (processing_dttm=${feedts})
    location '${hdfs.etl.root}/${category}/${feed}/${feedts}/'</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Create Feed Partition</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQLStatement</type></processors><processors><id>57ea7a90-f331-498c-9b94-cd0dcc7d74f6</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1585.400615917972</x><y>209.25173722255272</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The full HDFS directory(s) to create separated by newline</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>${hive.ingest.root}/${category}
${hive.ingest.root}/${category}/${feed}
${hive.ingest.root}/${category}/${feed}/feed
${hive.ingest.root}/${category}/${feed}/valid
${hive.ingest.root}/${category}/${feed}/invalid
${hive.profile.root}/${category}
${hive.profile.root}/${category}/${feed}
${hive.profile.root}/${category}/${feed}/profile
${hive.master.root}
${hive.master.root}/${category}/
${hive.master.root}/${category}/${feed}
${hdfs.ingest.root}/${category}
${hdfs.ingest.root}/${category}/${feed}</value></entry><entry><key>Permissions umask</key><value>777</value></entry><entry><key>Remote Owner</key><value>nifi</value></entry><entry><key>Remote Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>30 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Register HDFS Folders</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.hdfs.CreateHDFSFolder</type></processors><processors><id>325a8513-19e2-4c41-8234-98e1ec0a9387</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1586.8748009239077</x><y>367.2587270382396</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type</key><value><allowableValues><displayName>FEED</displayName><value>FEED</value></allowableValues><allowableValues><displayName>VALID</displayName><value>VALID</value></allowableValues><allowableValues><displayName>INVALID</displayName><value>INVALID</value></allowableValues><allowableValues><displayName>PROFILE</displayName><value>PROFILE</value></allowableValues><allowableValues><displayName>MASTER</displayName><value>MASTER</value></allowableValues><allowableValues><displayName>ALL</displayName><value>ALL</value></allowableValues><defaultValue>ALL</defaultValue><description>Specifies the standard table type to create or ALL for standard set.</description><displayName>Table Type</displayName><dynamic>false</dynamic><name>Table Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><defaultValue>${metadata.table.partitionStructure}</defaultValue><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Table Storage Format</key><value><defaultValue>${metadata.table.feedFormat}</defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Feed Table Storage Format</displayName><dynamic>false</dynamic><name>Feed Table Storage Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Format</key><value><defaultValue>${metadata.table.targetFormat}</defaultValue><description>Provide storage format specification for the target tables</description><displayName>Target Table Format</displayName><dynamic>false</dynamic><name>Target Table Format</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target Table Properties</key><value><defaultValue>${metadata.table.targetTblProperties}</defaultValue><description>TblProperties clause generally specificying the compression option</description><displayName>Target Table Properties</displayName><dynamic>false</dynamic><name>Target Table Properties</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed Root Path</key><value><defaultValue>${hive.ingest.root}</defaultValue><description>Specify the full HDFS root path for the feed,valid,invalid tables.</description><displayName>Feed Root Path</displayName><dynamic>false</dynamic><name>Feed Root Path</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Profile Root Path</key><value><defaultValue>${hive.profile.root}</defaultValue><description>Specify the HDFS folder root path for creating the profile table</description><displayName>Profile Root Path</displayName><dynamic>false</dynamic><name>Profile Root Path</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Master Root Path</key><value><defaultValue>${hive.master.root}</defaultValue><description>Specify the HDFS folder root path for creating the master table</description><displayName>Master Root Path</displayName><dynamic>false</dynamic><name>Master Root Path</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Table Type</key><value>ALL</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry><entry><key>Partition specification</key><value>${metadata.table.partitionStructure}</value></entry><entry><key>Feed Table Storage Format</key><value>${metadata.table.feedFormat}</value></entry><entry><key>Target Table Format</key><value>${metadata.table.targetFormat}</value></entry><entry><key>Target Table Properties</key><value>${metadata.table.targetTblProperties}</value></entry><entry><key>Feed Root Path</key><value>${hive.ingest.root}</value></entry><entry><key>Profile Root Path</key><value>${hive.profile.root}</value></entry><entry><key>Master Root Path</key><value>${hive.master.root}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Register Tables</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully relationship.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></processors><processors><id>2929da33-b670-401b-835e-4d1c0e20f7b1</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>558.205779275979</x><y>1149.6884920819998</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>High-Water Mark</key><value><defaultValue>highWaterMark</defaultValue><description>The name to be given to this high-water mark, stored in the feed's metadata, which records the latest committed water mark value</description><displayName>High-Water Mark</displayName><dynamic>false</dynamic><name>High-Water Mark</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>High-Water Mark Value Property Name</key><value><defaultValue>water.mark</defaultValue><description>Name of the flow file property which is set to the current high-water mark value for use in subsequent processing and commit</description><displayName>High-Water Mark Value Property Name</displayName><dynamic>false</dynamic><name>High-Water Mark Value Property Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Mode</key><value><allowableValues><description>Commits the updates to the high-water mark(s)</description><displayName>Commit</displayName><value>COMMIT</value></allowableValues><allowableValues><description>Rejects any updates to the high-water mark(s)</description><displayName>Reject</displayName><value>REJECT</value></allowableValues><defaultValue>COMMIT</defaultValue><description>Indicates whether this processor should commit or reject high-water mark updates</description><displayName>Mode</displayName><dynamic>false</dynamic><name>Mode</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Release All</key><value><allowableValues><displayName>True</displayName><value>true</value></allowableValues><allowableValues><displayName>False</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, commits or rolls back all pending high-water marks.  Otherwise, commits/rolls back only the named water mark property.</description><displayName>Release All</displayName><dynamic>false</dynamic><name>Release All</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>High-Water Mark</key><value>highWaterMark</value></entry><entry><key>High-Water Mark Value Property Name</key><value>water.mark</value></entry><entry><key>Mode</key><value>COMMIT</value></entry><entry><key>Release All</key><value>true</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Commit High Water Mark</name><relationships><autoTerminate>false</autoTerminate><description>Processing failed</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Processing was successful</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.core.watermark.ReleaseHighWaterMark</type></processors><processors><id>4a1817b0-ebe4-4e1c-b2b8-16f0f56cab14</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>455.42621063086006</x><y>-372.00732395857494</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Delete Attributes Expression</key><value><description>Regular expression for attributes to be deleted from flowfiles.</description><displayName>Delete Attributes Expression</displayName><dynamic>false</dynamic><name>Delete Attributes Expression</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hdfs.ingest.root</key><value><description></description><displayName>hdfs.ingest.root</displayName><dynamic>true</dynamic><name>hdfs.ingest.root</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hive.ingest.root</key><value><description></description><displayName>hive.ingest.root</displayName><dynamic>true</dynamic><name>hive.ingest.root</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hive.master.root</key><value><description></description><displayName>hive.master.root</displayName><dynamic>true</dynamic><name>hive.master.root</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hive.profile.root</key><value><description></description><displayName>hive.profile.root</displayName><dynamic>true</dynamic><name>hive.profile.root</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>merge.correlation</key><value><description></description><displayName>merge.correlation</displayName><dynamic>true</dynamic><name>merge.correlation</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>skipHeader</key><value><description></description><displayName>skipHeader</displayName><dynamic>true</dynamic><name>skipHeader</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Delete Attributes Expression</key></entry><entry><key>hdfs.ingest.root</key><value>${hdfs.ingest.root:replaceEmpty('/etl')}</value></entry><entry><key>hive.ingest.root</key><value>${hive.ingest.root:replaceEmpty('/model.db')}</value></entry><entry><key>hive.master.root</key><value>${hive.master.root:replaceEmpty('/app/warehouse')}</value></entry><entry><key>hive.profile.root</key><value>${hive.profile.root:replaceEmpty('/model.db')}</value></entry><entry><key>merge.correlation</key><value>${category}.${feed}.correlation</value></entry><entry><key>skipHeader</key><value>${skipHeader:replaceEmpty('false')}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Set Feed Defaults</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.attributes.UpdateAttribute</type></processors><processors><id>d46dc721-d8cc-4a81-ac0e-021df5767427</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1535.5852399676942</x><y>1351.0929660171987</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The absolute path to the HDFS directory to be permanently deleted. One directory per line.</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>${hive.ingest.root}/${category}/${feed}/
${hive.master.root}/${category}/${feed}/
${hive.profile.root}/${category}/${feed}/
${hfds.ingest.root}/${category}/${feed}/</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Remove HDFS Folders</name><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that failed to be processed</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that removed a directory</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#ff9900</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.hdfs.RemoveHDFSFolder</type></processors><processors><id>92889367-1600-454c-96b6-a1399d91dd57</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>459.8823506214392</x><y>559.7483354032479</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>High-Water Mark</key><value><defaultValue>highWaterMark</defaultValue><description>The name to be given to this high-water mark, stored in the feed's metadata, which records the latest committed water mark value</description><displayName>High-Water Mark</displayName><dynamic>false</dynamic><name>High-Water Mark</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>High-Water Mark Value Property Name</key><value><defaultValue>water.mark</defaultValue><description>Name of the flow file property which is set to the current high-water mark value for use in subsequent processing and commit</description><displayName>High-Water Mark Value Property Name</displayName><dynamic>false</dynamic><name>High-Water Mark Value Property Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Mode</key><value><allowableValues><description>Commits the updates to the high-water mark(s)</description><displayName>Commit</displayName><value>COMMIT</value></allowableValues><allowableValues><description>Rejects any updates to the high-water mark(s)</description><displayName>Reject</displayName><value>REJECT</value></allowableValues><defaultValue>COMMIT</defaultValue><description>Indicates whether this processor should commit or reject high-water mark updates</description><displayName>Mode</displayName><dynamic>false</dynamic><name>Mode</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Release All</key><value><allowableValues><displayName>True</displayName><value>true</value></allowableValues><allowableValues><displayName>False</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, commits or rolls back all pending high-water marks.  Otherwise, commits/rolls back only the named water mark property.</description><displayName>Release All</displayName><dynamic>false</dynamic><name>Release All</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>High-Water Mark</key><value>highWaterMark</value></entry><entry><key>High-Water Mark Value Property Name</key><value>water.mark</value></entry><entry><key>Mode</key><value>REJECT</value></entry><entry><key>Release All</key><value>true</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Failed Flow - Release High Water Mark</name><relationships><autoTerminate>false</autoTerminate><description>Processing failed</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Processing was successful</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.core.watermark.ReleaseHighWaterMark</type></processors><processors><id>ca7e9d3c-17db-4994-b1dd-b14fe2aa2076</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>-101.03176230653435</x><y>561.8807367853897</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Directory</key><value>/tmp/${category}/${feed}/${feedts}/failed</value></entry><entry><key>Conflict Resolution Strategy</key><value>ignore</value></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Permissions</key></entry><entry><key>Owner</key></entry><entry><key>Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Failed Flow</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#fa0303</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors><processors><id>33545455-530f-442b-b72c-b1d74be9776e</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1061.9002330853114</x><y>752.5559387207031</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Script Engine</key><value><allowableValues><displayName>ECMAScript</displayName><value>ECMAScript</value></allowableValues><allowableValues><displayName>Groovy</displayName><value>Groovy</value></allowableValues><allowableValues><displayName>lua</displayName><value>lua</value></allowableValues><allowableValues><displayName>python</displayName><value>python</value></allowableValues><allowableValues><displayName>ruby</displayName><value>ruby</value></allowableValues><defaultValue>ECMAScript</defaultValue><description>The engine to execute scripts</description><displayName>Script Engine</displayName><dynamic>false</dynamic><name>Script Engine</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Script File</key><value><description>Path to script file to execute. Only one of Script File or Script Body may be used</description><displayName>Script File</displayName><dynamic>false</dynamic><name>Script File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Script Body</key><value><description>Body of script to execute. Only one of Script File or Script Body may be used</description><displayName>Script Body</displayName><dynamic>false</dynamic><name>Script Body</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Module Directory</key><value><description>Comma-separated list of paths to files and/or directories which contain modules required by the script.</description><displayName>Module Directory</displayName><dynamic>false</dynamic><name>Module Directory</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Script Engine</key><value>Groovy</value></entry><entry><key>Script File</key></entry><entry><key>Script Body</key><value>def flowFile = session.get()
    if(!flowFile) return
    def json = flowFile.getAttribute(&quot;metadata.table.fieldPoliciesJson&quot;);
    def inputFolder = flowFile.getAttribute(&quot;spark.input_folder&quot;)
    def feed = flowFile.getAttribute(&quot;feed&quot;)
    def category = flowFile.getAttribute(&quot;category&quot;)
    def feedts = flowFile.getAttribute(&quot;feedts&quot;)
    def folder = new File(inputFolder + &quot;/&quot;+category+&quot;/&quot;+feed+&quot;/&quot;+feedts)
    // If it doesn't exist
    if( !folder.exists() ) {
    // Create all folders
    folder.mkdirs()
    }
    def jsonFile = new File(folder,feed+&quot;_field_policy.json&quot;)
    jsonFile.write(json)
    flowFile = session.putAttribute(flowFile,&quot;table_field_policy_json_file&quot;,jsonFile.getCanonicalPath())
    session.transfer(flowFile, REL_SUCCESS)
</value></entry><entry><key>Module Directory</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Fetch field policies</name><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that failed to be processed</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that were successfully processed</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>false</supportsParallelProcessing><type>org.apache.nifi.processors.script.ExecuteScript</type></processors><processors><id>2ca9afe4-f209-458d-b225-920181760dcd</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1057.312821748307</x><y>395.74139404296886</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>${hdfs.etl.root}/${category}/${feed}/${feedts}</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key><value>nifi</value></entry><entry><key>Remote Group</key><value>hdfs</value></entry><entry><key>Compression codec</key><value>NONE</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Upload to HDFS</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>e363633a-18ca-43a2-9044-d7a74a6c141d</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>2148.2373487202385</x><y>378.5362986274255</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Initialization Result</key><value><allowableValues><description>The mode indicating feed initialization was successful.</description><displayName>Successful</displayName><value>SUCCESSFUL</value></allowableValues><allowableValues><description>The mode indicating feed initialization failed.</description><displayName>Failure</displayName><value>FAILURE</value></allowableValues><description>Indicates how this processor should behave when a flow file arrives after feed initialization has failed.</description><displayName>Initialization Result</displayName><dynamic>false</dynamic><name>Initialization Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Initialization Result</key><value>FAILURE</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Initialization Failure</name><relationships><autoTerminate>true</autoTerminate><description>Processing failed</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Processing was successful</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#fa0303</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.init.CompleteInitializeFeed</type></processors><processors><id>bdf366e5-ce11-457a-88e8-c8498634cd27</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1058.7969933338666</x><y>18.894415442125478</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Delete Attributes Expression</key><value><description>Regular expression for attributes to be deleted from flowfiles.</description><displayName>Delete Attributes Expression</displayName><dynamic>false</dynamic><name>Delete Attributes Expression</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>feedts</key><value><description></description><displayName>feedts</displayName><dynamic>true</dynamic><name>feedts</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Delete Attributes Expression</key></entry><entry><key>feedts</key><value>${now():format('yyyyMMddHHmmss')}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>UpdateTimestamp</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.attributes.UpdateAttribute</type></processors><processors><id>6b1f04ca-5ba7-4a48-b74e-388faa990c7f</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1604.0762710656372</x><y>954.4124250340064</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ApplicationJAR</key><value><description>Path to the JAR file containing the Spark job application</description><displayName>ApplicationJAR</displayName><dynamic>false</dynamic><name>ApplicationJAR</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Extra JARs</key><value><description>A file or a list of files separated by comma which should be added to the class path</description><displayName>Extra JARs</displayName><dynamic>false</dynamic><name>Extra JARs</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainClass</key><value><description>Qualified classname of the Spark job application class</description><displayName>MainClass</displayName><dynamic>false</dynamic><name>MainClass</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainArgs</key><value><description>Comma separated arguments to be passed into the main as args</description><displayName>MainArgs</displayName><dynamic>false</dynamic><name>MainArgs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkMaster</key><value><defaultValue>local</defaultValue><description>The Spark master</description><displayName>SparkMaster</displayName><dynamic>false</dynamic><name>SparkMaster</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkHome</key><value><defaultValue>/usr/hdp/current/spark-client/</defaultValue><description>Qualified classname of the Spark job application class</description><displayName>SparkHome</displayName><dynamic>false</dynamic><name>SparkHome</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Driver Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the driver</description><displayName>Driver Memory</displayName><dynamic>false</dynamic><name>Driver Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the executor</description><displayName>Executor Memory</displayName><dynamic>false</dynamic><name>Executor Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Number of Executors</key><value><defaultValue>1</defaultValue><description>The number of exectors to be used</description><displayName>Number of Executors</displayName><dynamic>false</dynamic><name>Number of Executors</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Spark Application Name</key><value><description>The name of the spark application</description><displayName>Spark Application Name</displayName><dynamic>false</dynamic><name>Spark Application Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Cores</key><value><defaultValue>1</defaultValue><description>The number of executor cores to be used</description><displayName>Executor Cores</displayName><dynamic>false</dynamic><name>Executor Cores</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Network Timeout</key><value><defaultValue>120s</defaultValue><description>Default timeout for all network interactions. This config will be used in place of spark.core.connection.ack.wait.timeout, spark.akka.timeout, spark.storage.blockManagerSlaveTimeoutMs, spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.</description><displayName>Network Timeout</displayName><dynamic>false</dynamic><name>Network Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Yarn Queue</key><value><description>Optional Yarn Queue</description><displayName>Yarn Queue</displayName><dynamic>false</dynamic><name>Yarn Queue</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>ApplicationJAR</key><value>
    /opt/nifi/current/lib/app/thinkbig-spark-job-profiler-jar-with-dependencies.jar
</value></entry><entry><key>Extra JARs</key></entry><entry><key>MainClass</key><value>com.thinkbiganalytics.spark.dataprofiler.core.Profiler</value></entry><entry><key>MainArgs</key><value>table,${category}.${feed}_valid,10,${category}.${feed}_profile,${feedts}</value></entry><entry><key>SparkMaster</key><value>yarn-client</value></entry><entry><key>SparkHome</key><value>/usr/hdp/current/spark-client</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Driver Memory</key><value>512m</value></entry><entry><key>Executor Memory</key><value>512m</value></entry><entry><key>Number of Executors</key><value>1</value></entry><entry><key>Spark Application Name</key><value>Profiler</value></entry><entry><key>Executor Cores</key><value>2</value></entry><entry><key>Network Timeout</key><value>120s</value></entry><entry><key>Hadoop Configuration Resources</key></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Yarn Queue</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Profile Data</name><relationships><autoTerminate>true</autoTerminate><description>Spark execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Successful result.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#0a70f5</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.spark.ExecuteSparkJob</type></processors><processors><id>92640506-dbb5-446e-8dbd-d403d41030f4</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1060.6195296514786</x><y>208.82014023542027</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Initialization Failure Strategy</key><value><allowableValues><description>Immediately fail the flow file</description><displayName>Fail</displayName><value>FAIL</value></allowableValues><allowableValues><description>Retry initialization (if the appropriate time delay has expired) and penalize the flow file.</description><displayName>Retry</displayName><value>RETRY</value></allowableValues><defaultValue>RETRY</defaultValue><description>Indicates how this processor should behave when a flow file arrives after feed initialization has failed.</description><displayName>Initialization Failure Strategy</displayName><dynamic>false</dynamic><name>Initialization Failure Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Initialization Retry Delay (seconds)</key><value><defaultValue>60</defaultValue><description>The minimum amount of seconds to delay before an arriving flow file should trigger another attempt to initialize a feed that has previously failed initialization.  Any flow file arriving before this delay has expired will be immediately failed.</description><displayName>Initialization Retry Delay (seconds)</displayName><dynamic>false</dynamic><name>Initialization Retry Delay (seconds)</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Initialization Attempts</key><value><description>The maximum number of times initialization will be retried where there are failures.  There is no limit if unset.</description><displayName>Max Initialization Attempts</displayName><dynamic>false</dynamic><name>Max Initialization Attempts</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Initialization Failure Strategy</key><value>RETRY</value></entry><entry><key>Initialization Retry Delay (seconds)</key><value>15</value></entry><entry><key>Max Initialization Attempts</key><value>40</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Initialize Feed?</name><relationships><autoTerminate>false</autoTerminate><description>Processing failed</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Begin initialization</description><name>Initialize</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Processing was successful</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.init.InitializeFeed</type></processors><processors><id>c2a4e3b3-bf68-4599-bd1f-2953837b9ea0</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>348.3354215739121</x><y>1353.661453353635</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Delete Attributes Expression</key><value><description>Regular expression for attributes to be deleted from flowfiles.</description><displayName>Delete Attributes Expression</displayName><dynamic>false</dynamic><name>Delete Attributes Expression</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hdfs.ingest.root</key><value><description></description><displayName>hdfs.ingest.root</displayName><dynamic>true</dynamic><name>hdfs.ingest.root</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hive.ingest.root</key><value><description></description><displayName>hive.ingest.root</displayName><dynamic>true</dynamic><name>hive.ingest.root</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hive.master.root</key><value><description></description><displayName>hive.master.root</displayName><dynamic>true</dynamic><name>hive.master.root</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>hive.profile.root</key><value><description></description><displayName>hive.profile.root</displayName><dynamic>true</dynamic><name>hive.profile.root</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Delete Attributes Expression</key></entry><entry><key>hdfs.ingest.root</key><value>${hdfs.ingest.root:replaceEmpty('/etl')}</value></entry><entry><key>hive.ingest.root</key><value>${hive.ingest.root:replaceEmpty('/model.db')}</value></entry><entry><key>hive.master.root</key><value>${hive.master.root:replaceEmpty('/app/warehouse')}</value></entry><entry><key>hive.profile.root</key><value>${hive.profile.root:replaceEmpty('/model.db')}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Set Cleanup Defaults</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.attributes.UpdateAttribute</type></processors><processors><id>fa6b2cf9-6877-4d62-8946-d70dcd526559</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1062.8292927933853</x><y>939.9808360884263</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ApplicationJAR</key><value><description>Path to the JAR file containing the Spark job application</description><displayName>ApplicationJAR</displayName><dynamic>false</dynamic><name>ApplicationJAR</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Extra JARs</key><value><description>A file or a list of files separated by comma which should be added to the class path</description><displayName>Extra JARs</displayName><dynamic>false</dynamic><name>Extra JARs</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainClass</key><value><description>Qualified classname of the Spark job application class</description><displayName>MainClass</displayName><dynamic>false</dynamic><name>MainClass</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainArgs</key><value><description>Comma separated arguments to be passed into the main as args</description><displayName>MainArgs</displayName><dynamic>false</dynamic><name>MainArgs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkMaster</key><value><defaultValue>local</defaultValue><description>The Spark master</description><displayName>SparkMaster</displayName><dynamic>false</dynamic><name>SparkMaster</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkHome</key><value><defaultValue>/usr/hdp/current/spark-client/</defaultValue><description>Qualified classname of the Spark job application class</description><displayName>SparkHome</displayName><dynamic>false</dynamic><name>SparkHome</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Driver Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the driver</description><displayName>Driver Memory</displayName><dynamic>false</dynamic><name>Driver Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the executor</description><displayName>Executor Memory</displayName><dynamic>false</dynamic><name>Executor Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Number of Executors</key><value><defaultValue>1</defaultValue><description>The number of exectors to be used</description><displayName>Number of Executors</displayName><dynamic>false</dynamic><name>Number of Executors</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Spark Application Name</key><value><description>The name of the spark application</description><displayName>Spark Application Name</displayName><dynamic>false</dynamic><name>Spark Application Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Cores</key><value><defaultValue>1</defaultValue><description>The number of executor cores to be used</description><displayName>Executor Cores</displayName><dynamic>false</dynamic><name>Executor Cores</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Network Timeout</key><value><defaultValue>120s</defaultValue><description>Default timeout for all network interactions. This config will be used in place of spark.core.connection.ack.wait.timeout, spark.akka.timeout, spark.storage.blockManagerSlaveTimeoutMs, spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.</description><displayName>Network Timeout</displayName><dynamic>false</dynamic><name>Network Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties.</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Yarn Queue</key><value><description>Optional Yarn Queue</description><displayName>Yarn Queue</displayName><dynamic>false</dynamic><name>Yarn Queue</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>ApplicationJAR</key><value>
    /opt/nifi/current/lib/app/thinkbig-spark-validate-cleanse-jar-with-dependencies.jar
</value></entry><entry><key>Extra JARs</key></entry><entry><key>MainClass</key><value>com.thinkbiganalytics.spark.datavalidator.Validator</value></entry><entry><key>MainArgs</key><value>${category},${feed},${feedts},${table_field_policy_json_file}</value></entry><entry><key>SparkMaster</key><value>yarn-client</value></entry><entry><key>SparkHome</key><value>/usr/hdp/current/spark-client</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Driver Memory</key><value>512m</value></entry><entry><key>Executor Memory</key><value>512m</value></entry><entry><key>Number of Executors</key><value>1</value></entry><entry><key>Spark Application Name</key><value>Validator</value></entry><entry><key>Executor Cores</key><value>1</value></entry><entry><key>Network Timeout</key><value>120s</value></entry><entry><key>Hadoop Configuration Resources</key></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Yarn Queue</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Validate And Split Records</name><relationships><autoTerminate>false</autoTerminate><description>Spark execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successful result.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.spark.ExecuteSparkJob</type></processors><processors><id>130f5bf5-64f5-46a2-8141-508aba4ca04e</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1062.63455966068</x><y>1154.6928500336135</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Strategy</key><value><allowableValues><displayName>MERGE</displayName><value>MERGE</value></allowableValues><allowableValues><displayName>DEDUPE_AND_MERGE</displayName><value>DEDUPE_AND_MERGE</value></allowableValues><allowableValues><displayName>PK_MERGE</displayName><value>PK_MERGE</value></allowableValues><allowableValues><displayName>SYNC</displayName><value>SYNC</value></allowableValues><allowableValues><displayName>${metadata.table.targetMergeStrategy}</displayName><value>${metadata.table.targetMergeStrategy}</value></allowableValues><defaultValue>${metadata.table.targetMergeStrategy}</defaultValue><description>Specifies the algorithm used to merge. Valid values are SYNC,MERGE,PK_MERGE,DEDUPE_AND_MERGE.  Sync will completely overwrite the target table with the source data. Merge will append the data into the target partitions. Dedupe will insert into the target partition but ensure no duplicate rows are remaining. PK Merge will insert or update existing rows matching the same primary key.</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source schema</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>Name of the schema or database for the source table</description><displayName>Source schema</displayName><dynamic>false</dynamic><name>Source schema</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source table</key><value><defaultValue>${metadata.systemFeedName}_valid</defaultValue><description>Name of the source table</description><displayName>Source table</displayName><dynamic>false</dynamic><name>Source table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target schema</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>Name of the schema or database for the target table</description><displayName>Target schema</displayName><dynamic>false</dynamic><name>Target schema</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target table</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of the target table</description><displayName>Target table</displayName><dynamic>false</dynamic><name>Target table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed partition value</key><value><defaultValue>${feedts}</defaultValue><description>Feed timestamp that identifies the current feed partition</description><displayName>Feed partition value</displayName><dynamic>false</dynamic><name>Feed partition value</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Specification</key><value><defaultValue>${metadata.table.partitionSpecs}</defaultValue><description>Partition specification in format: field|type|formula
field|type|formula</description><displayName>Partition Specification</displayName><dynamic>false</dynamic><name>Partition Specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Field specification</key><value><defaultValue>${metadata.table.fieldStructure}</defaultValue><description>Pipe-delim format with the specifications for the fields (column name|data type|comment</description><displayName>Field specification</displayName><dynamic>false</dynamic><name>Field specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>Merge Strategy</key><value>${metadata.table.targetMergeStrategy}</value></entry><entry><key>Source schema</key><value>${category}</value></entry><entry><key>Source table</key><value>${feed}_valid</value></entry><entry><key>Target schema</key><value>${category}</value></entry><entry><key>Target table</key><value>${feed}</value></entry><entry><key>Feed partition value</key><value>${feedts}</value></entry><entry><key>Partition Specification</key><value>${metadata.table.partitionSpecs}</value></entry><entry><key>Field specification</key><value>${metadata.table.fieldStructure}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Merge Table</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully relationship.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.MergeTable</type></processors><processors><id>a7716cbe-f429-41f9-817e-100235553b3f</id><parentGroupId>c529c8d4-1307-4eb8-9f59-8406992e88fb</parentGroupId><position><x>1581.7198142755515</x><y>688.0890370018311</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>8f5b0b91-5bec-41f2-b4db-c8e4deb6ed32</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></allowableValues><allowableValues><displayName>Think Big Metadata Service</displayName><value>6b207fdf-55a2-4767-9c0b-e52656972733</value></allowableValues><description>Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><defaultValue>${metadata.category.systemName}</defaultValue><description>System category of the feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><defaultValue>${metadata.systemFeedName}</defaultValue><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Initialization Result</key><value><allowableValues><description>The mode indicating feed initialization was successful.</description><displayName>Successful</displayName><value>SUCCESSFUL</value></allowableValues><allowableValues><description>The mode indicating feed initialization failed.</description><displayName>Failure</displayName><value>FAILURE</value></allowableValues><description>Indicates how this processor should behave when a flow file arrives after feed initialization has failed.</description><displayName>Initialization Result</displayName><dynamic>false</dynamic><name>Initialization Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>0aa0b6c1-15c8-4518-9717-193854c72337</value></entry><entry><key>System feed category</key><value>${category}</value></entry><entry><key>System feed name</key><value>${feed}</value></entry><entry><key>Initialization Result</key><value>SUCCESSFUL</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Record Initialization</name><relationships><autoTerminate>true</autoTerminate><description>Processing failed</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Processing was successful</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.init.CompleteInitializeFeed</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>2</inputPortCount><invalidCount>10</invalidCount><name>standard-ingest</name><outputPortCount>2</outputPortCount><parent><id>4effe0f1-d388-4b70-a041-5a11bb080232</id><name>standard-ingest</name><parent><id>ed4e53d1-191c-4159-86f2-dcb77d14337f</id><name>NiFi Flow</name></parent></parent><runningCount>0</runningCount><stoppedCount>17</stoppedCount></processGroups><processGroups><id>67a35598-7018-4ee4-863d-28f6dc09720b</id><parentGroupId>4effe0f1-d388-4b70-a041-5a11bb080232</parentGroupId><position><x>489.9999981778524</x><y>490.0</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>34c9ddbf-a194-4568-9ef2-5510d0a83690</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>93f9567e-2e3e-462f-aff1-5c9baff9ee7c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>136a9612-f7ad-40c7-a4d8-cf55df6f6a6a</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>b2140a2f-e7da-4396-869b-fda8dae73c93</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>fc6eb3a4-5ecc-4956-a233-e8930c1d5269</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>3d46d199-0534-47bd-94e9-861b010e3a3b</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>039d598d-ebf0-4de4-b54c-de77ed865a97</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>3d46d199-0534-47bd-94e9-861b010e3a3b</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>b3e2acfa-9544-42c7-bf7d-ac28f0886c2a</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>c266322d-27f2-44b6-bbcf-6b86bfe27301</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>4430a2f3-f7aa-4380-b287-9c5be16084d0</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>fc6eb3a4-5ecc-4956-a233-e8930c1d5269</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>8b4d9e21-4502-4a17-a2c2-f30ed0e4c2b7</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>136a9612-f7ad-40c7-a4d8-cf55df6f6a6a</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>bfbea11b-7dff-4561-9f5a-c1c5f3e3df5d</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>f30efe1b-952c-4f2b-b603-640472b9895e</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>9e9d0a72-b95e-45a8-830d-340317e1a33f</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>3404db61-10b5-4808-9984-e2cc5bcc7ad6</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>36245751-b7d2-4665-aadd-d4a22f523be7</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>b3e2acfa-9544-42c7-bf7d-ac28f0886c2a</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><source><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>fe149e9d-71bf-48a5-808e-8a2acec106fe</id><type>INPUT_PORT</type></source><zIndex>0</zIndex></connections><connections><id>41d1147b-0632-4d31-8ce3-fc5eb02143b7</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>bfbea11b-7dff-4561-9f5a-c1c5f3e3df5d</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>matched</selectedRelationships><source><groupId>67a35598-7018-4ee4-863d-28f6dc09720b</groupId><id>9e9d0a72-b95e-45a8-830d-340317e1a33f</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><inputPorts><id>3404db61-10b5-4808-9984-e2cc5bcc7ad6</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>41.195438672571754</x><y>404.6720060046366</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>elasticsearch-fulltext-input</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><inputPorts><id>fe149e9d-71bf-48a5-808e-8a2acec106fe</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>27.578346443926307</x><y>-42.74942462782474</y></position><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><name>elasticsearch-register-input</name><state>STOPPED</state><type>INPUT_PORT</type></inputPorts><labels><id>b4c0fa73-3b8e-4e47-a90c-f2f5fd3f7a38</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>361.73516845703125</x><y>325.9691467285156</y></position><height>673.1553955078125</height><label>Index Elasticsearch</label><style><entry><key>font-size</key><value>18px</value></entry></style><width>575.7344970703125</width></labels><labels><id>478ffd04-388d-4f23-8793-fc9186e8e5ed</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>270.7421614455693</x><y>-134.17892753865505</y></position><height>396.84320068359375</height><label>Register schema in ElasticSearch</label><style><entry><key>background-color</key><value>#bc8fff</value></entry><entry><key>font-size</key><value>18px</value></entry></style><width>869.5535888671875</width></labels><processors><id>9e9d0a72-b95e-45a8-830d-340317e1a33f</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>415.22610292695094</x><y>369.71244257771014</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Routing Strategy</key><value><allowableValues><description>A copy of the FlowFile will be routed to each relationship whose corresponding expression evaluates to 'true'</description><displayName>Route to Property name</displayName><value>Route to Property name</value></allowableValues><allowableValues><description>Requires that all user-defined expressions evaluate to 'true' for the FlowFile to be considered a match</description><displayName>Route to 'matched' if all match</displayName><value>Route to 'match' if all match</value></allowableValues><allowableValues><description>Requires that at least one user-defined expression evaluate to 'true' for hte FlowFile to be considered a match</description><displayName>Route to 'matched' if any matches</displayName><value>Route to 'match' if any matches</value></allowableValues><defaultValue>Route to Property name</defaultValue><description>Specifies how to determine which relationship to use when evaluating the Expression Language</description><displayName>Routing Strategy</displayName><dynamic>false</dynamic><name>Routing Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>indexColumns</key><value><description></description><displayName>indexColumns</displayName><dynamic>true</dynamic><name>indexColumns</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Routing Strategy</key><value>Route to 'match' if all match</value></entry><entry><key>indexColumns</key><value>${metadata.table.fieldIndexString:isEmpty():not()}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Should Index?</name><relationships><autoTerminate>false</autoTerminate><description>FlowFiles will be routed to 'match' if one or all Expressions match, depending on the configuration of the Routing Strategy property</description><name>matched</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that do not match any user-define expression will be routed here</description><name>unmatched</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.RouteOnAttribute</type></processors><processors><id>3d46d199-0534-47bd-94e9-861b010e3a3b</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>757.0909138267871</x><y>-81.79882633618513</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>JSON container options</key><value><allowableValues><displayName>none</displayName><value>none</value></allowableValues><allowableValues><displayName>array</displayName><value>array</value></allowableValues><defaultValue>array</defaultValue><description>Determines how stream of records is exposed: either as a sequence of single Objects (none) (i.e. writing every Object to a new line), or as an array of Objects (array).</description><displayName>JSON container options</displayName><dynamic>false</dynamic><name>JSON container options</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Wrap Single Record</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Determines if the resulting output for empty records or a single record should be wrapped in a container array as specified by 'JSON container options'</description><displayName>Wrap Single Record</displayName><dynamic>false</dynamic><name>Wrap Single Record</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>JSON container options</key><value>array</value></entry><entry><key>Wrap Single Record</key><value>true</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Convert Metadata SQL to JSON</name><relationships><autoTerminate>true</autoTerminate><description>A FlowFile is routed to this relationship if it cannot be parsed as Avro or cannot be converted to JSON for any reason</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>A FlowFile is routed to this relationship after it has been converted to JSON</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.avro.ConvertAvroToJSON</type></processors><processors><id>136a9612-f7ad-40c7-a4d8-cf55df6f6a6a</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>416.58819137188243</x><y>667.5687682773951</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>JSON container options</key><value><allowableValues><displayName>none</displayName><value>none</value></allowableValues><allowableValues><displayName>array</displayName><value>array</value></allowableValues><defaultValue>array</defaultValue><description>Determines how stream of records is exposed: either as a sequence of single Objects (none) (i.e. writing every Object to a new line), or as an array of Objects (array).</description><displayName>JSON container options</displayName><dynamic>false</dynamic><name>JSON container options</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Wrap Single Record</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Determines if the resulting output for empty records or a single record should be wrapped in a container array as specified by 'JSON container options'</description><displayName>Wrap Single Record</displayName><dynamic>false</dynamic><name>Wrap Single Record</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>JSON container options</key><value>array</value></entry><entry><key>Wrap Single Record</key><value>true</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Prepare ElasticSearch Format</name><relationships><autoTerminate>true</autoTerminate><description>A FlowFile is routed to this relationship if it cannot be parsed as Avro or cannot be converted to JSON for any reason</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>A FlowFile is routed to this relationship after it has been converted to JSON</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.avro.ConvertAvroToJSON</type></processors><processors><id>bfbea11b-7dff-4561-9f5a-c1c5f3e3df5d</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>414.14337735974345</x><y>513.4959145126822</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3b60d84d-8239-4cd4-b503-a9dcc6f7c188</value></allowableValues><allowableValues><displayName>Hive Thrift Service</displayName><value>3275ca43-e691-4708-b5a4-b67c4888127c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>289bb069-e856-4d0e-94e9-5fbdd90424e5</value></entry><entry><key>SQL select query</key><value>select ${metadata.table.fieldIndexString} from ${category}.${feed}_valid where processing_dttm =
    ${feedts}</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Extract Feed Data</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from SQL query result set.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type></processors><processors><id>fc6eb3a4-5ecc-4956-a233-e8930c1d5269</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>339.83258246017203</x><y>106.6443105885478</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Name Field</key><value><description>The name of the hive database field</description><displayName>Database Name Field</displayName><dynamic>false</dynamic><name>Database Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Database Owner Field</key><value><description>Database owner field name</description><displayName>Database Owner Field</displayName><dynamic>false</dynamic><name>Database Owner Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Create Time Field</key><value><description>Field representing the table create time</description><displayName>Table Create Time Field</displayName><dynamic>false</dynamic><name>Table Create Time Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Name Field</key><value><description>Field holding the table name</description><displayName>Table Name Field</displayName><dynamic>false</dynamic><name>Table Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type Field</key><value><description>Field representing what type of hive table it is</description><displayName>Table Type Field</displayName><dynamic>false</dynamic><name>Table Type Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Column Name Field</key><value><description>Field representing the column name</description><displayName>Column Name Field</displayName><dynamic>false</dynamic><name>Column Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Column Type Field</key><value><description>Field representing what the column type is</description><displayName>Column Type Field</displayName><dynamic>false</dynamic><name>Column Type Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Name Field</key><value>NAME</value></entry><entry><key>Database Owner Field</key><value>OWNER_NAME</value></entry><entry><key>Table Create Time Field</key><value>CREATE_TIME</value></entry><entry><key>Table Name Field</key><value>TBL_NAME</value></entry><entry><key>Table Type Field</key><value>TBL_TYPE</value></entry><entry><key>Column Name Field</key><value>COLUMN_NAME</value></entry><entry><key>Column Type Field</key><value>TYPE_NAME</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Merge Metadata Columns</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully merged are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Json objects that are successfully merged are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.MergeHiveTableMetadata</type></processors><processors><id>b3e2acfa-9544-42c7-bf7d-ac28f0886c2a</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>329.1402587890625</x><y>-74.8199462890625</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>MySQL</displayName><value>8e0bd85a-9966-4b49-90f8-fed6f3649c09</value></allowableValues><allowableValues><displayName>MySQL</displayName><value>f577dedb-abb3-4edf-9fe1-b9e0256279cd</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>8e0bd85a-9966-4b49-90f8-fed6f3649c09</value></entry><entry><key>SQL select query</key><value>SELECT d.NAME DATABASE_NAME, d.OWNER_NAME OWNER, t.CREATE_TIME, t.TBL_NAME, t.TBL_TYPE,
    c.COLUMN_NAME, c.TYPE_NAME
    FROM ${config.hive.schema}.COLUMNS_V2 c
    JOIN ${config.hive.schema}.SDS s on s.CD_ID = c.CD_ID
    JOIN  ${config.hive.schema}.TBLS t ON s.SD_ID=t.SD_ID
    JOIN  ${config.hive.schema}.DBS d on d.DB_ID = t.DB_ID
    where d.name = '${category}'and t.tbl_name like '${feed}%';</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Query Hive Table Metadata</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from SQL query result set.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.ExecuteSQL</type></processors><processors><id>4430a2f3-f7aa-4380-b287-9c5be16084d0</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>754.5156150018033</x><y>107.90421914428634</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>IndexName</key><value><description>The name of the index</description><displayName>IndexName</displayName><dynamic>false</dynamic><name>IndexName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Type</key><value><description>Elasticsearch type</description><displayName>Type</displayName><dynamic>false</dynamic><name>Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>HostName</key><value><description>Elasticsearch host</description><displayName>HostName</displayName><dynamic>false</dynamic><name>HostName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>ClusterName</key><value><description>Elasticsearch cluster</description><displayName>ClusterName</displayName><dynamic>false</dynamic><name>ClusterName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>IdField</key><value><description>Id that you want to use for indexing into elasticsearch. If it is empty then a uuid will be generated</description><displayName>IdField</displayName><dynamic>false</dynamic><name>IdField</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>IndexName</key><value>metadata</value></entry><entry><key>Type</key><value>hive-tables</value></entry><entry><key>HostName</key><value>localhost</value></entry><entry><key>ClusterName</key><value>demo-cluster</value></entry><entry><key>IdField</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Index Metadata Elasticsearch</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully indexed in elasticsearch are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Json objects that are successfully indexed in elasticsearch are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.IndexElasticSearch</type></processors><processors><id>93f9567e-2e3e-462f-aff1-5c9baff9ee7c</id><parentGroupId>67a35598-7018-4ee4-863d-28f6dc09720b</parentGroupId><position><x>414.0225043472317</x><y>814.5763728495995</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>IndexName</key><value><description>The name of the index</description><displayName>IndexName</displayName><dynamic>false</dynamic><name>IndexName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Type</key><value><description>Elasticsearch type</description><displayName>Type</displayName><dynamic>false</dynamic><name>Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>HostName</key><value><description>Elasticsearch host</description><displayName>HostName</displayName><dynamic>false</dynamic><name>HostName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>ClusterName</key><value><description>Elasticsearch cluster</description><displayName>ClusterName</displayName><dynamic>false</dynamic><name>ClusterName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>IdField</key><value><description>Id that you want to use for indexing into elasticsearch. If it is empty then a uuid will be generated</description><displayName>IdField</displayName><dynamic>false</dynamic><name>IdField</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>IndexName</key><value>${category}</value></entry><entry><key>Type</key><value>${feed}</value></entry><entry><key>HostName</key><value>localhost</value></entry><entry><key>ClusterName</key><value>demo-cluster</value></entry><entry><key>IdField</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Update ElasticSearch</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully indexed in elasticsearch are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Json objects that are successfully indexed in elasticsearch are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.IndexElasticSearch</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>2</inputPortCount><invalidCount>2</invalidCount><name>index-elasticsearch</name><outputPortCount>0</outputPortCount><parent><id>4effe0f1-d388-4b70-a041-5a11bb080232</id><name>standard-ingest</name><parent><id>ed4e53d1-191c-4159-86f2-dcb77d14337f</id><name>NiFi Flow</name></parent></parent><runningCount>0</runningCount><stoppedCount>8</stoppedCount></processGroups></snippet><timestamp>11/03/2016 20:46:09 UTC</timestamp></template>