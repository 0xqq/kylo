<?xml version="1.0" encoding="UTF-8" standalone="yes"?><template><description>Standard ingest template</description><name>Ingest-Template-V20</name><snippet><connections><id>100ebb50-2870-4e75-9382-792ea3b53402</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b7f7fe54-ac31-40fa-8e85-789070305079</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>fe8c51aa-1618-44b7-b90c-fc6d1431db55</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>adfa099c-e1f1-4a66-a6e1-0a35fba310e3</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>3e177ab8-1092-4b49-af74-46c7febdf89f</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b7f7fe54-ac31-40fa-8e85-789070305079</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a95fb9b7-733a-4c07-997b-5f19aafaa461</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>87e258bb-5061-4dd2-a4de-898ef2731208</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>0540836b-e408-4524-8cbf-8aa3c12a647c</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>ee24a229-8853-4ac2-ad81-1b089ecc1d3a</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b8f5f670-11b0-4ad8-ae2b-d34a7cb8ccc5</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>e551394c-d940-49a8-9d61-21fb2e2385da</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>342d54fb-4c6c-4931-afd0-f0ffb4783e7b</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>e551394c-d940-49a8-9d61-21fb2e2385da</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>original</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b7f7fe54-ac31-40fa-8e85-789070305079</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>77fcd7bd-e7d5-4f04-b3c8-68668e7408fe</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>0540836b-e408-4524-8cbf-8aa3c12a647c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>82214f39-ade0-465e-beb0-3ede8c25a37a</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>f34d3b81-2a5f-4514-bf32-d44e3137e753</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>668940aa-3f2f-426d-92e2-d8d3498dc36f</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>matched</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>043c29a7-9b8f-4051-83f8-551b5f7b64ef</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>e0a1377d-01b1-414b-aff5-8f31264443cc</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>07907a41-ed7d-45dd-a047-ddd1910087b8</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>3e177ab8-1092-4b49-af74-46c7febdf89f</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>494135f4-ff96-4201-8baf-31847f056f76</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>82214f39-ade0-465e-beb0-3ede8c25a37a</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>07907a41-ed7d-45dd-a047-ddd1910087b8</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>acee1fd3-56b0-4f80-a8c1-4847213a559d</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b8f5f670-11b0-4ad8-ae2b-d34a7cb8ccc5</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b7f7fe54-ac31-40fa-8e85-789070305079</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>2407a756-6f8b-4a6e-a6d3-5bb58664c9ad</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>e8daae41-b4a9-4a75-8336-af09e8814ba8</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>c7adc60e-f455-4e54-88a3-afd8e8b18043</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>6f5a959a-e1d9-4a4d-9a96-31ea957bc84a</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b8f5f670-11b0-4ad8-ae2b-d34a7cb8ccc5</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>87e258bb-5061-4dd2-a4de-898ef2731208</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>dcb2c292-c5cb-4f63-9b9f-62582caebbab</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>c7adc60e-f455-4e54-88a3-afd8e8b18043</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>e49a9db2-74a5-4f70-98ab-d465c1f143fd</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>99ff2775-345a-4646-8133-c8f45d189433</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>043c29a7-9b8f-4051-83f8-551b5f7b64ef</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>0540836b-e408-4524-8cbf-8aa3c12a647c</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>9793062f-89c2-4659-a830-03b738a28632</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>431e5662-54f7-493d-9c30-58f38cbfec0c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>0540836b-e408-4524-8cbf-8aa3c12a647c</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>7291cff1-8953-4c16-ae06-3ea5b792bf99</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>fe8c51aa-1618-44b7-b90c-fc6d1431db55</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>825f6ac5-f56b-42c1-9e3a-a500f0ced69e</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>a6ab6047-ae44-4848-b25e-c08aaf43a479</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>2db995e6-7f7a-4887-86ef-7f49e4ecd7f4</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>668940aa-3f2f-426d-92e2-d8d3498dc36f</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>b37d4d83-b1ab-453f-a9eb-3886afe125f5</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b8f5f670-11b0-4ad8-ae2b-d34a7cb8ccc5</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>3e177ab8-1092-4b49-af74-46c7febdf89f</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>246c451e-afb6-48d4-adc4-01e578c14f8b</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b7dc685b-f98f-43ea-8005-cc64cbc8fd07</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>e8daae41-b4a9-4a75-8336-af09e8814ba8</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>07b17c75-a3ce-4adc-a5fb-1fc5eccd9584</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>825f6ac5-f56b-42c1-9e3a-a500f0ced69e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>8635dfe0-cc08-4390-b8f1-cedfc58cfb6b</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>9da11213-d1c0-4b55-8b35-8f46b6341ce7</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b7f7fe54-ac31-40fa-8e85-789070305079</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>9ccc4459-5c32-49fd-ad9c-35a8f4309255</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>add3c671-671f-4707-8faf-c77c2a6f5f44</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>63c38c5b-97f9-4ed4-b6ed-3d5229f0e5de</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>ab05c901-b092-4e5c-b1ea-fa6658a4b890</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>569deea8-3954-4361-82fa-2f841d44395a</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><bends><x>-1360.2388771945655</x><y>1264.2871149848506</y></bends><bends><x>-1360.2388771945655</x><y>1314.2871149848506</y></bends><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>07907a41-ed7d-45dd-a047-ddd1910087b8</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name>Retry</name><selectedRelationships>failure</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>07907a41-ed7d-45dd-a047-ddd1910087b8</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>33a1cbfe-e2de-4b7e-a25a-96dfdf50cc03</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>9ccc4459-5c32-49fd-ad9c-35a8f4309255</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>ba7dc74f-ad53-4098-93cb-0b81b3d296c8</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>ac34bf62-215a-44ba-82c8-a8e745e85619</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b8f5f670-11b0-4ad8-ae2b-d34a7cb8ccc5</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>0540836b-e408-4524-8cbf-8aa3c12a647c</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>ee0024a3-c6e4-4fa2-a737-87b1a98c5d65</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>ba7dc74f-ad53-4098-93cb-0b81b3d296c8</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>ab05c901-b092-4e5c-b1ea-fa6658a4b890</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>294ae946-1237-4e0c-8297-c9053d3871b7</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>ab05c901-b092-4e5c-b1ea-fa6658a4b890</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>registration_required</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>fe8c51aa-1618-44b7-b90c-fc6d1431db55</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>672e3575-c8e3-47e5-a0b4-c53aa9f0f831</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>dc2fb2ad-e58e-4567-936f-1c9211949b40</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>2db995e6-7f7a-4887-86ef-7f49e4ecd7f4</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>e27ccd49-a421-4d36-86dc-5a058884b6e5</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b8f5f670-11b0-4ad8-ae2b-d34a7cb8ccc5</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>82214f39-ade0-465e-beb0-3ede8c25a37a</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>021115df-fc51-4342-a187-8bab2193019a</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>e49a9db2-74a5-4f70-98ab-d465c1f143fd</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>9ccc4459-5c32-49fd-ad9c-35a8f4309255</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>6a0b3256-bbbe-4297-be7d-b8f562ada2da</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>825f6ac5-f56b-42c1-9e3a-a500f0ced69e</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>b2af743b-2160-4191-bb8a-aa18a29f9c96</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>8c87c382-0bd3-4789-bf5a-f40e74375ee0</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>63c38c5b-97f9-4ed4-b6ed-3d5229f0e5de</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>ba7dc74f-ad53-4098-93cb-0b81b3d296c8</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><controllerServices><id>e946b1e0-2097-4f15-840e-143df07ad49c</id><comments></comments><descriptors><entry><key>Database Connection URL</key><value><description>A database connection URL used to connect to a database. May contain database system name, host, port, database name and some parameters. The exact syntax of a database connection URL is specified by your DBMS.</description><displayName>Database Connection URL</displayName><dynamic>false</dynamic><name>Database Connection URL</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Class Name</key><value><description>Database driver class name</description><displayName>Database Driver Class Name</displayName><dynamic>false</dynamic><name>Database Driver Class Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Jar Url</key><value><description>Optional database driver jar file path url. For example 'file:///var/tmp/mariadb-java-client-1.1.7.jar'</description><displayName>Database Driver Jar Url</displayName><dynamic>false</dynamic><name>Database Driver Jar Url</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database User</key><value><description>Database user name</description><displayName>Database User</displayName><dynamic>false</dynamic><name>Database User</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Password</key><value><description>The password for the database user</description><displayName>Password</displayName><dynamic>false</dynamic><name>Password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>500 millis</defaultValue><description>The maximum amount of time that the pool will wait (when there are no available connections)  for a connection to be returned before failing, or -1 to wait indefinitely. </description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Total Connections</key><value><defaultValue>8</defaultValue><description>The maximum number of active connections that can be allocated from this pool at the same time,  or negative for no limit.</description><displayName>Max Total Connections</displayName><dynamic>false</dynamic><name>Max Total Connections</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><name>Hive Thrift Service</name><properties><entry><key>Database Connection URL</key><value>jdbc:hive2://localhost:10000/default</value></entry><entry><key>Database Driver Class Name</key><value>org.apache.hive.jdbc.HiveDriver</value></entry><entry><key>Database Driver Jar Url</key></entry><entry><key>Database User</key><value>nifi</value></entry><entry><key>Password</key></entry><entry><key>Max Wait Time</key><value>500 millis</value></entry><entry><key>Max Total Connections</key><value>8</value></entry></properties><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>ColumnSpecs</key><value><description>Pipe-delim format with the specifications for the columns (column name|data type|comment</description><displayName>ColumnSpecs</displayName><dynamic>false</dynamic><name>ColumnSpecs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Format specification</key><value><defaultValue>ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' </defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Format specification</displayName><dynamic>false</dynamic><name>Format specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source</key><value><description>Name representing the source category</description><displayName>Source</displayName><dynamic>false</dynamic><name>Source</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Entity</key><value><description>Name of the master table</description><displayName>Table Entity</displayName><dynamic>false</dynamic><name>Table Entity</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>ba7dc74f-ad53-4098-93cb-0b81b3d296c8</id><name>Register Tables</name><properties><entry><key>Database Connection Pooling Service</key><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></entry><entry><key>ColumnSpecs</key><value>${table_column_specs}</value></entry><entry><key>Format specification</key><value>${table_format}</value></entry><entry><key>Source</key><value>${source}</value></entry><entry><key>Partition specification</key><value>${table_partition_specs}</value></entry><entry><key>Table Entity</key><value>${entity}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>668940aa-3f2f-426d-92e2-d8d3498dc36f</id><name>ExecuteHQL</name><properties><entry><key>Database Connection Pooling Service</key><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></entry><entry><key>SQL select query</key><value>select ${elasticsearch.columns} from ${source}.${entity}_valid where processing_dttm =
    ${feedts}
</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Source table</key><value><description>Fully qualified name of the source table</description><displayName>Source table</displayName><dynamic>false</dynamic><name>Source table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target table</key><value><description>Fully qualified name of the target table</description><displayName>Target table</displayName><dynamic>false</dynamic><name>Target table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed partition value</key><value><description>Feed timestamp that identifies the current feed partition</description><displayName>Feed partition value</displayName><dynamic>false</dynamic><name>Feed partition value</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Specification</key><value><description>Partition specification in format: field|type|formula
    field|type|formula</description><displayName>Partition Specification</displayName><dynamic>false</dynamic><name>Partition Specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>87e258bb-5061-4dd2-a4de-898ef2731208</id><name>MergeTable</name><properties><entry><key>Database Connection Pooling Service</key><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></entry><entry><key>Source table</key><value>${source}.${entity}_valid</value></entry><entry><key>Target table</key><value>${source}.${entity}</value></entry><entry><key>Feed partition value</key><value>${feedts}</value></entry><entry><key>Partition Specification</key><value>${partition_specs}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.MergeTable</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Statement</key><value><description>Provide the DDL or DML statement. Return values will be ignored.</description><displayName>Statement</displayName><dynamic>false</dynamic><name>Statement</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>07907a41-ed7d-45dd-a047-ddd1910087b8</id><name>Create Feed Partition</name><properties><entry><key>Database Connection Pooling Service</key><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></entry><entry><key>Statement</key><value>alter table ${source}.${entity}_feed add
    if not exists partition (processing_dttm=${feedts})
    location '/etl/${source}/${entity}/${feedts}/'
</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQLStatement</type></referencingComponents><state>ENABLED</state><type>com.thinkbiganalytics.nifi.v2.thrift.ThriftConnectionPool</type></controllerServices><controllerServices><id>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</id><comments></comments><descriptors><entry><key>Database Connection URL</key><value><description>A database connection URL used to connect to a database. May contain database system name, host, port, database name and some parameters. The exact syntax of a database connection URL is specified by your DBMS.</description><displayName>Database Connection URL</displayName><dynamic>false</dynamic><name>Database Connection URL</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Class Name</key><value><description>Database driver class name</description><displayName>Database Driver Class Name</displayName><dynamic>false</dynamic><name>Database Driver Class Name</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database Driver Jar Url</key><value><description>Optional database driver jar file path url. For example 'file:///var/tmp/mariadb-java-client-1.1.7.jar'</description><displayName>Database Driver Jar Url</displayName><dynamic>false</dynamic><name>Database Driver Jar Url</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Database User</key><value><description>Database user name</description><displayName>Database User</displayName><dynamic>false</dynamic><name>Database User</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Password</key><value><description>The password for the database user</description><displayName>Password</displayName><dynamic>false</dynamic><name>Password</name><required>false</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>500 millis</defaultValue><description>The maximum amount of time that the pool will wait (when there are no available connections)  for a connection to be returned before failing, or -1 to wait indefinitely. </description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Total Connections</key><value><defaultValue>8</defaultValue><description>The maximum number of active connections that can be allocated from this pool at the same time,  or negative for no limit.</description><displayName>Max Total Connections</displayName><dynamic>false</dynamic><name>Max Total Connections</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><name>Example MySQL Connection Pool</name><properties><entry><key>Database Connection URL</key><value>jdbc:mysql://localhost</value></entry><entry><key>Database Driver Class Name</key><value>com.mysql.jdbc.Driver</value></entry><entry><key>Database Driver Jar Url</key><value>file:///opt/nifi/mysql/mysql-connector-java-5.1.32.jar</value></entry><entry><key>Database User</key><value>nifi</value></entry><entry><key>Password</key></entry><entry><key>Max Wait Time</key><value>500 millis</value></entry><entry><key>Max Total Connections</key><value>8</value></entry></properties><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Example MySQL Connection Pool</displayName><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>e49a9db2-74a5-4f70-98ab-d465c1f143fd</id><name>Query Hive Table Metadata</name><properties><entry><key>Database Connection Pooling Service</key><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></entry><entry><key>SQL select query</key><value>SELECT d.NAME DATABASE_NAME, d.OWNER_NAME OWNER, t.CREATE_TIME, t.TBL_NAME, t.TBL_TYPE,
    c.COLUMN_NAME, c.TYPE_NAME
    FROM hive.COLUMNS_V2 c
    JOIN hive.TBLS t ON c.CD_ID=t.TBL_ID
    JOIN hive.DBS d on d.DB_ID = t.DB_ID
    where d.name = '${source}'and t.tbl_name like '${entity}%';
</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>org.apache.nifi.processors.standard.ExecuteSQL</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Source Database Connection</key><value><allowableValues><displayName>Example MySQL Connection Pool</displayName><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></allowableValues><description>The database where the source table resides</description><displayName>Source Database Connection</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Source Database Connection</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></allowableValues><description>The Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source Table</key><value><description>Name of table including schema (if applicable)</description><displayName>Source Table</displayName><dynamic>false</dynamic><name>Source Table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source Fields</key><value><description>Field names (in order) to read from the source table. ie. the select fields. The format is separated by newline. Inconsistent order will cause corruption of the downstream Hive data.</description><displayName>Source Fields</displayName><dynamic>false</dynamic><name>Source Fields</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Load Strategy</key><value><allowableValues><displayName>FULL_LOAD</displayName><value>FULL_LOAD</value></allowableValues><allowableValues><displayName>INCREMENTAL</displayName><value>INCREMENTAL</value></allowableValues><defaultValue>FULL_LOAD</defaultValue><description>Whether to load the entire table or perform an incremental extract</description><displayName>Load Strategy</displayName><dynamic>false</dynamic><name>Load Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Date Field</key><value><description>Fieldname of the source field containing the modified date for incremental load</description><displayName>Date Field</displayName><dynamic>false</dynamic><name>Date Field</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Overlap Period</key><value><defaultValue>0 seconds</defaultValue><description>Amount of time to overlap into the last load date to ensure long running transactions missed by previous load weren't missed. Recommended: &gt;0s</description><displayName>Overlap Period</displayName><dynamic>false</dynamic><name>Overlap Period</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Backoff Period</key><value><defaultValue>300 seconds</defaultValue><description>Only records older than the backoff period will be eligible for pickup. This can be used in the ILM use case to define a retention period. Recommended: &gt;5m</description><displayName>Backoff Period</displayName><dynamic>false</dynamic><name>Backoff Period</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Time Unit</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>HOUR</displayName><value>HOUR</value></allowableValues><allowableValues><displayName>DAY</displayName><value>DAY</value></allowableValues><allowableValues><displayName>WEEK</displayName><value>WEEK</value></allowableValues><allowableValues><displayName>MONTH</displayName><value>MONTH</value></allowableValues><allowableValues><displayName>YEAR</displayName><value>YEAR</value></allowableValues><defaultValue>NONE</defaultValue><description>The minimum unit of data eligible to load. For the ILM case, this would be DAY, WEEK, MONTH, YEAR , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Minimum Time Unit</displayName><dynamic>false</dynamic><name>Minimum Time Unit</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>8635dfe0-cc08-4390-b8f1-cedfc58cfb6b</id><name>Poll database</name><properties><entry><key>Source Database Connection</key><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></entry><entry><key>Metadata Service</key><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></entry><entry><key>System feed category</key><value>sales</value></entry><entry><key>System feed name</key><value>test_field_policy</value></entry><entry><key>Source Table</key><value>${metadata.table.sourceTableSchema.name}</value></entry><entry><key>Source Fields</key><value></value></entry><entry><key>Load Strategy</key><value>FULL_LOAD</value></entry><entry><key>Date Field</key></entry><entry><key>Overlap Period</key><value>300 seconds</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Backoff Period</key><value>300 seconds</value></entry><entry><key>Minimum Time Unit</key><value>NONE</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.GetTableData</type><validationErrors>'Source Fields' validated against '' is invalid because Source Fields cannot be empty</validationErrors></referencingComponents><state>ENABLED</state><type>org.apache.nifi.dbcp.DBCPConnectionPool</type></controllerServices><controllerServices><id>c572c907-97c8-4623-b1b0-97b0c0f171e0</id><comments></comments><descriptors><entry><key>Implementation</key><value><allowableValues><description>An implemenation that stores metadata locally in memory (for development-only)</description><displayName>Local, In-memory storage</displayName><value>LOCAL</value></allowableValues><allowableValues><description>An implemenation that accesses metadata via the metadata service REST API</description><displayName>REST API</displayName><value>REMOTE</value></allowableValues><defaultValue>REMOTE</defaultValue><description>Specifies which implementation of the metadata providers should be used</description><displayName>Implementation</displayName><dynamic>false</dynamic><name>Implementation</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>rest-client-url</key><value><defaultValue>http://localhost:8077/api/metadata</defaultValue><description>The base URL to the metadata server when the REST API client implementation is chosen.</description><displayName>REST Client URL</displayName><dynamic>false</dynamic><name>rest-client-url</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><name>Think Big Metadata Service</name><properties><entry><key>Implementation</key><value>REMOTE</value></entry><entry><key>rest-client-url</key><value>http://localhost:8077/api/metadata</value></entry></properties><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Source Database Connection</key><value><allowableValues><displayName>Example MySQL Connection Pool</displayName><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></allowableValues><description>The database where the source table resides</description><displayName>Source Database Connection</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Source Database Connection</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></allowableValues><description>The Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source Table</key><value><description>Name of table including schema (if applicable)</description><displayName>Source Table</displayName><dynamic>false</dynamic><name>Source Table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source Fields</key><value><description>Field names (in order) to read from the source table. ie. the select fields. The format is separated by newline. Inconsistent order will cause corruption of the downstream Hive data.</description><displayName>Source Fields</displayName><dynamic>false</dynamic><name>Source Fields</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Load Strategy</key><value><allowableValues><displayName>FULL_LOAD</displayName><value>FULL_LOAD</value></allowableValues><allowableValues><displayName>INCREMENTAL</displayName><value>INCREMENTAL</value></allowableValues><defaultValue>FULL_LOAD</defaultValue><description>Whether to load the entire table or perform an incremental extract</description><displayName>Load Strategy</displayName><dynamic>false</dynamic><name>Load Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Date Field</key><value><description>Fieldname of the source field containing the modified date for incremental load</description><displayName>Date Field</displayName><dynamic>false</dynamic><name>Date Field</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Overlap Period</key><value><defaultValue>0 seconds</defaultValue><description>Amount of time to overlap into the last load date to ensure long running transactions missed by previous load weren't missed. Recommended: &gt;0s</description><displayName>Overlap Period</displayName><dynamic>false</dynamic><name>Overlap Period</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Backoff Period</key><value><defaultValue>300 seconds</defaultValue><description>Only records older than the backoff period will be eligible for pickup. This can be used in the ILM use case to define a retention period. Recommended: &gt;5m</description><displayName>Backoff Period</displayName><dynamic>false</dynamic><name>Backoff Period</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Time Unit</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>HOUR</displayName><value>HOUR</value></allowableValues><allowableValues><displayName>DAY</displayName><value>DAY</value></allowableValues><allowableValues><displayName>WEEK</displayName><value>WEEK</value></allowableValues><allowableValues><displayName>MONTH</displayName><value>MONTH</value></allowableValues><allowableValues><displayName>YEAR</displayName><value>YEAR</value></allowableValues><defaultValue>NONE</defaultValue><description>The minimum unit of data eligible to load. For the ILM case, this would be DAY, WEEK, MONTH, YEAR , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Minimum Time Unit</displayName><dynamic>false</dynamic><name>Minimum Time Unit</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>8635dfe0-cc08-4390-b8f1-cedfc58cfb6b</id><name>Poll database</name><properties><entry><key>Source Database Connection</key><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></entry><entry><key>Metadata Service</key><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></entry><entry><key>System feed category</key><value>sales</value></entry><entry><key>System feed name</key><value>test_field_policy</value></entry><entry><key>Source Table</key><value>${metadata.table.sourceTableSchema.name}</value></entry><entry><key>Source Fields</key><value></value></entry><entry><key>Load Strategy</key><value>FULL_LOAD</value></entry><entry><key>Date Field</key></entry><entry><key>Overlap Period</key><value>300 seconds</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Backoff Period</key><value>300 seconds</value></entry><entry><key>Minimum Time Unit</key><value>NONE</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.GetTableData</type><validationErrors>'Source Fields' validated against '' is invalid because Source Fields cannot be empty</validationErrors></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></allowableValues><description>The Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System Feed Category</key><value><description>System category of feed this processor supports</description><displayName>System Feed Category</displayName><dynamic>false</dynamic><name>System Feed Category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System Feed Name</key><value><description>System name of feed this processor supports</description><displayName>System Feed Name</displayName><dynamic>false</dynamic><name>System Feed Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Result</key><value><allowableValues><displayName>success</displayName><value>success</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>success</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Result</displayName><dynamic>false</dynamic><name>Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>9ccc4459-5c32-49fd-ad9c-35a8f4309255</id><name>Record Registration</name><properties><entry><key>Metadata Service</key><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></entry><entry><key>System Feed Category</key><value>${source}</value></entry><entry><key>System Feed Name</key><value>${entity}</value></entry><entry><key>Result</key><value>success</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.UpdateRegistration</type></referencingComponents><referencingComponents><activeThreadCount>0</activeThreadCount><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></allowableValues><description>The Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System Feed Category</key><value><description>System category of feed this processor supports</description><displayName>System Feed Category</displayName><dynamic>false</dynamic><name>System Feed Category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System Feed Name</key><value><description>System name of feed this processor supports</description><displayName>System Feed Name</displayName><dynamic>false</dynamic><name>System Feed Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><groupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</groupId><id>fe8c51aa-1618-44b7-b90c-fc6d1431db55</id><name>Route for Registration?</name><properties><entry><key>Metadata Service</key><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></entry><entry><key>System Feed Category</key><value>${source}</value></entry><entry><key>System Feed Name</key><value>${entity}</value></entry></properties><referenceType>Processor</referenceType><state>STOPPED</state><type>com.thinkbiganalytics.nifi.v2.ingest.RouteOnRegistration</type></referencingComponents><state>ENABLED</state><type>com.thinkbiganalytics.nifi.v2.core.metadata.MetadataProviderSelectorService</type></controllerServices><labels><id>e828d90e-d72c-4122-85bd-44dfd7eb2c0f</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1816.6808049541216</x><y>525.3984198091067</y></position><height>515.265380859375</height><label>One-time registration</label><style><entry><key>font-size</key><value>18px</value></entry><entry><key>background-color</key><value>#dbdbdb</value></entry></style><width>1283.34326171875</width></labels><labels><id>237b4df5-f0d9-4228-8321-a46dc242c26f</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1439.5396971447824</x><y>2060.957891727715</y></position><height>729.283935546875</height><label>Index Elasticsearch</label><style><entry><key>font-size</key><value>18px</value></entry></style><width>650.7080078125</width></labels><processors><id>431e5662-54f7-493d-9c30-58f38cbfec0c</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1226.940105126766</x><y>1614.7689916772433</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ApplicationJAR</key><value><description>Path to the JAR file containing the Spark job application</description><displayName>ApplicationJAR</displayName><dynamic>false</dynamic><name>ApplicationJAR</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainClass</key><value><description>Qualified classname of the Spark job application class</description><displayName>MainClass</displayName><dynamic>false</dynamic><name>MainClass</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainArgs</key><value><description>Comma separated arguments to be passed into the main as args</description><displayName>MainArgs</displayName><dynamic>false</dynamic><name>MainArgs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkMaster</key><value><defaultValue>local</defaultValue><description>The Spark master</description><displayName>SparkMaster</displayName><dynamic>false</dynamic><name>SparkMaster</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkHome</key><value><defaultValue>/usr/hdp/current/spark-client/</defaultValue><description>Qualified classname of the Spark job application class</description><displayName>SparkHome</displayName><dynamic>false</dynamic><name>SparkHome</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Driver Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the driver</description><displayName>Driver Memory</displayName><dynamic>false</dynamic><name>Driver Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the executor</description><displayName>Executor Memory</displayName><dynamic>false</dynamic><name>Executor Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Number of Executors</key><value><defaultValue>1</defaultValue><description>The number of exectors to be used</description><displayName>Number of Executors</displayName><dynamic>false</dynamic><name>Number of Executors</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Spark Application Name</key><value><description>The name of the spark application</description><displayName>Spark Application Name</displayName><dynamic>false</dynamic><name>Spark Application Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Cores</key><value><defaultValue>1</defaultValue><description>The number of executor cores to be used</description><displayName>Executor Cores</displayName><dynamic>false</dynamic><name>Executor Cores</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Network Timeout</key><value><defaultValue>120s</defaultValue><description>Default timeout for all network interactions. This config will be used in place of spark.core.connection.ack.wait.timeout, spark.akka.timeout, spark.storage.blockManagerSlaveTimeoutMs, spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.</description><displayName>Network Timeout</displayName><dynamic>false</dynamic><name>Network Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>ApplicationJAR</key><value>
    /opt/nifi/current/lib/app/thinkbig-spark-job-profiler-0.1.0-SNAPSHOT-jar-with-dependencies.jar
</value></entry><entry><key>MainClass</key><value>com.thinkbiganalytics.spark.dataprofiler.core.Profiler</value></entry><entry><key>MainArgs</key><value>table,${source}.${entity}_valid,10,${source}.${entity}_profile,${feedts}</value></entry><entry><key>SparkMaster</key><value>yarn-client</value></entry><entry><key>SparkHome</key><value>/usr/hdp/current/spark-client/</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Driver Memory</key><value>512m</value></entry><entry><key>Executor Memory</key><value>512m</value></entry><entry><key>Number of Executors</key><value>1</value></entry><entry><key>Spark Application Name</key><value>Profiler</value></entry><entry><key>Executor Cores</key><value>2</value></entry><entry><key>Network Timeout</key><value>120s</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ProfileData</name><relationships><autoTerminate>true</autoTerminate><description>Spark execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Successful result.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#0a70f5</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.spark.ExecuteSparkJob</type></processors><processors><id>c7adc60e-f455-4e54-88a3-afd8e8b18043</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-949.7995209896721</x><y>821.107049717056</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>JSON container options</key><value><allowableValues><displayName>none</displayName><value>none</value></allowableValues><allowableValues><displayName>array</displayName><value>array</value></allowableValues><defaultValue>array</defaultValue><description>Determines how stream of records is exposed: either as a sequence of single Objects (none) (i.e. writing every Object to a new line), or as an array of Objects (array).</description><displayName>JSON container options</displayName><dynamic>false</dynamic><name>JSON container options</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Wrap Single Record</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Determines if the resulting output for empty records or a single record should be wrapped in a container array as specified by 'JSON container options'</description><displayName>Wrap Single Record</displayName><dynamic>false</dynamic><name>Wrap Single Record</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>JSON container options</key><value>array</value></entry><entry><key>Wrap Single Record</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Convert Metadata SQL to JSON</name><relationships><autoTerminate>true</autoTerminate><description>A FlowFile is routed to this relationship if it cannot be parsed as Avro or cannot be converted to JSON for any reason</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>A FlowFile is routed to this relationship after it has been converted to JSON</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.avro.ConvertAvroToJSON</type></processors><processors><id>07907a41-ed7d-45dd-a047-ddd1910087b8</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1769.2388771945655</x><y>1239.2871149848506</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Statement</key><value><description>Provide the DDL or DML statement. Return values will be ignored.</description><displayName>Statement</displayName><dynamic>false</dynamic><name>Statement</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></entry><entry><key>Statement</key><value>alter table ${source}.${entity}_feed add
    if not exists partition (processing_dttm=${feedts})
    location '/etl/${source}/${entity}/${feedts}/'
</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Create Feed Partition</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQLStatement</type></processors><processors><id>0540836b-e408-4524-8cbf-8aa3c12a647c</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1770.132395899018</x><y>1618.1660160129131</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>ApplicationJAR</key><value><description>Path to the JAR file containing the Spark job application</description><displayName>ApplicationJAR</displayName><dynamic>false</dynamic><name>ApplicationJAR</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainClass</key><value><description>Qualified classname of the Spark job application class</description><displayName>MainClass</displayName><dynamic>false</dynamic><name>MainClass</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>MainArgs</key><value><description>Comma separated arguments to be passed into the main as args</description><displayName>MainArgs</displayName><dynamic>false</dynamic><name>MainArgs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkMaster</key><value><defaultValue>local</defaultValue><description>The Spark master</description><displayName>SparkMaster</displayName><dynamic>false</dynamic><name>SparkMaster</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>SparkHome</key><value><defaultValue>/usr/hdp/current/spark-client/</defaultValue><description>Qualified classname of the Spark job application class</description><displayName>SparkHome</displayName><dynamic>false</dynamic><name>SparkHome</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Driver Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the driver</description><displayName>Driver Memory</displayName><dynamic>false</dynamic><name>Driver Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Memory</key><value><defaultValue>512m</defaultValue><description>How much RAM to allocate to the executor</description><displayName>Executor Memory</displayName><dynamic>false</dynamic><name>Executor Memory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Number of Executors</key><value><defaultValue>1</defaultValue><description>The number of exectors to be used</description><displayName>Number of Executors</displayName><dynamic>false</dynamic><name>Number of Executors</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Spark Application Name</key><value><description>The name of the spark application</description><displayName>Spark Application Name</displayName><dynamic>false</dynamic><name>Spark Application Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Executor Cores</key><value><defaultValue>1</defaultValue><description>The number of executor cores to be used</description><displayName>Executor Cores</displayName><dynamic>false</dynamic><name>Executor Cores</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Network Timeout</key><value><defaultValue>120s</defaultValue><description>Default timeout for all network interactions. This config will be used in place of spark.core.connection.ack.wait.timeout, spark.akka.timeout, spark.storage.blockManagerSlaveTimeoutMs, spark.shuffle.io.connectionTimeout, spark.rpc.askTimeout or spark.rpc.lookupTimeout if they are not configured.</description><displayName>Network Timeout</displayName><dynamic>false</dynamic><name>Network Timeout</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>ApplicationJAR</key><value>
    /opt/nifi/current/lib/app/thinkbig-spark-validate-cleanse-0.1.0-SNAPSHOT-jar-with-dependencies.jar
</value></entry><entry><key>MainClass</key><value>com.thinkbiganalytics.spark.datavalidator.Validator</value></entry><entry><key>MainArgs</key><value>${source},${entity},${feedts},${table_field_policy_json_file}</value></entry><entry><key>SparkMaster</key><value>yarn-client</value></entry><entry><key>SparkHome</key><value>/usr/hdp/current/spark-client/</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Driver Memory</key><value>512m</value></entry><entry><key>Executor Memory</key><value>512m</value></entry><entry><key>Number of Executors</key><value>1</value></entry><entry><key>Spark Application Name</key><value>Validator</value></entry><entry><key>Executor Cores</key><value>2</value></entry><entry><key>Network Timeout</key><value>120s</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Validate And Split Records</name><relationships><autoTerminate>false</autoTerminate><description>Spark execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successful result.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.spark.ExecuteSparkJob</type></processors><processors><id>668940aa-3f2f-426d-92e2-d8d3498dc36f</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1282.5984071873825</x><y>2290.469370205241</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></entry><entry><key>SQL select query</key><value>select ${elasticsearch.columns} from ${source}.${entity}_valid where processing_dttm =
    ${feedts}
</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ExecuteHQL</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from SQL query result set.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.thrift.ExecuteHQL</type></processors><processors><id>e8daae41-b4a9-4a75-8336-af09e8814ba8</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1357.3311677859747</x><y>1038.7299351769452</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Name Field</key><value><description>The name of the hive database field</description><displayName>Database Name Field</displayName><dynamic>false</dynamic><name>Database Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Database Owner Field</key><value><description>Database owner field name</description><displayName>Database Owner Field</displayName><dynamic>false</dynamic><name>Database Owner Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Create Time Field</key><value><description>Field representing the table create time</description><displayName>Table Create Time Field</displayName><dynamic>false</dynamic><name>Table Create Time Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Name Field</key><value><description>Field holding the table name</description><displayName>Table Name Field</displayName><dynamic>false</dynamic><name>Table Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Type Field</key><value><description>Field representing what type of hive table it is</description><displayName>Table Type Field</displayName><dynamic>false</dynamic><name>Table Type Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Column Name Field</key><value><description>Field representing the column name</description><displayName>Column Name Field</displayName><dynamic>false</dynamic><name>Column Name Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Column Type Field</key><value><description>Field representing what the column type is</description><displayName>Column Type Field</displayName><dynamic>false</dynamic><name>Column Type Field</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Name Field</key><value>NAME</value></entry><entry><key>Database Owner Field</key><value>OWNER_NAME</value></entry><entry><key>Table Create Time Field</key><value>CREATE_TIME</value></entry><entry><key>Table Name Field</key><value>TBL_NAME</value></entry><entry><key>Table Type Field</key><value>TBL_TYPE</value></entry><entry><key>Column Name Field</key><value>COLUMN_NAME</value></entry><entry><key>Column Type Field</key><value>TYPE_NAME</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Merge Metadata Columns</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully merged are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Json objects that are successfully merged are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.MergeHiveTableMetadata</type></processors><processors><id>b7f7fe54-ac31-40fa-8e85-789070305079</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-2300.8477634361275</x><y>1064.680199685386</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Merge Strategy</key><value><allowableValues><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value></allowableValues><allowableValues><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt; or alternatively (for backward compatibility purposes) &lt;segment.identifier&gt;, &lt;segment.count&gt;, and &lt;segment.index&gt;. All FlowFiles with the same value for &quot;fragment.identifier&quot; will be grouped together. All FlowFiles in this group must have the same value for the &quot;fragment.count&quot; attribute. All FlowFiles in this group must have a unique value for the &quot;fragment.index&quot; attribute between 0 and the value of the &quot;fragment.count&quot; attribute.</description><displayName>Defragment</displayName><value>Defragment</value></allowableValues><defaultValue>Bin-Packing Algorithm</defaultValue><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Format</key><value><allowableValues><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description><displayName>TAR</displayName><value>TAR</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description><displayName>ZIP</displayName><value>ZIP</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value></allowableValues><allowableValues><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value></allowableValues><allowableValues><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Avro</displayName><value>Avro</value></allowableValues><defaultValue>Binary Concatenation</defaultValue><description>Determines the format that will be used to merge the content.</description><displayName>Merge Format</displayName><dynamic>false</dynamic><name>Merge Format</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attribute Strategy</key><value><allowableValues><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value></allowableValues><allowableValues><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value></allowableValues><defaultValue>Keep Only Common Attributes</defaultValue><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><displayName>Attribute Strategy</displayName><dynamic>false</dynamic><name>Attribute Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Correlation Attribute Name</key><value><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><displayName>Correlation Attribute Name</displayName><dynamic>false</dynamic><name>Correlation Attribute Name</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Minimum Number of Entries</key><value><defaultValue>1</defaultValue><description>The minimum number of files to include in a bundle</description><displayName>Minimum Number of Entries</displayName><dynamic>false</dynamic><name>Minimum Number of Entries</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Number of Entries</key><value><description>The maximum number of files to include in a bundle. If not specified, there is no maximum.</description><displayName>Maximum Number of Entries</displayName><dynamic>false</dynamic><name>Maximum Number of Entries</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Group Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size of for the bundle</description><displayName>Minimum Group Size</displayName><dynamic>false</dynamic><name>Minimum Group Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Group Size</key><value><description>The maximum size for the bundle. If not specified, there is no maximum.</description><displayName>Maximum Group Size</displayName><dynamic>false</dynamic><name>Maximum Group Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Bin Age</key><value><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><displayName>Max Bin Age</displayName><dynamic>false</dynamic><name>Max Bin Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum number of Bins</key><value><defaultValue>100</defaultValue><description>Specifies the maximum number of bins that can be held in memory at any one time</description><displayName>Maximum number of Bins</displayName><dynamic>false</dynamic><name>Maximum number of Bins</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Delimiter Strategy</key><value><allowableValues><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description><displayName>Filename</displayName><value>Filename</value></allowableValues><allowableValues><description>The values of Header, Footer, and Demarcator will be specified as property values</description><displayName>Text</displayName><value>Text</value></allowableValues><defaultValue>Filename</defaultValue><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><displayName>Delimiter Strategy</displayName><dynamic>false</dynamic><name>Delimiter Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Header File</key><value><description>Filename specifying the header to use. If not specified, no header is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Header</displayName><dynamic>false</dynamic><name>Header File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Footer File</key><value><description>Filename specifying the footer to use. If not specified, no footer is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Footer</displayName><dynamic>false</dynamic><name>Footer File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Demarcator File</key><value><description>Filename specifying the demarcator to use. If not specified, no demarcator is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Demarcator</displayName><dynamic>false</dynamic><name>Demarcator File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Compression Level</key><value><allowableValues><displayName>0</displayName><value>0</value></allowableValues><allowableValues><displayName>1</displayName><value>1</value></allowableValues><allowableValues><displayName>2</displayName><value>2</value></allowableValues><allowableValues><displayName>3</displayName><value>3</value></allowableValues><allowableValues><displayName>4</displayName><value>4</value></allowableValues><allowableValues><displayName>5</displayName><value>5</value></allowableValues><allowableValues><displayName>6</displayName><value>6</value></allowableValues><allowableValues><displayName>7</displayName><value>7</value></allowableValues><allowableValues><displayName>8</displayName><value>8</value></allowableValues><allowableValues><displayName>9</displayName><value>9</value></allowableValues><defaultValue>1</defaultValue><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Keep Path</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names; if using other merge strategy, this value is ignored</description><displayName>Keep Path</displayName><dynamic>false</dynamic><name>Keep Path</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Merge Strategy</key><value>Bin-Packing Algorithm</value></entry><entry><key>Merge Format</key><value>Binary Concatenation</value></entry><entry><key>Attribute Strategy</key><value>Keep Only Common Attributes</value></entry><entry><key>Correlation Attribute Name</key></entry><entry><key>Minimum Number of Entries</key><value>1</value></entry><entry><key>Maximum Number of Entries</key></entry><entry><key>Minimum Group Size</key><value>0 B</value></entry><entry><key>Maximum Group Size</key></entry><entry><key>Max Bin Age</key></entry><entry><key>Maximum number of Bins</key><value>100</value></entry><entry><key>Delimiter Strategy</key><value>Text</value></entry><entry><key>Header File</key></entry><entry><key>Footer File</key></entry><entry><key>Demarcator File</key></entry><entry><key>Compression Level</key><value>1</value></entry><entry><key>Keep Path</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeContent</name><relationships><autoTerminate>false</autoTerminate><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFile containing the merged content</description><name>merged</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFiles that were used to create the bundle</description><name>original</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.MergeContent</type></processors><processors><id>ab05c901-b092-4e5c-b1ea-fa6658a4b890</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1777.8131479697438</x><y>580.5325897544614</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The full HDFS directory(s) to create separated by newline</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/model.db/${source}
    /model.db/${source}/${entity}
    /model.db/${source}/${entity}/feed
    /model.db/${source}/${entity}/valid
    /model.db/${source}/${entity}/invalid
    /model.db/${source}/${entity}/profile
    /app/warehouse/${source}/
    /app/warehouse/${source}/${entity}
    /etl/${source}
    /etl/${source}/${entity}
</value></entry><entry><key>Permissions umask</key><value>777</value></entry><entry><key>Remote Owner</key><value>nifi</value></entry><entry><key>Remote Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>30 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Register HDFS Folders</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.hdfs.CreateHDFSFolder</type></processors><processors><id>825f6ac5-f56b-42c1-9e3a-a500f0ced69e</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-2305.6022270914664</x><y>405.5357048268305</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Delete Attributes Expression</key><value><description>Regular expression for attributes to be deleted from flowfiles.</description><displayName>Delete Attributes Expression</displayName><dynamic>false</dynamic><name>Delete Attributes Expression</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>elasticsearch.columns</key><value><description></description><displayName>elasticsearch.columns</displayName><dynamic>true</dynamic><name>elasticsearch.columns</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>entity</key><value><description></description><displayName>entity</displayName><dynamic>true</dynamic><name>entity</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>feedts</key><value><description></description><displayName>feedts</displayName><dynamic>true</dynamic><name>feedts</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>partition_specs</key><value><description></description><displayName>partition_specs</displayName><dynamic>true</dynamic><name>partition_specs</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>source</key><value><description></description><displayName>source</displayName><dynamic>true</dynamic><name>source</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>spark.input_folder</key><value><description></description><displayName>spark.input_folder</displayName><dynamic>true</dynamic><name>spark.input_folder</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>table_column_specs</key><value><description></description><displayName>table_column_specs</displayName><dynamic>true</dynamic><name>table_column_specs</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>table_field_policy_json</key><value><description></description><displayName>table_field_policy_json</displayName><dynamic>true</dynamic><name>table_field_policy_json</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>table_format</key><value><description></description><displayName>table_format</displayName><dynamic>true</dynamic><name>table_format</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>table_partition_specs</key><value><description></description><displayName>table_partition_specs</displayName><dynamic>true</dynamic><name>table_partition_specs</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Delete Attributes Expression</key></entry><entry><key>elasticsearch.columns</key><value>first_name,last_name</value></entry><entry><key>entity</key><value>test_field_policy</value></entry><entry><key>feedts</key><value>${now():format('yyyyMMddHHmmss')}</value></entry><entry><key>partition_specs</key><value></value></entry><entry><key>source</key><value>sales</value></entry><entry><key>spark.input_folder</key><value>/tmp</value></entry><entry><key>table_column_specs</key><value>registration_dttm|timestamp
    id|bigint
    first_name|string
    last_name|string
    email|string
    gender|string
    ip_address|string
    cc|string
    country|string
    birthdate|string
    salary|double
    title|string
    comments|string
</value></entry><entry><key>table_field_policy_json</key><value>[{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;registration_dttm&quot;,&quot;standardization&quot;:[],&quot;validation&quot;:[{&quot;name&quot;:&quot;Timestamp&quot;,&quot;displayName&quot;:&quot;Timestamp&quot;,&quot;description&quot;:&quot;Validate
    ISO8601 format&quot;,&quot;properties&quot;:[],&quot;objectClassType&quot;:&quot;com.thinkbiganalytics.policy.validation.TimestampValidator&quot;,&quot;regex&quot;:null,&quot;type&quot;:null}]},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;id&quot;,&quot;standardization&quot;:null,&quot;validation&quot;:null},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:true,&quot;fieldName&quot;:&quot;first_name&quot;,&quot;standardization&quot;:[{&quot;name&quot;:&quot;Uppercase&quot;,&quot;displayName&quot;:&quot;Uppercase&quot;,&quot;description&quot;:&quot;Convert
    string to uppercase&quot;,&quot;properties&quot;:[],&quot;objectClassType&quot;:&quot;com.thinkbiganalytics.policy.standardization.UppercaseStandardizer&quot;}],&quot;validation&quot;:null},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:true,&quot;fieldName&quot;:&quot;last_name&quot;,&quot;standardization&quot;:null,&quot;validation&quot;:null},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;email&quot;,&quot;standardization&quot;:null,&quot;validation&quot;:[{&quot;name&quot;:&quot;Email&quot;,&quot;displayName&quot;:&quot;Email&quot;,&quot;description&quot;:&quot;Valid
    email address&quot;,&quot;properties&quot;:[],&quot;objectClassType&quot;:&quot;com.thinkbiganalytics.policy.validation.EmailValidator&quot;,&quot;regex&quot;:null,&quot;type&quot;:null}]},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;gender&quot;,&quot;standardization&quot;:null,&quot;validation&quot;:[{&quot;name&quot;:&quot;Lookup&quot;,&quot;displayName&quot;:&quot;Lookup&quot;,&quot;description&quot;:&quot;Must
    be contained in the list&quot;,&quot;properties&quot;:[{&quot;name&quot;:&quot;List&quot;,&quot;displayName&quot;:&quot;List&quot;,&quot;value&quot;:&quot;Male,Female&quot;,&quot;placeholder&quot;:&quot;&quot;,&quot;type&quot;:&quot;string&quot;,&quot;hint&quot;:&quot;Comma
    separated list of values&quot;,&quot;objectProperty&quot;:&quot;lookupList&quot;,&quot;selectableValues&quot;:[]}],&quot;objectClassType&quot;:&quot;com.thinkbiganalytics.policy.validation.LookupValidator&quot;,&quot;regex&quot;:null,&quot;type&quot;:null}]},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;ip_address&quot;,&quot;standardization&quot;:null,&quot;validation&quot;:[{&quot;name&quot;:&quot;IP
    Address&quot;,&quot;displayName&quot;:&quot;IP Address&quot;,&quot;description&quot;:&quot;Valid
    IP Address&quot;,&quot;properties&quot;:[],&quot;objectClassType&quot;:&quot;com.thinkbiganalytics.policy.validation.IPAddressValidator&quot;,&quot;regex&quot;:null,&quot;type&quot;:null}]},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;cc&quot;,&quot;standardization&quot;:[],&quot;validation&quot;:[]},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;country&quot;,&quot;standardization&quot;:[],&quot;validation&quot;:null},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;birthdate&quot;,&quot;standardization&quot;:[{&quot;name&quot;:&quot;Date/Time&quot;,&quot;displayName&quot;:&quot;Date/Time&quot;,&quot;description&quot;:&quot;Converts
    any date to ISO8601&quot;,&quot;properties&quot;:[{&quot;name&quot;:&quot;Date Format&quot;,&quot;displayName&quot;:&quot;Date
    Format&quot;,&quot;value&quot;:&quot;MM/dd/YYYY&quot;,&quot;placeholder&quot;:&quot;&quot;,&quot;type&quot;:&quot;string&quot;,&quot;hint&quot;:&quot;Format
    Example: MM/DD/YYYY&quot;,&quot;objectProperty&quot;:&quot;inputDateFormat&quot;,&quot;selectableValues&quot;:[]},{&quot;name&quot;:&quot;Output
    Format&quot;,&quot;displayName&quot;:&quot;Output Format&quot;,&quot;value&quot;:&quot;DATE_ONLY&quot;,&quot;placeholder&quot;:&quot;&quot;,&quot;type&quot;:&quot;select&quot;,&quot;hint&quot;:&quot;Choose
    an output format&quot;,&quot;objectProperty&quot;:&quot;outputFormat&quot;,&quot;selectableValues&quot;:[{&quot;label&quot;:&quot;DATE_ONLY&quot;,&quot;value&quot;:&quot;DATE_ONLY&quot;},{&quot;label&quot;:&quot;DATETIME&quot;,&quot;value&quot;:&quot;DATETIME&quot;},{&quot;label&quot;:&quot;DATETIME_NOMILLIS&quot;,&quot;value&quot;:&quot;DATETIME_NOMILLIS&quot;}]}],&quot;objectClassType&quot;:&quot;com.thinkbiganalytics.policy.standardization.DateTimeStandardizer&quot;}],&quot;validation&quot;:null},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;salary&quot;,&quot;standardization&quot;:[{&quot;name&quot;:&quot;Strip
    Non Numeric&quot;,&quot;displayName&quot;:&quot;Strip Non Numeric&quot;,&quot;description&quot;:&quot;Remove
    any characters that are not numeric&quot;,&quot;properties&quot;:[],&quot;objectClassType&quot;:&quot;com.thinkbiganalytics.policy.standardization.StripNonNumeric&quot;}],&quot;validation&quot;:null},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;title&quot;,&quot;standardization&quot;:null,&quot;validation&quot;:null},{&quot;partition&quot;:false,&quot;profile&quot;:true,&quot;index&quot;:false,&quot;fieldName&quot;:&quot;comments&quot;,&quot;standardization&quot;:[{&quot;name&quot;:&quot;Uppercase&quot;,&quot;displayName&quot;:&quot;Uppercase&quot;,&quot;description&quot;:&quot;Convert
    string to uppercase&quot;,&quot;properties&quot;:[],&quot;objectClassType&quot;:&quot;com.thinkbiganalytics.policy.standardization.UppercaseStandardizer&quot;}],&quot;validation&quot;:null}]
</value></entry><entry><key>table_format</key><value>ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' STORED AS
    TEXTFILE
</value></entry><entry><key>table_partition_specs</key><value></value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Update flow parameters</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.attributes.UpdateAttribute</type></processors><processors><id>82214f39-ade0-465e-beb0-3ede8c25a37a</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1769.3131645914668</x><y>1414.652983879565</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Script Engine</key><value><allowableValues><displayName>ECMAScript</displayName><value>ECMAScript</value></allowableValues><allowableValues><displayName>Groovy</displayName><value>Groovy</value></allowableValues><allowableValues><displayName>lua</displayName><value>lua</value></allowableValues><allowableValues><displayName>python</displayName><value>python</value></allowableValues><allowableValues><displayName>ruby</displayName><value>ruby</value></allowableValues><defaultValue>ECMAScript</defaultValue><description>The engine to execute scripts</description><displayName>Script Engine</displayName><dynamic>false</dynamic><name>Script Engine</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Script File</key><value><description>Path to script file to execute. Only one of Script File or Script Body may be used</description><displayName>Script File</displayName><dynamic>false</dynamic><name>Script File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Script Body</key><value><description>Body of script to execute. Only one of Script File or Script Body may be used</description><displayName>Script Body</displayName><dynamic>false</dynamic><name>Script Body</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Module Directory</key><value><description>Comma-separated list of paths to files and/or directories which contain modules required by the script.</description><displayName>Module Directory</displayName><dynamic>false</dynamic><name>Module Directory</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Script Engine</key><value>Groovy</value></entry><entry><key>Script File</key></entry><entry><key>Script Body</key><value>def flowFile = session.get()
    if(!flowFile) return
    def json = flowFile.getAttribute(&quot;table_field_policy_json&quot;);
    def inputFolder = flowFile.getAttribute(&quot;spark.input_folder&quot;)
    def entity = flowFile.getAttribute(&quot;entity&quot;)
    def source = flowFile.getAttribute(&quot;source&quot;)
    def feedts = flowFile.getAttribute(&quot;feedts&quot;)
    def folder = new File(inputFolder + &quot;/&quot;+source+&quot;/&quot;+entity+&quot;/&quot;+feedts)
    // If it doesn't exist
    if( !folder.exists() ) {
    // Create all folders
    folder.mkdirs()
    }
    def jsonFile = new File(folder,entity+&quot;_field_policy.json&quot;)
    jsonFile.write(json)
    flowFile = session.putAttribute(flowFile,&quot;table_field_policy_json_file&quot;,jsonFile.getCanonicalPath())
    session.transfer(flowFile, REL_SUCCESS)
</value></entry><entry><key>Module Directory</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Write field policy JSON to file</name><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that failed to be processed</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that were successfully processed</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>false</supportsParallelProcessing><type>org.apache.nifi.processors.script.ExecuteScript</type></processors><processors><id>8635dfe0-cc08-4390-b8f1-cedfc58cfb6b</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-2865.0352360556844</x><y>546.7630351045526</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Source Database Connection</key><value><allowableValues><displayName>Example MySQL Connection Pool</displayName><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></allowableValues><description>The database where the source table resides</description><displayName>Source Database Connection</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Source Database Connection</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></allowableValues><description>The Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System feed category</key><value><description>System category of feed this processor supports</description><displayName>System feed category</displayName><dynamic>false</dynamic><name>System feed category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System feed name</key><value><description>Name of feed this processor supports</description><displayName>System feed name</displayName><dynamic>false</dynamic><name>System feed name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source Table</key><value><description>Name of table including schema (if applicable)</description><displayName>Source Table</displayName><dynamic>false</dynamic><name>Source Table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source Fields</key><value><description>Field names (in order) to read from the source table. ie. the select fields. The format is separated by newline. Inconsistent order will cause corruption of the downstream Hive data.</description><displayName>Source Fields</displayName><dynamic>false</dynamic><name>Source Fields</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Load Strategy</key><value><allowableValues><displayName>FULL_LOAD</displayName><value>FULL_LOAD</value></allowableValues><allowableValues><displayName>INCREMENTAL</displayName><value>INCREMENTAL</value></allowableValues><defaultValue>FULL_LOAD</defaultValue><description>Whether to load the entire table or perform an incremental extract</description><displayName>Load Strategy</displayName><dynamic>false</dynamic><name>Load Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Date Field</key><value><description>Fieldname of the source field containing the modified date for incremental load</description><displayName>Date Field</displayName><dynamic>false</dynamic><name>Date Field</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Overlap Period</key><value><defaultValue>0 seconds</defaultValue><description>Amount of time to overlap into the last load date to ensure long running transactions missed by previous load weren't missed. Recommended: &gt;0s</description><displayName>Overlap Period</displayName><dynamic>false</dynamic><name>Overlap Period</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Backoff Period</key><value><defaultValue>300 seconds</defaultValue><description>Only records older than the backoff period will be eligible for pickup. This can be used in the ILM use case to define a retention period. Recommended: &gt;5m</description><displayName>Backoff Period</displayName><dynamic>false</dynamic><name>Backoff Period</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Time Unit</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>HOUR</displayName><value>HOUR</value></allowableValues><allowableValues><displayName>DAY</displayName><value>DAY</value></allowableValues><allowableValues><displayName>WEEK</displayName><value>WEEK</value></allowableValues><allowableValues><displayName>MONTH</displayName><value>MONTH</value></allowableValues><allowableValues><displayName>YEAR</displayName><value>YEAR</value></allowableValues><defaultValue>NONE</defaultValue><description>The minimum unit of data eligible to load. For the ILM case, this would be DAY, WEEK, MONTH, YEAR , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Minimum Time Unit</displayName><dynamic>false</dynamic><name>Minimum Time Unit</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Source Database Connection</key><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></entry><entry><key>Metadata Service</key><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></entry><entry><key>System feed category</key><value>sales</value></entry><entry><key>System feed name</key><value>test_field_policy</value></entry><entry><key>Source Table</key><value>${metadata.table.sourceTableSchema.name}</value></entry><entry><key>Source Fields</key><value></value></entry><entry><key>Load Strategy</key><value>FULL_LOAD</value></entry><entry><key>Date Field</key></entry><entry><key>Overlap Period</key><value>300 seconds</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry><entry><key>Backoff Period</key><value>300 seconds</value></entry><entry><key>Minimum Time Unit</key><value>NONE</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Poll database</name><relationships><autoTerminate>true</autoTerminate><description>Table extract execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Successful but no new data to process.</description><name>nodata</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successful created new flow file from the table.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#3cff00</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.GetTableData</type></processors><processors><id>9ccc4459-5c32-49fd-ad9c-35a8f4309255</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1774.1785944764126</x><y>901.8223185217865</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></allowableValues><description>The Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System Feed Category</key><value><description>System category of feed this processor supports</description><displayName>System Feed Category</displayName><dynamic>false</dynamic><name>System Feed Category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System Feed Name</key><value><description>System name of feed this processor supports</description><displayName>System Feed Name</displayName><dynamic>false</dynamic><name>System Feed Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Result</key><value><allowableValues><displayName>success</displayName><value>success</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>success</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Result</displayName><dynamic>false</dynamic><name>Result</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></entry><entry><key>System Feed Category</key><value>${source}</value></entry><entry><key>System Feed Name</key><value>${entity}</value></entry><entry><key>Result</key><value>success</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Record Registration</name><relationships><autoTerminate>false</autoTerminate><description>Registration succeeded.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.UpdateRegistration</type></processors><processors><id>2db995e6-7f7a-4887-86ef-7f49e4ecd7f4</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1284.0444012807125</x><y>2465.9406004347975</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>JSON container options</key><value><allowableValues><displayName>none</displayName><value>none</value></allowableValues><allowableValues><displayName>array</displayName><value>array</value></allowableValues><defaultValue>array</defaultValue><description>Determines how stream of records is exposed: either as a sequence of single Objects (none) (i.e. writing every Object to a new line), or as an array of Objects (array).</description><displayName>JSON container options</displayName><dynamic>false</dynamic><name>JSON container options</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Wrap Single Record</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>Determines if the resulting output for empty records or a single record should be wrapped in a container array as specified by 'JSON container options'</description><displayName>Wrap Single Record</displayName><dynamic>false</dynamic><name>Wrap Single Record</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>JSON container options</key><value>array</value></entry><entry><key>Wrap Single Record</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ConvertAvroToJSON</name><relationships><autoTerminate>true</autoTerminate><description>A FlowFile is routed to this relationship if it cannot be parsed as Avro or cannot be converted to JSON for any reason</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>A FlowFile is routed to this relationship after it has been converted to JSON</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.avro.ConvertAvroToJSON</type></processors><processors><id>fe8c51aa-1618-44b7-b90c-fc6d1431db55</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-2304.4017794190504</x><y>594.3394376255175</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Metadata Service</key><value><allowableValues><displayName>Think Big Metadata Service</displayName><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></allowableValues><description>The Think Big metadata service</description><displayName>Metadata Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.core.api.metadata.MetadataProviderService</identifiesControllerService><name>Metadata Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>System Feed Category</key><value><description>System category of feed this processor supports</description><displayName>System Feed Category</displayName><dynamic>false</dynamic><name>System Feed Category</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>System Feed Name</key><value><description>System name of feed this processor supports</description><displayName>System Feed Name</displayName><dynamic>false</dynamic><name>System Feed Name</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Metadata Service</key><value>c572c907-97c8-4623-b1b0-97b0c0f171e0</value></entry><entry><key>System Feed Category</key><value>${source}</value></entry><entry><key>System Feed Name</key><value>${entity}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Route for Registration?</name><relationships><autoTerminate>false</autoTerminate><description>Registration is required.</description><name>registration_required</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Registration already occurred or not required.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.RouteOnRegistration</type></processors><processors><id>ba7dc74f-ad53-4098-93cb-0b81b3d296c8</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1775.1437725341204</x><y>738.5395795701482</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>ColumnSpecs</key><value><description>Pipe-delim format with the specifications for the columns (column name|data type|comment</description><displayName>ColumnSpecs</displayName><dynamic>false</dynamic><name>ColumnSpecs</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Format specification</key><value><defaultValue>ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' </defaultValue><description>Provide format and delimiter specification. This is the full clause starting with the INPUTFORMAT such as: INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' </description><displayName>Format specification</displayName><dynamic>false</dynamic><name>Format specification</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Source</key><value><description>Name representing the source category</description><displayName>Source</displayName><dynamic>false</dynamic><name>Source</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition specification</key><value><description>Provide list of partition columns column-delimited</description><displayName>Partition specification</displayName><dynamic>false</dynamic><name>Partition specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Table Entity</key><value><description>Name of the master table</description><displayName>Table Entity</displayName><dynamic>false</dynamic><name>Table Entity</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></entry><entry><key>ColumnSpecs</key><value>${table_column_specs}</value></entry><entry><key>Format specification</key><value>${table_format}</value></entry><entry><key>Source</key><value>${source}</value></entry><entry><key>Partition specification</key><value>${table_partition_specs}</value></entry><entry><key>Table Entity</key><value>${entity}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Register Tables</name><relationships><autoTerminate>false</autoTerminate><description>Table execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created tables.</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#da05ff</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.RegisterFeedTables</type></processors><processors><id>b2af743b-2160-4191-bb8a-aa18a29f9c96</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-2862.8909233805293</x><y>400.28085253190864</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Input Directory</key><value><description>The input directory from which to pull files</description><displayName>Input Directory</displayName><dynamic>false</dynamic><name>Input Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>File Filter</key><value><defaultValue>[^\.].*</defaultValue><description>Only files whose names match the given regular expression will be picked up</description><displayName>File Filter</displayName><dynamic>false</dynamic><name>File Filter</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Path Filter</key><value><description>When Recurse Subdirectories is true, then only subdirectories whose path matches the given regular expression will be scanned</description><displayName>Path Filter</displayName><dynamic>false</dynamic><name>Path Filter</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Batch Size</key><value><defaultValue>10</defaultValue><description>The maximum number of files to pull in each iteration</description><displayName>Batch Size</displayName><dynamic>false</dynamic><name>Batch Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Keep Source File</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If true, the file is not deleted after it has been copied to the Content Repository; this causes the file to be picked up continually and is useful for testing purposes.  If not keeping original NiFi will need write permissions on the directory it is pulling from otherwise it will ignore the file.</description><displayName>Keep Source File</displayName><dynamic>false</dynamic><name>Keep Source File</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Recurse Subdirectories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>Indicates whether or not to pull files from subdirectories</description><displayName>Recurse Subdirectories</displayName><dynamic>false</dynamic><name>Recurse Subdirectories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Polling Interval</key><value><defaultValue>0 sec</defaultValue><description>Indicates how long to wait before performing a directory listing</description><displayName>Polling Interval</displayName><dynamic>false</dynamic><name>Polling Interval</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Ignore Hidden Files</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>Indicates whether or not hidden files should be ignored</description><displayName>Ignore Hidden Files</displayName><dynamic>false</dynamic><name>Ignore Hidden Files</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum File Age</key><value><defaultValue>0 sec</defaultValue><description>The minimum age that a file must be in order to be pulled; any file younger than this amount of time (according to last modification date) will be ignored</description><displayName>Minimum File Age</displayName><dynamic>false</dynamic><name>Minimum File Age</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Age</key><value><description>The maximum age that a file must be in order to be pulled; any file older than this amount of time (according to last modification date) will be ignored</description><displayName>Maximum File Age</displayName><dynamic>false</dynamic><name>Maximum File Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum File Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size that a file must be in order to be pulled</description><displayName>Minimum File Size</displayName><dynamic>false</dynamic><name>Minimum File Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Size</key><value><description>The maximum size that a file can be in order to be pulled</description><displayName>Maximum File Size</displayName><dynamic>false</dynamic><name>Maximum File Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Input Directory</key><value>/var/dropzone</value></entry><entry><key>File Filter</key><value>mydata\d{1,3}.csv</value></entry><entry><key>Path Filter</key></entry><entry><key>Batch Size</key><value>100</value></entry><entry><key>Keep Source File</key><value>false</value></entry><entry><key>Recurse Subdirectories</key><value>false</value></entry><entry><key>Polling Interval</key><value>0 sec</value></entry><entry><key>Ignore Hidden Files</key><value>true</value></entry><entry><key>Minimum File Age</key><value>0 sec</value></entry><entry><key>Maximum File Age</key></entry><entry><key>Minimum File Size</key><value>0 B</value></entry><entry><key>Maximum File Size</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>10 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Poll filesystem</name><relationships><autoTerminate>false</autoTerminate><description>All files are routed to success</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#11f237</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.GetFile</type></processors><processors><id>87e258bb-5061-4dd2-a4de-898ef2731208</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1862.4610401645357</x><y>2041.3233424581003</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Hive Thrift Service</displayName><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>com.thinkbiganalytics.nifi.v2.thrift.ThriftService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Source table</key><value><description>Fully qualified name of the source table</description><displayName>Source table</displayName><dynamic>false</dynamic><name>Source table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Target table</key><value><description>Fully qualified name of the target table</description><displayName>Target table</displayName><dynamic>false</dynamic><name>Target table</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Feed partition value</key><value><description>Feed timestamp that identifies the current feed partition</description><displayName>Feed partition value</displayName><dynamic>false</dynamic><name>Feed partition value</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Partition Specification</key><value><description>Partition specification in format: field|type|formula
    field|type|formula</description><displayName>Partition Specification</displayName><dynamic>false</dynamic><name>Partition Specification</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>e946b1e0-2097-4f15-840e-143df07ad49c</value></entry><entry><key>Source table</key><value>${source}.${entity}_valid</value></entry><entry><key>Target table</key><value>${source}.${entity}</value></entry><entry><key>Feed partition value</key><value>${feedts}</value></entry><entry><key>Partition Specification</key><value>${partition_specs}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeTable</name><relationships><autoTerminate>false</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Successfully created FlowFile from .</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.ingest.MergeTable</type></processors><processors><id>b7dc685b-f98f-43ea-8005-cc64cbc8fd07</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-927.0857573146559</x><y>1022.4820312326838</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>IndexName</key><value><description>The name of the index</description><displayName>IndexName</displayName><dynamic>false</dynamic><name>IndexName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Type</key><value><description>Elasticsearch type</description><displayName>Type</displayName><dynamic>false</dynamic><name>Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>HostName</key><value><description>Elasticsearch host</description><displayName>HostName</displayName><dynamic>false</dynamic><name>HostName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>ClusterName</key><value><description>Elasticsearch cluster</description><displayName>ClusterName</displayName><dynamic>false</dynamic><name>ClusterName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>IdField</key><value><description>Id that you want to use for indexing into elasticsearch. If it is empty then a uuid will be generated</description><displayName>IdField</displayName><dynamic>false</dynamic><name>IdField</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>IndexName</key><value>metadata</value></entry><entry><key>Type</key><value>hive-tables</value></entry><entry><key>HostName</key><value>localhost</value></entry><entry><key>ClusterName</key><value>demo-cluster</value></entry><entry><key>IdField</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Index Metadata Elasticsearch</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully indexed in elasticsearch are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Json objects that are successfully indexed in elasticsearch are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.IndexElasticSearch</type></processors><processors><id>3e177ab8-1092-4b49-af74-46c7febdf89f</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1767.9013083503462</x><y>1073.6177055592525</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/etl/${source}/${entity}/${feedts}</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key><value>nifi</value></entry><entry><key>Remote Group</key><value>hdfs</value></entry><entry><key>Compression codec</key><value>NONE</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutHDFS</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#2cfa08</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>dc2fb2ad-e58e-4567-936f-1c9211949b40</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1276.883220629582</x><y>2646.018517507002</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>10</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>IndexName</key><value><description>The name of the index</description><displayName>IndexName</displayName><dynamic>false</dynamic><name>IndexName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Type</key><value><description>Elasticsearch type</description><displayName>Type</displayName><dynamic>false</dynamic><name>Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>HostName</key><value><description>Elasticsearch host</description><displayName>HostName</displayName><dynamic>false</dynamic><name>HostName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>ClusterName</key><value><description>Elasticsearch cluster</description><displayName>ClusterName</displayName><dynamic>false</dynamic><name>ClusterName</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>IdField</key><value><description>Id that you want to use for indexing into elasticsearch. If it is empty then a uuid will be generated</description><displayName>IdField</displayName><dynamic>false</dynamic><name>IdField</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>IndexName</key><value>${source}</value></entry><entry><key>Type</key><value>${entity}</value></entry><entry><key>HostName</key><value>localhost</value></entry><entry><key>ClusterName</key><value>demo-cluster</value></entry><entry><key>IdField</key><value>id</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>IndexElasticSearch Full Text</name><relationships><autoTerminate>true</autoTerminate><description>Json objects that are un-successfully indexed in elasticsearch are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Json objects that are successfully indexed in elasticsearch are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>com.thinkbiganalytics.nifi.v2.elasticsearch.IndexElasticSearch</type></processors><processors><id>b8f5f670-11b0-4ad8-ae2b-d34a7cb8ccc5</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-2316.975762247717</x><y>1619.3053271102672</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Directory</key><value>/tmp/${source}/${entity}/${feedts}/failed</value></entry><entry><key>Conflict Resolution Strategy</key><value>ignore</value></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Permissions</key></entry><entry><key>Owner</key></entry><entry><key>Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Failed Flow</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#fa0303</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors><processors><id>043c29a7-9b8f-4051-83f8-551b5f7b64ef</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1289.2969316201752</x><y>2111.670334305425</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Routing Strategy</key><value><allowableValues><description>A copy of the FlowFile will be routed to each relationship whose corresponding expression evaluates to 'true'</description><displayName>Route to Property name</displayName><value>Route to Property name</value></allowableValues><allowableValues><description>Requires that all user-defined expressions evaluate to 'true' for the FlowFile to be considered a match</description><displayName>Route to 'matched' if all match</displayName><value>Route to 'match' if all match</value></allowableValues><allowableValues><description>Requires that at least one user-defined expression evaluate to 'true' for hte FlowFile to be considered a match</description><displayName>Route to 'matched' if any matches</displayName><value>Route to 'match' if any matches</value></allowableValues><defaultValue>Route to Property name</defaultValue><description>Specifies how to determine which relationship to use when evaluating the Expression Language</description><displayName>Routing Strategy</displayName><dynamic>false</dynamic><name>Routing Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>indexColumns</key><value><description></description><displayName>indexColumns</displayName><dynamic>true</dynamic><name>indexColumns</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Routing Strategy</key><value>Route to 'match' if all match</value></entry><entry><key>indexColumns</key><value>${elasticsearch.columns:isEmpty():not()}</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>RouteOnAttribute</name><relationships><autoTerminate>false</autoTerminate><description>FlowFiles will be routed to 'match' if one or all Expressions match, depending on the configuration of the Routing Strategy property</description><name>matched</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that do not match any user-define expression will be routed here</description><name>unmatched</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.RouteOnAttribute</type></processors><processors><id>e551394c-d940-49a8-9d61-21fb2e2385da</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-2820.0999014080644</x><y>1056.7542072735569</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key><value>4 hours</value></entry><entry><key>Directory</key><value>/archive/${source}/${entity}/${feedts}</value></entry><entry><key>Conflict Resolution Strategy</key><value>fail</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key></entry><entry><key>Remote Group</key></entry><entry><key>Compression codec</key><value>BZIP</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Archive Originals</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#e6f205</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>e49a9db2-74a5-4f70-98ab-d465c1f143fd</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1364.1329885273967</x><y>818.3594282993349</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Database Connection Pooling Service</key><value><allowableValues><displayName>Example MySQL Connection Pool</displayName><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></allowableValues><description>The Controller Service that is used to obtain connection to database</description><displayName>Database Connection Pooling Service</displayName><dynamic>false</dynamic><identifiesControllerService>org.apache.nifi.dbcp.DBCPService</identifiesControllerService><name>Database Connection Pooling Service</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>SQL select query</key><value><description>SQL select query</description><displayName>SQL select query</displayName><dynamic>false</dynamic><name>SQL select query</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Max Wait Time</key><value><defaultValue>0 seconds</defaultValue><description>The maximum amount of time allowed for a running SQL select query  , zero means there is no limit. Max time less than 1 second will be equal to zero.</description><displayName>Max Wait Time</displayName><dynamic>false</dynamic><name>Max Wait Time</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Database Connection Pooling Service</key><value>d77ebd97-26f0-40ad-bcb7-26e3dfe7c4d5</value></entry><entry><key>SQL select query</key><value>SELECT d.NAME DATABASE_NAME, d.OWNER_NAME OWNER, t.CREATE_TIME, t.TBL_NAME, t.TBL_TYPE,
    c.COLUMN_NAME, c.TYPE_NAME
    FROM hive.COLUMNS_V2 c
    JOIN hive.TBLS t ON c.CD_ID=t.TBL_ID
    JOIN hive.DBS d on d.DB_ID = t.DB_ID
    where d.name = '${source}'and t.tbl_name like '${entity}%';
</value></entry><entry><key>Max Wait Time</key><value>0 seconds</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Query Hive Table Metadata</name><relationships><autoTerminate>true</autoTerminate><description>SQL query execution failed. Incoming FlowFile will be penalized and routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>Successfully created FlowFile from SQL query result set.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.ExecuteSQL</type></processors><processors><id>63c38c5b-97f9-4ed4-b6ed-3d5229f0e5de</id><parentGroupId>3397bb3a-bb78-405e-b9d3-6d91320007d6</parentGroupId><position><x>-1244.566577404592</x><y>666.7545969767285</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Directory</key><value>/tmp/${source}/${entity}/${feedts}/abandoned</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Permissions</key></entry><entry><key>Owner</key></entry><entry><key>Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Aborted Registration</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style><entry><key>background-color</key><value>#fa0a1a</value></entry></style><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors></snippet><timestamp>05/01/2016 22:36:08 UTC</timestamp></template>