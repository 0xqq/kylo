[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test
	*** Completed run for BigDecimalColumnCase1Test ***
Tests run: 10, Failures: 0, Errors: 10, Skipped: 0, Time elapsed: 7.522 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test
testBigDecimalMax(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 5.218 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBigDecimalMin(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 0.345 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBigDecimalSum(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 0.154 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBigDecimalTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 0.147 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBigDecimalPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 0.323 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBigDecimalPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 0.156 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBigDecimalNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 0.186 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBigDecimalPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 0.26 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBigDecimalUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 0.122 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBigDecimalTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test)  Time elapsed: 0.102 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BigDecimalColumnCase1Test.setUp(BigDecimalColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...
  BigDecimalColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted...

Tests run: 10, Failures: 0, Errors: 10, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 10.075 s
[INFO] Finished at: 2017-01-31T16:37:04-08:00
[INFO] Final Memory: 23M/309M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test
	*** Completed run for BooleanColumnCase1Test ***
Tests run: 9, Failures: 0, Errors: 9, Skipped: 0, Time elapsed: 7.235 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test
testBooleanFalseCount(com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test)  Time elapsed: 4.811 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test.setUp(BooleanColumnCase1Test.java:58)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBooleanTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test)  Time elapsed: 0.27 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test.setUp(BooleanColumnCase1Test.java:58)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBooleanNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test)  Time elapsed: 0.462 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test.setUp(BooleanColumnCase1Test.java:58)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBooleanTrueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test)  Time elapsed: 0.088 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test.setUp(BooleanColumnCase1Test.java:58)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBooleanPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test)  Time elapsed: 0.289 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test.setUp(BooleanColumnCase1Test.java:58)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBooleanTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test)  Time elapsed: 0.167 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test.setUp(BooleanColumnCase1Test.java:58)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBooleanPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test)  Time elapsed: 0.188 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test.setUp(BooleanColumnCase1Test.java:58)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBooleanUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test)  Time elapsed: 0.186 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test.setUp(BooleanColumnCase1Test.java:58)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBooleanPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test)  Time elapsed: 0.134 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.BooleanColumnCase1Test.setUp(BooleanColumnCase1Test.java:58)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  BooleanColumnCase1Test.setUp:58->ProfilerTest.setUp:286 » Spark Job aborted du...
  BooleanColumnCase1Test.setUp:58->ProfilerTest.setUp:286 » Spark Job aborted du...
  BooleanColumnCase1Test.setUp:58->ProfilerTest.setUp:286 » Spark Job aborted du...
  BooleanColumnCase1Test.setUp:58->ProfilerTest.setUp:286 » Spark Job aborted du...
  BooleanColumnCase1Test.setUp:58->ProfilerTest.setUp:286 » Spark Job aborted du...
  BooleanColumnCase1Test.setUp:58->ProfilerTest.setUp:286 » Spark Job aborted du...
  BooleanColumnCase1Test.setUp:58->ProfilerTest.setUp:286 » Spark Job aborted du...
  BooleanColumnCase1Test.setUp:58->ProfilerTest.setUp:286 » Spark Job aborted du...
  BooleanColumnCase1Test.setUp:58->ProfilerTest.setUp:286 » Spark Job aborted du...

Tests run: 9, Failures: 0, Errors: 9, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 10.090 s
[INFO] Finished at: 2017-01-31T16:37:15-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test
	*** Completed run for ByteColumnCase1Test ***
Tests run: 13, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 11.963 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test
testByteMean(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 5.271 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testByteTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.503 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testByteNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.147 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testByteStddev(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.389 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testByteMax(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.257 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testByteMin(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.357 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testByteSum(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.33 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBytePercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.42 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testByteUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.747 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBytePercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.609 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testBytePercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 1.054 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testByteTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.701 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testByteVariance(com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test)  Time elapsed: 0.633 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ByteColumnCase1Test.setUp(ByteColumnCase1Test.java:64)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...
  ByteColumnCase1Test.setUp:64->ProfilerTest.setUp:286 » Spark Job aborted due t...

Tests run: 13, Failures: 0, Errors: 13, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 14.961 s
[INFO] Finished at: 2017-01-31T16:37:32-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------

Results :

Tests run: 0, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 6.809 s
[INFO] Finished at: 2017-01-31T16:37:43-08:00
[INFO] Final Memory: 22M/309M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: No tests were executed!  (Set -DfailIfNoTests=false to ignore this error.) -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test
	*** Completed run for DateColumnCase1Test ***
Tests run: 9, Failures: 0, Errors: 9, Skipped: 0, Time elapsed: 11.214 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test
testDateUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test)  Time elapsed: 6.962 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test.setUp(DateColumnCase1Test.java:59)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDatePercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test)  Time elapsed: 0.324 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test.setUp(DateColumnCase1Test.java:59)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDateTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test)  Time elapsed: 0.222 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test.setUp(DateColumnCase1Test.java:59)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDatePercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test)  Time elapsed: 0.227 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test.setUp(DateColumnCase1Test.java:59)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDateNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test)  Time elapsed: 0.381 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test.setUp(DateColumnCase1Test.java:59)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDateTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test)  Time elapsed: 0.267 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test.setUp(DateColumnCase1Test.java:59)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDatePercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test)  Time elapsed: 1.215 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test.setUp(DateColumnCase1Test.java:59)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDateMaxDate(com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test)  Time elapsed: 0.139 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test.setUp(DateColumnCase1Test.java:59)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDateMinDate(com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test)  Time elapsed: 0.28 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DateColumnCase1Test.setUp(DateColumnCase1Test.java:59)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  DateColumnCase1Test.setUp:59->ProfilerTest.setUp:286 » Spark Job aborted due t...
  DateColumnCase1Test.setUp:59->ProfilerTest.setUp:286 » Spark Job aborted due t...
  DateColumnCase1Test.setUp:59->ProfilerTest.setUp:286 » Spark Job aborted due t...
  DateColumnCase1Test.setUp:59->ProfilerTest.setUp:286 » Spark Job aborted due t...
  DateColumnCase1Test.setUp:59->ProfilerTest.setUp:286 » Spark Job aborted due t...
  DateColumnCase1Test.setUp:59->ProfilerTest.setUp:286 » Spark Job aborted due t...
  DateColumnCase1Test.setUp:59->ProfilerTest.setUp:286 » Spark Job aborted due t...
  DateColumnCase1Test.setUp:59->ProfilerTest.setUp:286 » Spark Job aborted due t...
  DateColumnCase1Test.setUp:59->ProfilerTest.setUp:286 » Spark Job aborted due t...

Tests run: 9, Failures: 0, Errors: 9, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 15.964 s
[INFO] Finished at: 2017-01-31T16:38:01-08:00
[INFO] Final Memory: 23M/309M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test
	*** Completed run for DoubleColumnCase1Test ***
Tests run: 13, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 9.552 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test
testDoubleTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 5.85 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoublePercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.34 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoubleNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.319 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoubleUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.14 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoubleTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.295 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoubleMax(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.184 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoubleMin(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.369 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoubleSum(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.125 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoubleMean(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.214 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoubleVariance(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.21 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoublePercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.229 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoublePercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.293 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testDoubleStddev(com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test)  Time elapsed: 0.123 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.DoubleColumnCase1Test.setUp(DoubleColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...
  DoubleColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted due...

Tests run: 13, Failures: 0, Errors: 13, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 13.142 s
[INFO] Finished at: 2017-01-31T16:38:16-08:00
[INFO] Final Memory: 23M/309M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test
	*** Completed run for FloatColumnCase1Test ***
Tests run: 13, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 7.635 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test
testFloatMax(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 4.239 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatMin(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.371 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatSum(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.533 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.235 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatMean(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.128 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatVariance(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.372 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.202 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.165 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.198 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.021 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatStddev(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.104 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.366 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testFloatNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test)  Time elapsed: 0.077 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.FloatColumnCase1Test.setUp(FloatColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  FloatColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...

Tests run: 13, Failures: 0, Errors: 13, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 10.462 s
[INFO] Finished at: 2017-01-31T16:38:28-08:00
[INFO] Final Memory: 23M/309M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test
	*** Completed run for IntegerColumnCase1Test ***
Tests run: 13, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 6.967 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test
testIntegerPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 3.972 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.207 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.273 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.211 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.23 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerVariance(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.158 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerMean(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.227 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerStddev(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.165 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.163 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerMax(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.192 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerMin(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.118 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerSum(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.281 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test)  Time elapsed: 0.165 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase1Test.setUp(IntegerColumnCase1Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase1Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...

Tests run: 13, Failures: 0, Errors: 13, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 9.529 s
[INFO] Finished at: 2017-01-31T16:38:39-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test
	*** Completed run for IntegerColumnCase2Test ***
Tests run: 13, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 7.09 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test
testIntegerPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 3.807 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.444 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.043 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.137 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.263 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerVariance(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.263 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerMean(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.134 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerStddev(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.277 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.125 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerMax(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.217 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerMin(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.33 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerSum(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.261 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testIntegerPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test)  Time elapsed: 0.18 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.IntegerColumnCase2Test.setUp(IntegerColumnCase2Test.java:62)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...
  IntegerColumnCase2Test.setUp:62->ProfilerTest.setUp:286 » Spark Job aborted du...

Tests run: 13, Failures: 0, Errors: 13, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 9.742 s
[INFO] Finished at: 2017-01-31T16:38:50-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test
	*** Completed run for LongColumnCase1Test ***
Tests run: 13, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 9.158 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test
testLongStddev(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 4.348 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongMean(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.223 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.363 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongMax(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.182 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongMin(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.179 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongSum(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.243 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.331 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.181 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.251 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 1.518 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.32 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.283 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testLongVariance(com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test)  Time elapsed: 0.174 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.LongColumnCase1Test.setUp(LongColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...
  LongColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due t...

Tests run: 13, Failures: 0, Errors: 13, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 11.856 s
[INFO] Finished at: 2017-01-31T16:39:03-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test
	*** Completed run for ShortColumnCase1Test ***
Tests run: 13, Failures: 0, Errors: 13, Skipped: 0, Time elapsed: 6.981 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test
testShortPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 4.032 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortMean(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.214 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.414 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.151 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortVariance(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.095 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.184 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortStddev(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.237 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortMax(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.208 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortMin(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.174 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortSum(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.153 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.199 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.145 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testShortUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test)  Time elapsed: 0.176 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.ShortColumnCase1Test.setUp(ShortColumnCase1Test.java:63)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...
  ShortColumnCase1Test.setUp:63->ProfilerTest.setUp:286 » Spark Job aborted due ...

Tests run: 13, Failures: 0, Errors: 13, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 9.877 s
[INFO] Finished at: 2017-01-31T16:39:14-08:00
[INFO] Final Memory: 23M/309M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test
	*** Completed run for StringColumnCase1Test ***
Tests run: 17, Failures: 0, Errors: 17, Skipped: 0, Time elapsed: 7.36 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test
testStringMaxLength(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 3.817 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringEmptyCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.173 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.176 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringShortestString(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.203 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinLength(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.182 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMaxStringCaseSensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.167 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.247 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.114 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.274 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringLongestString(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.189 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.132 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMaxStringCaseInsensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.28 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinStringCaseInsensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.162 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.216 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinStringCaseSensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.127 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercEmptyValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.215 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test)  Time elapsed: 0.209 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase1Test.setUp(StringColumnCase1Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase1Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...

Tests run: 17, Failures: 0, Errors: 17, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 9.805 s
[INFO] Finished at: 2017-01-31T16:39:25-08:00
[INFO] Final Memory: 23M/309M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test
	*** Completed run for StringColumnCase2Test ***
Tests run: 17, Failures: 0, Errors: 17, Skipped: 0, Time elapsed: 9.154 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test
testStringMaxLength(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 5.37 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringEmptyCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.169 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.25 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringShortestString(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.242 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinLength(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.108 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMaxStringCaseSensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.214 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.285 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.177 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.184 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringLongestString(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.19 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.105 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMaxStringCaseInsensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.121 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinStringCaseInsensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.166 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.147 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinStringCaseSensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.218 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercEmptyValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.359 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test)  Time elapsed: 0.109 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase2Test.setUp(StringColumnCase2Test.java:66)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase2Test.setUp:66->ProfilerTest.setUp:286 » Spark Job aborted due...

Tests run: 17, Failures: 0, Errors: 17, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 11.776 s
[INFO] Finished at: 2017-01-31T16:39:38-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test
	*** Completed run for StringColumnCase1Test ***
Tests run: 17, Failures: 0, Errors: 17, Skipped: 0, Time elapsed: 11.881 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test
testStringMaxLength(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 5.5 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringEmptyCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.246 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.348 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringShortestString(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.201 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinLength(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.389 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMaxStringCaseSensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.15 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.282 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.387 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 7 in stage 0.0 failed 1 times, most recent failure: Lost task 7.0 in stage 0.0 (TID 7, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.156 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringLongestString(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.232 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.503 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMaxStringCaseInsensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.437 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinStringCaseInsensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.127 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.143 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinStringCaseSensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.199 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercEmptyValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 1.264 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test)  Time elapsed: 0.306 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase3Test.setUp(StringColumnCase3Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase3Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...

Tests run: 17, Failures: 0, Errors: 17, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 15.185 s
[INFO] Finished at: 2017-01-31T16:39:54-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test
	*** Completed run for StringColumnCase4Test ***
Tests run: 17, Failures: 0, Errors: 17, Skipped: 0, Time elapsed: 9.021 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test
testStringMaxLength(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 5.049 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringEmptyCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.348 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.202 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringShortestString(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.215 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinLength(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.193 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMaxStringCaseSensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.184 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.28 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.187 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.141 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 3 in stage 0.0 failed 1 times, most recent failure: Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringLongestString(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.215 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.225 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMaxStringCaseInsensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.225 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinStringCaseInsensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.132 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.19 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringMinStringCaseSensitive(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.279 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercEmptyValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.193 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testStringPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test)  Time elapsed: 0.078 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.StringColumnCase4Test.setUp(StringColumnCase4Test.java:68)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...
  StringColumnCase4Test.setUp:68->ProfilerTest.setUp:286 » Spark Job aborted due...

Tests run: 17, Failures: 0, Errors: 17, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 12.177 s
[INFO] Finished at: 2017-01-31T16:40:08-08:00
[INFO] Final Memory: 23M/309M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test
	*** Completed run for TimestampColumnCase1Test ***
Tests run: 9, Failures: 0, Errors: 9, Skipped: 0, Time elapsed: 6.109 sec <<< FAILURE! - in com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test
testTimestampPercNullValues(com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test)  Time elapsed: 3.961 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test.setUp(TimestampColumnCase1Test.java:60)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testTimestampTotalCount(com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test)  Time elapsed: 0.302 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test.setUp(TimestampColumnCase1Test.java:60)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testTimestampMaxTimestamp(com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test)  Time elapsed: 0.278 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 6 in stage 0.0 failed 1 times, most recent failure: Lost task 6.0 in stage 0.0 (TID 6, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test.setUp(TimestampColumnCase1Test.java:60)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testTimestampNullCount(com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test)  Time elapsed: 0.081 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test.setUp(TimestampColumnCase1Test.java:60)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testTimestampMinTimestamp(com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test)  Time elapsed: 0.233 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test.setUp(TimestampColumnCase1Test.java:60)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testTimestampTopNValues(com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test)  Time elapsed: 0.324 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test.setUp(TimestampColumnCase1Test.java:60)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testTimestampPercDuplicateValues(com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test)  Time elapsed: 0.104 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test.setUp(TimestampColumnCase1Test.java:60)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testTimestampUniqueCount(com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test)  Time elapsed: 0.094 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test.setUp(TimestampColumnCase1Test.java:60)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;

testTimestampPercUniqueValues(com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test)  Time elapsed: 0.136 sec  <<< ERROR!
org.apache.spark.SparkException: 
Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase1Test.setUp(TimestampColumnCase1Test.java:60)
Caused by: java.lang.AbstractMethodError: com.thinkbiganalytics.spark.dataprofiler.functions.IndividualColumnValueCounts.call(Ljava/lang/Object;)Ljava/util/Iterator;


Results :

Tests in error: 
  TimestampColumnCase1Test.setUp:60->ProfilerTest.setUp:286 » Spark Job aborted ...
  TimestampColumnCase1Test.setUp:60->ProfilerTest.setUp:286 » Spark Job aborted ...
  TimestampColumnCase1Test.setUp:60->ProfilerTest.setUp:286 » Spark Job aborted ...
  TimestampColumnCase1Test.setUp:60->ProfilerTest.setUp:286 » Spark Job aborted ...
  TimestampColumnCase1Test.setUp:60->ProfilerTest.setUp:286 » Spark Job aborted ...
  TimestampColumnCase1Test.setUp:60->ProfilerTest.setUp:286 » Spark Job aborted ...
  TimestampColumnCase1Test.setUp:60->ProfilerTest.setUp:286 » Spark Job aborted ...
  TimestampColumnCase1Test.setUp:60->ProfilerTest.setUp:286 » Spark Job aborted ...
  TimestampColumnCase1Test.setUp:60->ProfilerTest.setUp:286 » Spark Job aborted ...

Tests run: 9, Failures: 0, Errors: 9, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 8.763 s
[INFO] Finished at: 2017-01-31T16:40:18-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project thinkbig-spark-job-profiler-tests: There are test failures.
[ERROR] 
[ERROR] Please refer to /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase2Test
	*** Starting run for TimestampColumnCase2Test ***
	*** Completed run for TimestampColumnCase2Test ***
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.501 sec - in com.thinkbiganalytics.spark.dataprofiler.testcases.TimestampColumnCase2Test

Results :

Tests run: 4, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3.030 s
[INFO] Finished at: 2017-01-31T16:40:22-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.TopNCase1Test
	*** Starting run for TopNCase1Test ***
	*** Completed run for TopNCase1Test ***
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.057 sec - in com.thinkbiganalytics.spark.dataprofiler.testcases.TopNCase1Test

Results :

Tests run: 3, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2.412 s
[INFO] Finished at: 2017-01-31T16:40:26-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.TopNCase2Test
	*** Starting run for TopNCase2Test ***
	*** Completed run for TopNCase2Test ***
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.731 sec - in com.thinkbiganalytics.spark.dataprofiler.testcases.TopNCase2Test

Results :

Tests run: 2, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2.865 s
[INFO] Finished at: 2017-01-31T16:40:29-08:00
[INFO] Final Memory: 25M/437M
[INFO] ------------------------------------------------------------------------
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.thinkbiganalytics.datalake:thinkbig-spark-job-profiler-tests:jar:0.7.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:license-maven-plugin is missing. @ com.thinkbiganalytics.datalake:thinkbig-data-lake-accelerator:0.7.0-SNAPSHOT, /Users/js186104/Code/thinkbig/data-lake-accelerator/pom.xml, line 804, column 14
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building thinkbig-spark-job-profiler-tests 0.7.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ thinkbig-spark-job-profiler-tests ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ thinkbig-spark-job-profiler-tests ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /Users/js186104/Code/thinkbig/data-lake-accelerator/integrations/spark/spark-job-profiler/spark-job-profiler-tests/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ thinkbig-spark-job-profiler-tests ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ thinkbig-spark-job-profiler-tests ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.thinkbiganalytics.spark.dataprofiler.testcases.TopNCase3Test
	*** Starting run for TopNCase3Test ***
	*** Completed run for TopNCase3Test ***
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.058 sec - in com.thinkbiganalytics.spark.dataprofiler.testcases.TopNCase3Test

Results :

Tests run: 7, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2.215 s
[INFO] Finished at: 2017-01-31T16:40:33-08:00
[INFO] Final Memory: 23M/309M
[INFO] ------------------------------------------------------------------------
